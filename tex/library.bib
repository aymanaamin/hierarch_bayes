Automatically generated by Mendeley Desktop 1.19.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Harvey1997,
abstract = {Given two sources of forecasts of the same quantity, it is possible to compare prediction records. In particular, it can be useful to test the hypothesis of equal accuracy in forecast performance. We analyse the behaviour of two possible tests, and of modifications of these tests designed to circumvent shortcomings in the original formulations. As a result of this analysis, a recommendation for one particular testing approach is made for practical applications. {\textcopyright} 1997 Elsevier Science B.V.},
author = {Harvey, David and Leybourne, Stephen and Newbold, Paul},
doi = {10.1016/S0169-2070(96)00719-4},
file = {:Users/Florian/Documents/Literature/Harvey, Leybourne, Newbold - 1997 - Testing the Equality of Prediction Mean Squared Errors.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Comparing forecasts,Correlated forecast errors,Evaluation of forecasts,Non-normality},
number = {2},
pages = {281--291},
title = {{Testing the Equality of Prediction Mean Squared Errors}},
volume = {13},
year = {1997}
}
@article{NengjunYi2013,
abstract = {In this article, we present a selective overview of some recent developments in Bayesian model and variable selection methods for high dimensional linear models. While most of the reviews in literature are based on conventional methods, we focus on recently developed methods, which have proven to be successful in dealing with high dimensional variable selection. First, we give a brief overview of the traditional model selection methods (viz. Mallow's Cp, AIC, BIC, DIC), followed by a discussion on some recently developed methods (viz. EBIC, regularization), which have occupied the minds of many statisticians. Then, we review high dimensional Bayesian methods with a particular emphasis on Bayesian regularization methods, which have been used extensively in recent years. We conclude by briefly addressing the asymptotic behaviors of Bayesian variable selection methods for high dimensional linear models under different regularity conditions.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {{Nengjun Yi}, Himel Mallick},
doi = {10.4172/2155-6180.S1-005},
eprint = {NIHMS150003},
file = {:Users/Florian/Documents/Literature/Nengjun Yi - 2013 - Bayesian Methods for High Dimensional Linear Models.pdf:pdf},
isbn = {6176321972},
issn = {21556180},
journal = {Journal of Biometrics {\&} Biostatistics},
keywords = {Bayesian hierarchical models,Bayesian model selection,Bayesian variable selection,High dimensional linear models,MCMC,Nonlocal priors: Bayesian subset regression,Penalized regression,Posterior consistency,Regularization,Shrinkage methods,bayesian hierarchical models,bayesian model selection,bayesian subset regression,bayesian variable selection,high dimensional linear models,mcmc,nonlocal priors,penalized regression,posterior consistency,regularization,shrinkage methods},
pmid = {24511433},
title = {{Bayesian Methods for High Dimensional Linear Models}},
url = {https://www.omicsonline.org/bayesian-methods-for-high-dimensional-linear-models-2155-6180.S1-005.php?aid=15156},
year = {2013}
}
@article{Pennings2017,
abstract = {Forecasts are often made at various levels of aggregation of individual products, which combine into groups at higher hierarchical levels. We provide an alternative to the traditional discussion of bottom-up versus top-down forecasting by examining how the hierarchy of products can be exploited when forecasts are generated. Instead of selecting series from parts of the hierarchy for forecasting, we explore the possibility of using all the series. Moreover, instead of using the hierarchy after the initial forecasts are generated, we consider the hierarchical structure as a defining feature of the data-generating process and use it to instantaneously generate forecasts for all levels of the hierarchy. This integrated approach uses a state space model and the Kalman filter to explicitly incorporate product dependencies, such as complementarity of products and product substitution, which are otherwise ignored. An empirical study shows the substantial gain in forecast and inventory performance of generalizing the bottom-up and top-down forecast approaches to an integrated approach. The integrated approach is applicable to hierarchical forecasting in general, and extends beyond the current application of demand forecasting for manufacturers.},
author = {Pennings, Clint L.P. and van Dalen, Jan},
doi = {10.1016/j.ejor.2017.04.047},
file = {:Users/Florian/Documents/Literature/Pennings, van Dalen - 2017 - Integrated Hierarchical Forecasting.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Bottom-up,Decision-making,Forecasting,Hierarchical,Top-down},
number = {2},
pages = {412--418},
publisher = {Elsevier B.V.},
title = {{Integrated Hierarchical Forecasting}},
volume = {263},
year = {2017}
}
@article{Geweke2012,
abstract = {The assumption that one of a set of prediction models is a literal description of reality formally underlies many formal econometric methods, including Bayesian model averaging and most approaches to model selection. Prediction pooling does not invoke this assumption and leads to predictions that improve on those based on Bayesian model averaging, as assessed by the log predictive score. The paper shows that the improvement is substantial using a pool consisting of a dynamic stochastic general equilibrium model, a vector autoregression, and a dynamic factor model, in conjunction with standard US postwar quarterly macroeconomic time series. [ABSTRACT FROM AUTHOR]},
author = {Geweke, John and Amisano, Gianni},
doi = {10.1257/aer.102.3.482},
file = {:Users/Florian/Documents/Literature/Geweke, Amisano - 2012 - Prediction with misspecified models.pdf:pdf},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {3},
pages = {482--486},
title = {{Prediction with misspecified models}},
volume = {102},
year = {2012}
}
@article{Piironen2017,
abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
archivePrefix = {arXiv},
arxivId = {1707.01694},
author = {Piironen, Juho and Vehtari, Aki},
doi = {10.1214/17-EJS1337SI},
eprint = {1707.01694},
file = {:Users/Florian/Documents/Literature/Piironen, Vehtari - 2017 - Sparsity information and regularization in the horseshoe and other shrinkage priors.pdf:pdf},
isbn = {1041-1135},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Bayesian inference,Horseshoe prior,Shrinkage priors,Sparse estimation},
number = {2},
pages = {5018--5051},
title = {{Sparsity information and regularization in the horseshoe and other shrinkage priors}},
volume = {11},
year = {2017}
}
@article{Bai2015,
abstract = {We consider a set of minimal identification conditions for dynamic factor models. These conditions have economic interpretations and require fewer number of restrictions than the static factor framework. Under these restric- tions, a standard structural vector autoregression (SVAR) with measurement errors can be embedded into a dynamic factor model. More generally, we also consider overidentification restrictions to achieve efficiency. General lin- ear restrictions, either in the form of known factor loadings or cross-equation restrictions, are considered. We further consider serially correlated idiosyn- cratic errors with heterogeneous coefficients. A numerically stable Bayesian algorithm for the dynamic factor model with general parameter restrictions is constructed for estimation and inference. A square-root form of Kalman filter is shown to improve robustness and accuracy when sampling the latent factors. Confidence intervals (bands) for the parameters of interest such as impulse responses are readily computed. Similar identification conditions are also exploited for multi-level factor models, and they allow us to study the “spill-over” effects of the shocks arising from one group to another. Key},
archivePrefix = {arXiv},
arxivId = {suresh govindarajan},
author = {Bai, Jushan and Wang, Peng},
doi = {10.1080/07350015.2014.941467},
eprint = {suresh govindarajan},
file = {:Users/Florian/Documents/Literature/Bai, Wang - 2015 - Identification and Estimation of Dynamic Factor Models(2).pdf:pdf},
isbn = {9781905846498},
issn = {15372707},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Dynamic factor models,Impulse response function,Multi-level factor model,Spill-over effect},
number = {2},
pages = {221--240},
pmid = {910},
title = {{Identification and Estimation of Dynamic Factor Models}},
volume = {33},
year = {2015}
}
@article{Watson2004,
author = {Stock, James H. and Watson, Mark W.},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2004 - Combination Forecasts of Output Growth in a Seven-Country Data Set.pdf:pdf},
journal = {Journal of Forecasting},
keywords = {forecast pooling,high-dimensional forecasting,macroeconomic forecasting,time-,varying parameters},
number = {6},
pages = {405 -- 430},
title = {{Combination Forecasts of Output Growth in a Seven-Country Data Set}},
url = {http://ideas.repec.org/a/jof/jforec/v23y2004i6p405-430.html},
volume = {23},
year = {2004}
}
@article{Primiceri2005,
abstract = {This note shows how to apply the procedure of Kim et al. (1998) to the estimation of VAR, DSGE, factor, and unobserved components models with stochastic volatility. In particular, it revisits the estimation algorithm of the time-varying VAR model of Primiceri (2005). The main difference of the new algorithm is the ordering of the various MCMC steps, with each individual step remaining the same.},
author = {Primiceri, Giorgio E.},
doi = {10.1093/restud/rdv024},
file = {:Users/Florian/Documents/Literature/Primiceri - 2005 - Time Varying Structural Vector Autoregressions and Monetary Policy.pdf:pdf},
issn = {1467937X},
journal = {Review of Economic Studies},
keywords = {Bayesian Methods,Time-varying Volatility},
number = {72},
pages = {821--852},
title = {{Time Varying Structural Vector Autoregressions and Monetary Policy}},
volume = {2005},
year = {2005}
}
@article{Diebold1995,
author = {Diebold, Francis X. and Mariano, Roberto S.},
file = {:Users/Florian/Documents/Literature/Diebold, Mariano - 1995 - Comparing Predictive Accuracy.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
number = {3},
pages = {253--263},
title = {{Comparing Predictive Accuracy}},
volume = {13},
year = {1995}
}
@article{Zellner1962,
author = {Zellner, Arnold},
file = {:Users/Florian/Documents/Literature/Zellner - 1962 - An Efficient Method of Estimating Seemingly Unrelated Regressions and Tests for Aggregation Bias.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {298},
pages = {348--368},
title = {{An Efficient Method of Estimating Seemingly Unrelated Regressions and Tests for Aggregation Bias}},
volume = {57},
year = {1962}
}
@book{Clark2013,
abstract = {This chapter surveys recent developments in the evaluation of point forecasts. Taking West's (2006) survey as a starting point, we briefly cover the state of the literature as of the time of West's writing. We then focus on recent developments, including advancements in the evaluation of forecasts at the population level (based on true, unknown model coefficients), the evaluation of forecasts in the infinite sample (based on estimated model coefficients), and the evaluation of conditional versus unconditional forecasts. We present original results in a few subject areas: the optimization of power in determining the split of a sample into in-sample and out-of-sample portions; whether the accuracy of inference in evaluation of multi-step forecasts can be improved with judicious choice of heteroskedasticity-and-autocorrelation estimator (it can); and the extension of West's (1996) theory results for population-level, unconditional forecast evaluation to the case of conditional forecast evaluation. {\textcopyright} 2013 Elsevier B.V.},
author = {Clark, Todd and McCracken, Michael},
booktitle = {Handbook of Economic Forecasting},
doi = {10.1016/B978-0-444-62731-5.00020-8},
file = {:Users/Florian/Documents/Literature/Clark, McCracken - 2013 - Advances in Forecast Evaluation.pdf:pdf},
isbn = {9780444627315},
issn = {15740706},
keywords = {Equal accuracy,Multi-step forecasts,Point forecasts,Prediction},
pages = {1107--1201},
publisher = {Elsevier B.V.},
title = {{Advances in Forecast Evaluation}},
url = {http://dx.doi.org/10.1016/B978-0-444-62731-5.00020-8},
volume = {2},
year = {2013}
}
@article{Hall2004,
author = {Hall, Stephen G and Mitchell, James},
number = {0},
pages = {1--36},
title = {{Density Forecast Combination}},
year = {2004}
}
@article{Wickramasuriya2015,
abstract = {Large collections of time series often have aggregation constraints due to product or geographical hierarchies. The forecasts for the disaggregated series are usually required to add up exactly to the forecasts of the aggregated series, a constraint known as " aggregate consistency " . The combination forecasts proposed by Hyndman et al. (2011) are based on a Generalized Least Squares (GLS) estimator and require an estimate of the covariance matrix of the reconciliation errors (i.e., the errors that arise due to aggregate inconsistency). We show that this is impossible to estimate in practice due to identifiability conditions. We propose a new combination forecasting approach that incorporates the information from a full covariance matrix of forecast errors in obtaining a set of aggregate consistent forecasts. Our approach minimizes the mean squared error of the aggregate consistent forecasts across the en-tire collection of time series under the assumption of unbiasedness. The minimization problem has a closed form solution. We make this solution scalable by providing a computationally less demanding alternative representation. We evaluate the performance of the proposed method compared to alternative methods using a series of simulation designs which take into account various features of the collected time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that the proposed method works well with artificial and real data.},
author = {Wickramasuriya, Shanika L and Athanasopoulos, George and Hyndman, Rob J},
doi = {10.1080/01621459.2018.1448825},
file = {:Users/Florian/Documents/Literature/Wickramasuriya, Athanasopoulos, Hyndman - 2019 - Forecasting Hierarchical and Grouped Time Series Through Trace Minimization.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Hierarchical time series,contemporaneous error correla-tion,forecasting,reconciliation,trace minimization},
number = {526},
pages = {804--819},
publisher = {Taylor {\&} Francis},
title = {{Forecasting Hierarchical and Grouped Time Series Through Trace Minimization}},
url = {https://www.monash.edu/business/econometrics-and-business-statistics/research/publications/ebs/wp15-15.pdf},
volume = {114},
year = {2019}
}
@article{Gross1990,
abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable.},
author = {Gross, Charles W. and Sohl, Jeffrey E.},
doi = {10.1002/for.3980090304},
file = {:Users/Florian/Documents/Literature/Gross, Sohl - 1990 - Disaggregation Methods to Expedite Product Line Forecasting.pdf:pdf},
isbn = {1099-131X},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {Composite root mean square error differential,Disaggregational methods,Forecasting,Product line,Time series analysis},
number = {3},
pages = {233--254},
title = {{Disaggregation Methods to Expedite Product Line Forecasting}},
volume = {9},
year = {1990}
}
@article{Mustonen1997,
abstract = {The total dispersion (sum of variances) and the generalized variance (determinant of the covariance matrix) do not meet certain essential requirements as measures of variability in the multivariate normal distribution. Therefore an alternative measure which is a generalization of the total dispersion is introduced and its formal and statistical properties studied. This measure is genuinely dependent on the covariances and it grows monotonously when new variables are included. The measure is strongly scale-dependent and not invariant even in orthogonal transformations, but it is shown that any invariant measure would violate the above-mentioned monotony requirement.},
author = {Mustonen, Seppo},
doi = {10.1016/S0167-9473(96)00042-4},
file = {:Users/Florian/Documents/Literature/Mustonen - 1997 - A Measure for Total Variability in Multivariate Normal Distribution.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Generalized variance,Measure of variability,Multivariate normal distribution,Total variation},
number = {3},
pages = {321--334},
title = {{A Measure for Total Variability in Multivariate Normal Distribution}},
volume = {23},
year = {1997}
}
@article{Jarocinski2010,
abstract = {This note simplifies the Waggoner and Zha (1999) formula for the conditional distribution of shocks, discusses its linear algebraic intuition, and shows how to account for the dependence between the conditional and unconditional predictive densities when comparing them. {\textcopyright} 2010 Elsevier B.V.},
author = {Jaroci{\'{n}}ski, Marek},
doi = {10.1016/j.econlet.2010.05.022},
file = {:Users/Florian/Documents/Literature/Jaroci{\'{n}}ski - 2010 - Conditional forecasts and uncertainty about forecast revisions in vector autoregressions.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {Conditional forecast,Forecast revision,Vector autoregression},
number = {3},
pages = {257--259},
title = {{Conditional forecasts and uncertainty about forecast revisions in vector autoregressions}},
volume = {108},
year = {2010}
}
@article{Kang2017,
abstract = {It is common practice to evaluate the strength of forecasting methods using collections of well-studied time series datasets, such as the M3 data. The question is, though, how diverse and challenging are these time series, and do they enable us to study the unique strengths and weaknesses of different forecasting methods? This paper proposes a visualisation method for collections of time series that enables a time series to be represented as a point in a two-dimensional instance space. The effectiveness of different forecasting methods across this space is easy to visualise, and the diversity of the time series in an existing collection can be assessed. Noting that the diversity of the M3 dataset has been questioned, this paper also proposes a method for generating new time series with controllable characteristics in order to fill in and spread out the instance space, making our generalisations of forecasting method performances as robust as possible.},
author = {Kang, Yanfei and Hyndman, Rob J. and Smith-Miles, Kate},
doi = {10.1016/j.ijforecast.2016.09.004},
file = {:Users/Florian/Documents/Literature/Kang, Hyndman, Smith-Miles - 2017 - Visualising Forecasting Algorithm Performance Using Time Series Instance Spaces.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecasting algorithm comparison,M3-Competition,Time series generation,Time series visualisation},
number = {2},
pages = {345--358},
title = {{Visualising Forecasting Algorithm Performance Using Time Series Instance Spaces}},
volume = {33},
year = {2017}
}
@article{Jeon2019,
abstract = {New methods are proposed for adjusting probabilistic forecasts to ensure coherence with the aggregation constraints inherent in temporal hierarchies. The different approaches nested within this framework include methods that exploit information at all levels of the hierarchy as well as a novel method based on cross-validation. The methods are evaluated using real data from two wind farms in Crete and electric load in Boston. For these applications, optimal decisions related to grid operations and bidding strategies are based on coherent probabilistic forecasts of energy power. Empirical evidence is also presented showing that probabilistic forecast reconciliation improves the accuracy of the probabilistic forecasts.},
author = {Jeon, Jooyoung and Panagiotelis, Anastasios and Petropoulos, Fotios},
doi = {10.1016/j.ejor.2019.05.020},
file = {:Users/Florian/Documents/Literature/Jeon, Panagiotelis, Petropoulos - 2019 - Probabilistic forecast reconciliation with applications to wind power and electric load.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Aggregation,Cross-validation,Forecasting,Renewable energy generation,Temporal hierarchies},
number = {2},
pages = {364--379},
publisher = {Elsevier B.V.},
title = {{Probabilistic forecast reconciliation with applications to wind power and electric load}},
url = {https://doi.org/10.1016/j.ejor.2019.05.020},
volume = {279},
year = {2019}
}
@article{Feder1982,
author = {Feder, Gershon},
file = {:Users/Florian/Documents/Literature/Feder - 1982 - On Exports and Economic Growth.pdf:pdf},
journal = {Journal of Development Economics},
number = {1-2},
pages = {59--73},
title = {{On Exports and Economic Growth}},
volume = {12},
year = {1982}
}
@article{Athanasopoulos2009,
abstract = {In this paper we explore the hierarchical nature of tourism demand time series and produce short-term forecasts for Australian domestic tourism. The data and forecasts are organized in a hierarchy based on disaggregating the data according to geographical regions and purposes of travel. We consider five approaches to hierarchical forecasting: two variations of the top-down approach, the bottom-up method, a newly proposed top-down approach where top-level forecasts are disaggregated according to the forecasted proportions of lower level series, and a recently proposed optimal combination approach. Our forecast performance evaluation shows that the top-down approach based on forecast proportions and the optimal combination method perform best for the tourism hierarchies we consider. By applying these methods, we produce detailed forecasts of the Australian domestic tourism market. {\textcopyright} 2008 International Institute of Forecasters.},
author = {Athanasopoulos, George and Ahmed, Roman A. and Hyndman, Rob J.},
doi = {10.1016/j.ijforecast.2008.07.004},
file = {:Users/Florian/Documents/Literature/Athanasopoulos, Ahmed, Hyndman - 2009 - Hierarchical Forecasts for Australian Domestic Tourism.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Australia,Exponential smoothing,Hierarchical forecasting,Innovations state space models,Optimal combination forecasts,Top-down method,Tourism demand},
number = {1},
pages = {146--166},
pmid = {15492257},
publisher = {Elsevier B.V.},
title = {{Hierarchical Forecasts for Australian Domestic Tourism}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2008.07.004},
volume = {25},
year = {2009}
}
@article{Waggoner1999,
abstract = {In the existing literature, conditional forecasts in the vector autoregressive (VAR) framework have not been commonly presented with probability distributions. This paper develops Bayesian methods for computing the exact finite-sample distribution of conditional forecasts. It broadens the class of conditional forecasts to which the methods can be applied. The methods work for both structural and reduced-form VAR models and, in contrast to common practices, account for parameter uncertainty in finite samples. Empirical examples under both a flat prior and a reference prior are provided to show the use of these methods.},
author = {Waggoner, Daniel F. and Zha, Tao},
doi = {10.1162/003465399558508},
file = {:Users/Florian/Documents/Literature/Waggoner, Zha - 1999 - Conditional Forecasts in Dynamic Multivariate Models.pdf:pdf},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
keywords = {bayesian methods,conditional forecasts,error,hard and soft conditions,probability distribution},
number = {4},
pages = {639--651},
title = {{Conditional Forecasts in Dynamic Multivariate Models}},
volume = {81},
year = {1999}
}
@article{Hyndman2006,
abstract = {We discuss and compare measures of accuracy of univariate time series forecasts. The methods used in the M-competition as well as the M3-competition, and many of the measures recommended by previous authors on this topic, are found to be degenerate in commonly occurring situations. Instead, we propose that the mean absolute scaled error become the standard measure for comparing forecast accuracy across multiple time series. {\textcopyright} 2006 International Institute of Forecasters.},
author = {Hyndman, Rob J. and Koehler, Anne B.},
doi = {10.1016/j.ijforecast.2006.03.001},
file = {:Users/Florian/Documents/Literature/Hyndman, Koehler - 2006 - Another Look at Measures of Forecast Accuracy.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecast accuracy,Forecast error measures,Forecast evaluation,M-competition,Mean absolute scaled error},
number = {4},
pages = {679--688},
title = {{Another Look at Measures of Forecast Accuracy}},
volume = {22},
year = {2006}
}
@article{Cesur2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Amisano, Gianni and Geweke, John},
doi = {10.1162/REST},
eprint = {arXiv:1011.1669v3},
file = {:Users/Florian/Documents/Literature/Amisano, Geweke - 2017 - Prediction Using Several Macroeconomic Models.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {5},
pages = {912--925},
pmid = {21860536},
title = {{Prediction Using Several Macroeconomic Models}},
volume = {99},
year = {2017}
}
@article{Baumeister2015,
abstract = {Many empirical studies have used numerical Bayesian methods for structural inference in vector autoregressions that are identified solely on the basis of sign restrictions. Because sign restrictions only provide set-identification of structural parameters, over certain regions of the parameter space the posterior inference could only be a restatement of prior beliefs. In this paper we characterize these regions, explicate the beliefs about parameters that are implicit in conventional priors, provide an analytical characterization of the full posterior distribution for arbitrary priors, and analyze the asymptotic properties of this posterior distribution. We show that in a bivariate supply and demand example, if the population correlation between the VAR residuals is negative, then even if one has available an infinite sample of data, any inference about the supply elasticity is coming solely from the prior distribution. More generally, the asymptotic posterior distribution of contemporaneous coefficients in an n-variable VAR is confined to the set of values that orthogonalize the population variance-covariance matrix of OLS residuals, with the height of the posterior proportional to the height of the prior at any point within that set. We suggest that researchers should defend their prior beliefs explicitly and report the difference between prior and posterior distributions for key magnitudes of interest. We illustrate these methods with a simple macroeconomic model. 2},
author = {Baumeister, Christiane and Hamilton, James D.},
doi = {10.3982/ECTA12356},
file = {:Users/Florian/Documents/Literature/Baumeister, Hamilton - 2015 - Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {5},
pages = {1963--1999},
title = {{Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information}},
url = {https://www.econometricsociety.org/doi/10.3982/ECTA12356},
volume = {83},
year = {2015}
}
@article{Kourentzes2019,
abstract = {Key to ensuring a successful tourism sector is timely policy making and detailed planning. National policy formulation and strategic planning requires long-term forecasts at an aggregate level, while regional operational decisions require short-term forecasts, relevant to local tourism operators. For aligned decisions at all levels, supporting forecasts must be ‘coherent' that is they should add up appropriately, across relevant demarcations (e.g., geographical divisions or market segments) and also across time. We propose an approach for generating coherent forecasts across both cross-sections and planning horizons for Australia. This results in significant improvements in forecast accuracy with substantial decision making benefits. Coherent forecasts help break intra- and inter-organisational information and planning silos, in a data driven fashion, blending information from different sources. This article also launches the Annals of Tourism Research Curated Collection on Tourism Demand Forecast, a special selection of research in this field.},
author = {Kourentzes, Nikolaos and Athanasopoulos, George},
doi = {10.1016/j.annals.2019.02.001},
file = {:Users/Florian/Documents/Literature/Kourentzes, Athanasopoulos - 2019 - Cross-Temporal Coherent Forecasts for Australian Tourism.pdf:pdf},
issn = {01607383},
journal = {Annals of Tourism Research},
keywords = {Cross-sectional aggregation,Forecast combinations,Spatial correlations,Temporal aggregation},
pages = {393--409},
publisher = {Elsevier},
title = {{Cross-Temporal Coherent Forecasts for Australian Tourism}},
url = {https://doi.org/10.1016/j.annals.2019.02.001},
volume = {75},
year = {2019}
}
@article{Stock2006,
abstract = {Historically, time series forecasts of economic variables have used only a handful of predictor variables, while forecasts based on a large number of predictors have been the province of judgmental forecasts and large structural econometric models. The past decade, however, has seen considerable progress in the development of time series forecasting methods that exploit many predictors, and this chapter surveys these methods. The first group of methods considered is forecast combination (forecast pooling), in which a single forecast is produced from a panel of many forecasts. The second group of methods is based on dynamic factor models, in which the comovements among a large number of economic variables are treated as arising from a small number of unobserved sources, or factors. In a dynamic factor model, estimates of the factors (which become increasingly precise as the number of series increases) can be used to forecast individual economic variables. The third group of methods is Bayesian model averaging, in which the forecasts from very many models, which differ in their constituent variables, are averaged based on the posterior probability assigned to each model. The chapter also discusses empirical Bayes methods, in which the hyperparameters of the priors are estimated. An empirical illustration applies these different methods to the problem of forecasting the growth rate of the U.S. index of industrial production with 130 predictor variables. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1016/S1574-0706(05)01010-4},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2006 - Forecasting with Many Predictors.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
journal = {Handbook of Economic Forecasting},
keywords = {Bayesian model averaging,dynamic factor models,empirical Bayes forecasts,forecast combining,principal components analysis,shrinkage forecasts},
number = {05},
pages = {515--554},
title = {{Forecasting with Many Predictors}},
volume = {1},
year = {2006}
}
@article{Chan2009,
abstract = {We consider the problem of implementing simple and efficient Markov chain Monte Carlo (MCMC) estimation algorithms for state space models. A conceptually transparent derivation of the posterior distribution of the states is discussed, which also leads to an efficient simulation algorithm that is modular, scalable and widely applicable. We also discuss a simple approach for evaluating the integrated likelihood, defined as the density of the data given the parameters but marginal of the state vector. We show that this high-dimensional integral can be easily evaluated with minimal computational and conceptual difficulty. Two empirical applications in macroeconomics demonstrate that the methods are versatile and computationally undemanding. In one application, involving a time-varying parameter model, we show that the methods allow for efficient handling of large state vectors. In our second application, involving a dynamic factor model, we introduce a new blocking strategy which results in improved MCMC mixing at little cost. The results demonstrate that the framework is simple, flexible and efficient.},
author = {Chan, J.C.C. and Jeliazkov, I.},
doi = {10.1504/IJMMNO.2009.030090},
file = {:Users/Florian/Documents/Literature/Chan, Jeliazkov - 2009 - Efficient Simulation and Integrated Likelihood Estimation in State Space Models.pdf:pdf},
issn = {2040-3607},
journal = {International Journal of Mathematical Modelling and Numerical Optimisation},
keywords = {Banded matrix,Bayesian estimation,Collapsed sampler,Dynamic factor model,Kalman filter,MCMC,Markov chain Monte Carlo,State smoothing,Time-varying parameter model},
number = {1-2},
pages = {101--120},
title = {{Efficient Simulation and Integrated Likelihood Estimation in State Space Models}},
volume = {1},
year = {2009}
}
@article{Polson2010,
abstract = {We study the classic problem of choosing a prior distribution for a location parameter $\beta$ = ($\beta$1, . . . ,$\beta$p) as p grows large. First, we study the stan- dard “global-local shrinkage” approach, based on scale mixtures of normals. Two theorems are presented which characterize certain desirable properties of shrinkage priors for sparse problems. Next, we review some recent results showing how L´ evy processes can be used to generate infinite-dimensional ver- sions of standard normal scale-mixture priors, along with new priors that have yet to be seriously studied in the literature. This approach provides an intuitive framework both for generating new regularization penalties and shrinkage rules, and for performing asymptotic analysis on existing models.},
author = {Polson, Nicholas G. and Scott, James G.},
doi = {10.1093/acprof:oso/9780199694587.003.0017},
file = {:Users/Florian/Documents/Literature/Polson, Scott - 2010 - Shrink Globally, Act Locally Sparse Bayesian Regularization and Prediction.pdf:pdf},
isbn = {9780191731921},
journal = {Bayesian Statistics},
keywords = {L{\'{e}}vy processes,Shrinkage,Sparsity},
title = {{Shrink Globally, Act Locally: Sparse Bayesian Regularization and Prediction}},
volume = {9},
year = {2010}
}
@article{Kapetanios2015,
abstract = {Abstract Density forecast combinations are becoming increasingly popular as a means of improving forecast 'accuracy', as measured by a scoring rule. In this paper we generalise this literature by letting the combination weights follow more general schemes. Sieve estimation is used to optimise the score of the generalised density combination where the combination weights depend on the variable one is trying to forecast. Specific attention is paid to the use of piecewise linear weight functions that let the weights vary by region of the density. We analyse these schemes theoretically, in Monte Carlo experiments and in an empirical study. Our results show that the generalised combinations outperform their linear counterparts.},
author = {Kapetanios, G. and Mitchell, J. and Price, S. and Fawcett, N.},
doi = {10.1016/j.jeconom.2015.02.047},
file = {:Users/Florian/Documents/Literature/Kapetanios et al. - 2015 - Generalised Density Forecast Combinations.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Density forecasting,Model combination,Scoring rules},
number = {1},
pages = {150--165},
publisher = {Elsevier B.V.},
title = {{Generalised Density Forecast Combinations}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.02.047},
volume = {188},
year = {2015}
}
@article{Farebrother1978,
author = {Farebrother, R. W.},
doi = {10.1080/00401706.1978.10489635},
file = {:Users/Florian/Documents/Literature/Farebrother - 1978 - Partitioned Ridge Regression.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Mean square error,Partitioned regression,Ridge regression,Standardization},
number = {2},
pages = {121--122},
title = {{Partitioned Ridge Regression}},
volume = {20},
year = {1978}
}
@article{Hyndman2011,
abstract = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these "hierarchical time series". They are commonly forecast using either a "bottom-up" or a "top-down" method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
doi = {10.1016/j.csda.2011.03.006},
file = {:Users/Florian/Documents/Literature/Hyndman et al. - 2011 - Optimal Combination Forecasts for Hierarchical Time Series.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Bottom-up forecasting,Combining forecasts,GLS regression,Hierarchical forecasting,Reconciling forecasts,Top-down forecasting},
number = {9},
pages = {2579--2589},
publisher = {Elsevier B.V.},
title = {{Optimal Combination Forecasts for Hierarchical Time Series}},
url = {http://dx.doi.org/10.1016/j.csda.2011.03.006},
volume = {55},
year = {2011}
}
@article{Hyndman2008,
author = {Hyndman, Rob J. and Khandakar, Yeasmin},
file = {:Users/Florian/Documents/Literature/Hyndman, Khandakar - 2008 - Automatic Time Series Forecasting The forecast Package for R.pdf:pdf},
journal = {Journal of Statistical Software},
keywords = {arima models,automatic forecasting,exponential smoothing,prediction inter-,r,state space models,time series,vals},
number = {3},
pages = {1--22},
title = {{Automatic Time Series Forecasting: The forecast Package for R}},
volume = {27},
year = {2008}
}
@article{Brown1980,
author = {Brown, P. J. and Zidek, J. V.},
file = {:Users/Florian/Documents/Literature/Brown, Zidek - 1980 - Adaptive Multivariate Ridge Regression.pdf:pdf},
journal = {The Annals of Statistics},
number = {1},
pages = {64--74},
title = {{Adaptive Multivariate Ridge Regression}},
volume = {8},
year = {1980}
}
@article{Awokuse2007,
abstract = {The economic growth effects of CEEC market liberalization and increasing trade access to the larger EU market is an important empirical question worthy of investigation. This paper examines the impact of export and import expansion on growth in three transition economies. The empirical results suggest that trade stimulates economic growth. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Awokuse, Titus O.},
doi = {10.1016/j.econlet.2006.08.025},
file = {:Users/Florian/Documents/Literature/Awokuse - 2007 - Causality between exports, imports, and economic growth Evidence from transition economies.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {CEEC nations,Cointegration,Economic growth,Granger causality,Trade},
number = {3},
pages = {389--395},
title = {{Causality between exports, imports, and economic growth: Evidence from transition economies}},
volume = {94},
year = {2007}
}
@incollection{Hyndman2018,
author = {Hyndman, Rob J. and Athanasopoulos, George},
booktitle = {Forecasting: Principles and Practice},
title = {{Forecasting Hierarchical or Grouped Time Series}},
year = {2018}
}
@article{Athanasopoulos2017,
abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied combination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short-term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that forecasting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident {\&} Emergency departments.},
author = {Athanasopoulos, George and Hyndman, Rob J. and Kourentzes, Nikolaos and Petropoulos, Fotios},
doi = {10.1016/j.ejor.2017.02.046},
file = {:Users/Florian/Documents/Literature/Athanasopoulos et al. - 2017 - Forecasting with Temporal Hierarchies.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Forecast combination,Forecasting,Hierarchical forecasting,Reconciliation,Temporal aggregation},
number = {1},
pages = {60--74},
title = {{Forecasting with Temporal Hierarchies}},
volume = {262},
year = {2017}
}
@article{Bollineni-Balabay2017,
abstract = {This study compares state space models (estimated with the Kalman filter with a frequentist approach to hyperparameter estimation) with multilevel time series models (based on the hierarchical Bayesian framework). The application chosen is the Dutch Travel Survey featuring small sample sizes and discontinuities caused by the survey redesigns. Both modelling approaches deliver similar point and variance estimates. Slight differences in model-based variance estimates appear mostly in small-scaled domains and are due to neglecting uncertainty around the hyperparameter estimates in the state space models, and to a lesser extent to skewness in the posterior distributions of the parameters of interest. The results suggest that the reduction in design-based standard errors with the hierarchical Bayesian approach is over 50{\%} at the provincial level, and over 30{\%} at the national level.},
author = {Bollineni-Balabay, Oksana and van den Brakel, Jan and Palm, Franz and Boonstra, Harm Jan},
doi = {10.1111/rssa.12332},
file = {:Users/Florian/Documents/Literature/Bollineni-Balabay et al. - 2017 - Multilevel hierarchical Bayesian versus state space approach in time series small area estimation the.pdf:pdf},
issn = {1467985X},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Gibbs sampling,Hierarchical Bayes approach,Hyperparameter uncertainty,Multilevel model,State space model,Structural time series model},
number = {4},
pages = {1281--1308},
title = {{Multilevel hierarchical Bayesian versus state space approach in time series small area estimation: the Dutch Travel Survey}},
volume = {180},
year = {2017}
}
@article{Haitovsky1987,
author = {Haitovsky, Yoel},
file = {:Users/Florian/Documents/Literature/Haitovsky - 1987 - On Multivariate Ridge Regression.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {563--570},
title = {{On Multivariate Ridge Regression}},
volume = {74},
year = {1987}
}
@article{Conflitti2015,
author = {Conflitti, Cristina and Mol, Christine De and Giannone, Domenico},
file = {:Users/Florian/Documents/Literature/Conflitti, Mol, Giannone - 2001 - Optimal Combination of Survey Forecasts.pdf:pdf},
journal = {International Journal of Forecasting},
keywords = {forecast combination},
number = {4},
pages = {1096--1103},
title = {{Optimal Combination of Survey Forecasts}},
volume = {31},
year = {2015}
}
@article{Taieb2017,
abstract = {Many applications require forecasts for a hierarchy comprising a set of time series along with aggregates of subsets of these series. Hierarchical forecasting require not only good prediction accuracy at each level of the hierarchy, but also the coherency between different levels — the property that forecasts add up appropriately across the hierarchy. A fundamental limitation of prior research is the focus on forecasting the mean of each time series. We consider the situation where probabilistic forecasts are needed for each series in the hierarchy, and propose an algorithm to compute predictive distributions rather than mean forecasts only. Our algorithm has the advantage of synthesizing information from different levels in the hierarchy through a sparse forecast combination and a probabilistic hierarchical aggregation. We evaluate the accuracy of our forecasting algorithm on both simulated data and large-scale electricity smart meter data. The results show consistent performance gains compared to state-of-the art methods.},
author = {Taieb, Souhaib Ben and Taylor, James W and Hyndman, Rob J},
file = {:Users/Florian/Documents/Literature/Taieb, Taylor, Hyndman - 2017 - Coherent Probabilistic Forecasts for Hierarchical Time Series.pdf:pdf},
issn = {1938-7228},
journal = {Proceedings of the 34th International Conference on Machine Learning},
keywords = {empi,forecast combination,probabilistic forecast},
number = {April},
pages = {3348--3357},
title = {{Coherent Probabilistic Forecasts for Hierarchical Time Series}},
url = {http://proceedings.mlr.press/v70/taieb17a.html},
volume = {70},
year = {2017}
}
@article{Percy1992,
author = {Percy, David F.},
file = {:Users/Florian/Documents/Literature/Percy - 1992 - Prediction for Seemingly Unrelated Regressions.pdf:pdf},
journal = {Journal of the Royal Statistical Society},
keywords = {bayes estimate,gibbs sampling,predictive density function,seemingly,unrelated regressions},
number = {1},
pages = {243--252},
title = {{Prediction for Seemingly Unrelated Regressions}},
volume = {54},
year = {1992}
}
@article{Baum2004,
abstract = {In this paper, we investigate empirically the impact of exchange rate volatility on real international trade flows utilizing a 13-country data set of monthly bilateral real exports for 1980-1998. We compute one-month-ahead exchange rate volatility from the intra-monthly variations in the exchange rate to better quantify this latent variable. We find that the effect of exchange rate volatility on trade flows is nonlinear, depending on its interaction with the importing country's volatility of economic activity, and that it varies considerably over the set of country pairs considered. Copyright {\textcopyright} 2003 John Wiley {\&} Sons, Ltd.},
author = {Baum, Christopher F. and Caglayan, Mustafa and Ozkan, Neslihan},
doi = {10.1002/jae.725},
file = {:Users/Florian/Documents/Literature/Baum, Caglayan, Ozkan - 2004 - Nonlinear effects of exchange rate volatility on the volume of bilateral exports.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
number = {1},
pages = {1--23},
title = {{Nonlinear effects of exchange rate volatility on the volume of bilateral exports}},
volume = {19},
year = {2004}
}
@article{Timmermann2006,
abstract = {Forecast combinations have frequently been found in empirical studies to produce better forecasts on average than methods based on the ex ante best individual forecasting model. Moreover, simple combinations that ignore correlations between forecast errors often dominate more refined combination schemes aimed at estimating the theoretically optimal combination weights. In this chapter we analyze theoretically the factors that determine the advantages from combining forecasts (for example, the degree of correlation between forecast errors and the relative size of the individual models' forecast error variances). Although the reasons for the success of simple combination schemes are poorly understood, we discuss several possibilities related to model misspecification, instability (non-stationarities) and estimation error in situations where the number of models is large relative to the available sample size. We discuss the role of combinations under asymmetric loss and consider combinations of point, interval and probability forecasts. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Timmermann, Allan},
doi = {10.1016/S1574-0706(05)01004-9},
eprint = {arXiv:1011.1669v3},
file = {:Users/Florian/Documents/Literature/Timmermann - 2006 - Forecast Combinations.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
journal = {Handbook of Economic Forecasting},
keywords = {diversification gains,forecast combinations,model misspecification,pooling and trimming,shrinkage methods},
number = {05},
pages = {135--196},
pmid = {25246403},
title = {{Forecast Combinations}},
volume = {1},
year = {2006}
}
@article{Bonadio2020,
abstract = {On January 15, 2015, the Swiss National Bank discontinued its minimum exchange rate policy of 1 euro against 1.2 Swiss francs. This policy change resulted in a sharp, unanticipated, and permanent appreciation of the Swiss franc by more than 11{\%} against the euro. We analyze the pass-through of this unusually clean exchange rate shock into import unit values at the daily frequency using Swiss transaction-level trade data. Our key findings are twofold. First, for goods invoiced in euros, the pass-through is immediate and complete. Second, for goods invoiced in Swiss francs, the pass-through is partial and exceptionally fast: beginning on the second working day after the exchange rate shock, the medium-run pass-through is reached after 12 working days.},
author = {Bonadio, Barth{\'{e}}l{\'{e}}my and Fischer, Andreas M. and Saur{\'{e}}, Philip},
doi = {10.1093/jeea/jvz007},
file = {:Users/Florian/Documents/Literature/Bonadio, Fischer, Saur{\'{e}} - 2020 - The Speed of Exchange Rate Pass-Through.pdf:pdf},
issn = {15424774},
journal = {Journal of the European Economic Association},
number = {1},
pages = {506--538},
title = {{The Speed of Exchange Rate Pass-Through}},
volume = {18},
year = {2020}
}
@article{Ando2010,
abstract = {Computationally efficient simulation methods for hierarchical Bayesian analysis of the seemingly unrelated regression (SUR) and simultaneous equa- tions models (SEM) are proposed and applied. These methods combine a direct Monte Carlo (DMC) approach and an importance sampling procedure to calculate Bayesian estimation and prediction results, namely, Bayesian posterior densities for parameters, predictive densities for future values of variables and associated moments, intervals and other quantities. The results obtained by our approach are compared to those yielded by use of MCMC techniques. Finally, we show that our algorithm can be applied to the Bayesian analysis of state space models},
author = {Ando, Tomohiro and Zellner, Arnold},
doi = {10.1214/10-BA503},
file = {:Users/Florian/Documents/Literature/Ando, Zellner - 2010 - Hierarchical Bayesian Analysis of the Seemingly Unrelated Regression and Simultaneous Equations Models Using a Co.pdf:pdf},
isbn = {9781424444410},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Bayesian estimation and prediction,Direct Monte Carlo,Hierarchical priors importance sampling,Markov Chain Monte Carlo},
number = {1},
pages = {65--96},
title = {{Hierarchical Bayesian Analysis of the Seemingly Unrelated Regression and Simultaneous Equations Models Using a Combination of Direct Monte Carlo and Importance Sampling Techniques}},
volume = {5},
year = {2010}
}
@article{Hyndman2016,
abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
author = {Hyndman, Rob J. and Lee, Alan J. and Wang, Earo},
doi = {10.1016/j.csda.2015.11.007},
file = {:Users/Florian/Documents/Literature/Hyndman, Lee, Wang - 2016 - Fast Computation of Reconciled Forecasts for Hierarchical and Grouped Time Series.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Combining forecasts,Grouped time series,Hierarchical time series,Reconciling forecasts,Weighted least squares},
pages = {16--32},
publisher = {Elsevier B.V.},
title = {{Fast Computation of Reconciled Forecasts for Hierarchical and Grouped Time Series}},
url = {http://dx.doi.org/10.1016/j.csda.2015.11.007},
volume = {97},
year = {2016}
}
@article{Firinguetti1997,
author = {Firinguetti, Luis},
doi = {10.1080/00949659708811785},
file = {:Users/Florian/Documents/Literature/Firinguetti - 1997 - Ridge regression in the context of a system of seemingly unrelated regression equations.pdf:pdf},
isbn = {0094965970881},
issn = {00949655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {Collinearity; simulation,Ridge regression,Seemingly unrelated regressions},
number = {2},
pages = {145--162},
title = {{Ridge regression in the context of a system of seemingly unrelated regression equations}},
volume = {56},
year = {1997}
}
@article{Bergmeir2016,
abstract = {Exponential smoothing is one of the most popular forecasting methods. We present a technique for the bootstrap aggregation (bagging) of exponential smoothing methods, which results in significant improvements in the forecasts. The bagging uses a Box-Cox transformation followed by an STL decomposition to separate the time series into the trend, seasonal part, and remainder. The remainder is then bootstrapped using a moving block bootstrap, and a new series is assembled using this bootstrapped remainder. An ensemble of exponential smoothing models is then estimated on the bootstrapped series, and the resulting point forecasts are combined. We evaluate this new method on the M3 data set, and show that it outperforms the original exponential smoothing models consistently. On the monthly data, we achieve better results than any of the original M3 participants.},
author = {Bergmeir, Christoph and Hyndman, Rob J. and Ben{\'{i}}tez, Jos{\'{e}} M.},
doi = {10.1016/j.ijforecast.2015.07.002},
file = {:Users/Florian/Documents/Literature/Bergmeir, Hyndman, Ben{\'{i}}tez - 2016 - Bagging Exponential Smoothing Methods using STL Decomposition and Box-Cox Transformation.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bagging,Bootstrapping,Exponential smoothing,STL decomposition},
number = {2},
pages = {303--312},
publisher = {Elsevier B.V.},
title = {{Bagging Exponential Smoothing Methods using STL Decomposition and Box-Cox Transformation}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2015.07.002},
volume = {32},
year = {2016}
}
@book{Greenberg2008,
author = {Greenberg, Edward},
file = {:Users/Florian/Documents/Literature/Greenberg - 2008 - Introduction to Bayesian Econometrics.pdf:pdf},
publisher = {Cambridge University Press},
title = {{Introduction to Bayesian Econometrics}},
year = {2008}
}
@article{corani2019,
  title={{Reconciling Hierarchical Forecasts via Bayes' Rule}},
  author={Corani, Giorgio and Azzimonti, Dario and Zaffalon, Marco},
  journal={arXiv preprint arXiv:1906.03105},
  year={2019}
}
@inproceedings{bentaieb2019,
  title={{Regularized regression for Hierarchical Forecasting without Unbiasedness Conditions}},
  author={Ben Taieb, Souhaib and Koo, Bonsoo},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1337--1347},
  year={2019}
}


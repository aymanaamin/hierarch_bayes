Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Baumeister2015,
abstract = {Many empirical studies have used numerical Bayesian methods for structural inference in vector autoregressions that are identified solely on the basis of sign restrictions. Because sign restrictions only provide set-identification of structural parameters, over certain regions of the parameter space the posterior inference could only be a restatement of prior beliefs. In this paper we characterize these regions, explicate the beliefs about parameters that are implicit in conventional priors, provide an analytical characterization of the full posterior distribution for arbitrary priors, and analyze the asymptotic properties of this posterior distribution. We show that in a bivariate supply and demand example, if the population correlation between the VAR residuals is negative, then even if one has available an infinite sample of data, any inference about the supply elasticity is coming solely from the prior distribution. More generally, the asymptotic posterior distribution of contemporaneous coefficients in an n-variable VAR is confined to the set of values that orthogonalize the population variance-covariance matrix of OLS residuals, with the height of the posterior proportional to the height of the prior at any point within that set. We suggest that researchers should defend their prior beliefs explicitly and report the difference between prior and posterior distributions for key magnitudes of interest. We illustrate these methods with a simple macroeconomic model. 2},
author = {Baumeister, Christiane and Hamilton, James D.},
doi = {10.3982/ECTA12356},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Baumeister, Hamilton - 2015 - Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {5},
pages = {1963--1999},
title = {{Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information}},
url = {https://www.econometricsociety.org/doi/10.3982/ECTA12356},
volume = {83},
year = {2015}
}
@article{Anderson1987,
abstract = {In order to generate a random orthogonal matrix distributed according to Haar measure over the orthogonal group it is natural to start with a matrix of normal random variables and then factor it by the singular value decomposition. A more efficient method is obtained by using Householder transformations. We propose another alternative based on the product of {\$}{\{}{\{}n(n - 1){\}}/2{\}}{\$} orthogonal matrices, each of which represents an angle of rotation. Some numerical comparisons of alternative methods are made.},
author = {Anderson, T. W. and Olkin, I. and Underhill, L. G.},
doi = {10.1137/0908055},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Anderson, Olkin, Underhill - 1987 - Generation of Random Orthogonal Matrices.pdf:pdf},
issn = {0196-5204},
journal = {SIAM Journal on Scientific and Statistical Computing},
keywords = {haar measure,monte carlo method,orthogonal matrix,random matrix,random number generator,simulation},
number = {2},
pages = {625--629},
title = {{Generation of Random Orthogonal Matrices}},
volume = {8},
year = {1987}
}
@article{Angrist2010,
author = {Angrist, Joshua D. and Pischke, J{\"{o}}rn-Steffen},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Angrist, Pischke - 2010 - The Credibility Revolution in Empirical Economics How Better Research Design is Taking the Con out of Economet.pdf:pdf},
journal = {Journal of Economic Perspectives},
number = {2},
pages = {3--30},
title = {{The Credibility Revolution in Empirical Economics: How Better Research Design is Taking the Con out of Econometrics}},
volume = {24},
year = {2010}
}
@article{Zhang2005,
author = {Zhang, Lu},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Zhang - 2005 - The Value Premium.pdf:pdf},
journal = {Journal of Finance},
number = {1},
pages = {67--103},
title = {{The Value Premium}},
volume = {60},
year = {2005}
}
@article{PaulConwayandBenHunt1997,
author = {Conway, Paul and Hunt, Ben},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Conway, Hunt - 1997 - Estimating Potential Output A Semi-Structural Approach.pdf:pdf},
title = {{Estimating Potential Output: A Semi-Structural Approach}},
year = {1997}
}
@article{Mariano2010,
abstract = {The Stock-Watson coincident index and its subsequent extensions assume a static linear one-factor model for the component indicators. This restrictive assumption is unnecessary if one defines a coincident index as an estimate of monthly real gross domestic products (GDP). This paper estimates Gaussian vector autoregression (VAR) and factor models for latent monthly real GDP and other coincident indicators using the observable mixed-frequency series. For maximum likelihood estimation of a VAR model, the expectation-maximization (EM) algorithm helps in finding a good starting value for a quasi-Newton method. The smoothed estimate of latent monthly real GDP is a natural extension of the Stock-Watson coincident index. Copyright (c) Blackwell Publishing Ltd and the Department of Economics, University of Oxford, 2009.},
author = {Mariano, Roberto S. and Murasawa, Yasutomo},
doi = {10.1111/j.1468-0084.2009.00567.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Mariano, Murasawa - 2010 - A Coincident Index, Common Factors, and Monthly Real GDP.pdf:pdf},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
number = {1},
pages = {27--46},
title = {{A Coincident Index, Common Factors, and Monthly Real GDP}},
volume = {72},
year = {2010}
}
@article{Runstler2009,
abstract = {This paper evaluates different models for the short-term forecasting of real GDP growth in ten selected European countries and the euro area as a whole. Purely quarterly models are compared with models designed to exploit early releases of monthly indicators for the nowcast and forecast of quarterly GDP growth. Amongst the latter, we consider small bridge equations and forecast equations in which the bridging between monthly and quarterly data is achieved through a regression on factors extracted from large monthly datasets. The forecasting exercise is performed in a simulated real-time context, which takes account of publication lags in the individual series. In general, we fi nd that models that exploit monthly information outperform models that use purely quarterly data and, amongst the former, factor models perform best.},
author = {R{\"{u}}nstler, G. and Barhoum, K. and Benk, S. and Cristadoro, R. and Reijer, A. D.E.N. and Jakaitiene, A. and Jelonek, P. and Rua, A. and Ruth, K. and Nieuwenhuyze, C. V.A.N.},
doi = {10.1002/for.1105},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/R{\"{u}}nstler et al. - 2009 - Short-term forecasting of GDP using large datasets A pseudo real-time forecast evaluation exercise.pdf:pdf},
issn = {02776693},
journal = {Journal of Forecasting},
keywords = {Dynamic factor models,State space models,Uoc models},
number = {7},
pages = {595--611},
title = {{Short-term forecasting of GDP using large datasets: A pseudo real-time forecast evaluation exercise}},
volume = {28},
year = {2009}
}
@incollection{Mahler2009,
author = {Mahler, Nicolas},
booktitle = {Machine Learning for Signal Processing},
doi = {10.1109/MLSP.2009.5306195},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Mahler - 2009 - Modeling the S{\&}P 500 index using the Kalman filter and the LagLasso.pdf:pdf},
isbn = {978-1-4244-4947-7},
pages = {1--4},
title = {{Modeling the S{\&}P 500 index using the Kalman filter and the LagLasso}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5306195},
year = {2009}
}
@article{Claeskens2016,
abstract = {This paper offers a theoretical explanation for the stylized fact that forecast combinations with estimated optimal weights often perform poorly in applications. The properties of the forecast combination are typically derived under the assumption that the weights are fixed, while in practice they need to be estimated. If the fact that the weights are random rather than fixed is taken into account during the optimality derivation, then the forecast combination will be biased (even when the original forecasts are unbiased), and its variance will be larger than in the fixed-weight case. In particular, there is no guarantee that the 'optimal' forecast combination will be better than the equal-weight case, or even improve on the original forecasts. We provide the underlying theory, some special cases, and a numerical illustration.},
author = {Claeskens, Gerda and Magnus, Jan R. and Vasnev, Andrey L. and Wang, Wendun},
doi = {10.1016/j.ijforecast.2015.12.005},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Claeskens et al. - 2016 - The forecast combination puzzle A simple theoretical explanation.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecast combination,Optimal weights},
number = {3},
pages = {754--762},
publisher = {Elsevier B.V.},
title = {{The forecast combination puzzle: A simple theoretical explanation}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2015.12.005},
volume = {32},
year = {2016}
}
@article{Andreou2013,
abstract = {We introduce easy to implement regression-based methods for predicting quarterly real economic activity that use daily financial data. Our analysis is designed to elucidate the value of daily information and provide real-time forecast updates of the current (nowcasting) and future quarters. Our findings show that while on average the predictive ability of all models worsens substantially following the financial crisis, the models we propose suffer relatively less losses. Moreover, these predictive gains are primarily driven by the asset classes of government securities, equities, and especially corporate risk.},
author = {Andreou, Elena and Ghysels, Eric and Kourtellos, Andros},
doi = {10.1080/07350015.2013.767199},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Andreou, Ghysels, Kourtellos - 2013 - Should Macroeconomic Forecasters Use Daily Financial Data and How.pdf:pdf},
isbn = {0735-0015$\backslash$r1537-2707},
issn = {07350015},
journal = {Journal of Business and Economic Statistics},
keywords = {Daily financial factors,Financial markets and the macroeconomy,MIDAS regressions},
number = {2},
pages = {240--251},
title = {{Should Macroeconomic Forecasters Use Daily Financial Data and How?}},
volume = {31},
year = {2013}
}
@article{Christiano2010,
author = {Christiano, Lawrence J and Trabandt, Mathias and Walentin, Karl},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Christiano, Trabandt, Walentin - 2010 - DSGE Models for Monetary Policy Analysis.pdf:pdf},
journal = {NBER Working Paper Series},
title = {{DSGE Models for Monetary Policy Analysis}},
volume = {16074},
year = {2010}
}
@article{Reinhart2008,
author = {Reinhart, Carmen M. and Rogoff, Kenneth S.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Reinhart, Rogoff - 2008 - Is the 2007 U.S. Sub-Prime Financial Crisis So Different An International Historical Comparison.pdf:pdf},
journal = {NBER Working Paper Series},
number = {13761},
pages = {1--14},
title = {{Is the 2007 U.S. Sub-Prime Financial Crisis So Different? An International Historical Comparison}},
volume = {2008},
year = {2008}
}
@article{DelNegro2004,
author = {{Del Negro}, Marco and Schorfheide, Frank},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Del Negro, Schorfheide - 2004 - Priors from General Equilibrium Models for VARs.pdf:pdf},
journal = {International Economic Review},
keywords = {bayesian analysis,dsge models,forecasting,vector autoregressions},
number = {2},
pages = {643--673},
title = {{Priors from General Equilibrium Models for VARs}},
volume = {45},
year = {2004}
}
@article{Kalt2001,
author = {Kalt, Daniel},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kalt - 2001 - The Credit Channel as a Monetary Transmission Mechanism Some Microeconometric Evidence for Switzerland.pdf:pdf},
journal = {Schweiz. Zeitschrift f{\"{u}}r Volkswirtschaft und Statistik},
number = {4},
pages = {555--577},
title = {{The Credit Channel as a Monetary Transmission Mechanism: Some Microeconometric Evidence for Switzerland}},
volume = {137},
year = {2001}
}
@article{Bai2015,
abstract = {We consider a set of minimal identification conditions for dynamic factor models. These conditions have economic interpretations and require fewer number of restrictions than the static factor framework. Under these restric- tions, a standard structural vector autoregression (SVAR) with measurement errors can be embedded into a dynamic factor model. More generally, we also consider overidentification restrictions to achieve efficiency. General lin- ear restrictions, either in the form of known factor loadings or cross-equation restrictions, are considered. We further consider serially correlated idiosyn- cratic errors with heterogeneous coefficients. A numerically stable Bayesian algorithm for the dynamic factor model with general parameter restrictions is constructed for estimation and inference. A square-root form of Kalman filter is shown to improve robustness and accuracy when sampling the latent factors. Confidence intervals (bands) for the parameters of interest such as impulse responses are readily computed. Similar identification conditions are also exploited for multi-level factor models, and they allow us to study the “spill-over” effects of the shocks arising from one group to another. Key},
archivePrefix = {arXiv},
arxivId = {suresh govindarajan},
author = {Bai, Jushan and Wang, Peng},
doi = {10.1080/07350015.2014.941467},
eprint = {suresh govindarajan},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bai, Wang - 2015 - Identification and Estimation of Dynamic Factor Models(2).pdf:pdf},
isbn = {9781905846498},
issn = {15372707},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Dynamic factor models,Impulse response function,Multi-level factor model,Spill-over effect},
number = {2},
pages = {221--240},
pmid = {910},
title = {{Identification and Estimation of Dynamic Factor Models}},
volume = {33},
year = {2015}
}
@article{Karlsson1997,
author = {Karlsson, Sune and Kadiyala, K. Rao},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Karlsson, Kadiyala - 1997 - Numerical Methods for Estimation and Inference in Bayesian Var-Models.pdf:pdf},
journal = {Journal of Applied Econometrics},
number = {12},
pages = {99--132},
title = {{Numerical Methods for Estimation and Inference in Bayesian Var-Models}},
volume = {12},
year = {1997}
}
@book{Kim1999a,
author = {Kim, Chang-Jin and Nelson, Charles R.},
booktitle = {MIT Press Books},
doi = {10.2307/2669796},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kim, Nelson - 1999 - State-Space Models with Regime-Switching Classical and Gibbs Sampling Approaches with Applications(2).pdf:pdf},
isbn = {9780262112383},
issn = {01621459},
pages = {1--297},
publisher = {The MIT press},
title = {{State-Space Models with Regime-Switching: Classical and Gibbs Sampling Approaches with Applications}},
url = {http://proxy.mul.missouri.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=e000xna{\&}AN=9231{\&}site=ehost-live{\&}scope=site},
year = {1999}
}
@article{DelNegro2008,
abstract = {We develop a dynamic factor model with time-varying factor loadings and stochastic volatility in both the latent factors and idiosyncratic components. We employ this new measurement tool to study the evolution of international business cycles in the post- Bretton Woods period, using a panel of output growth rates for nineteen countries. We find 1) statistical evidence of a decline in volatility for most countries, with the timing, magnitude, and source (international or domestic) of the decline differing across countries; 2) some evidence of a decline in business cycle synchronization for Group of Seven (G-7) countries, but otherwise no evidence of changes in synchronization for the sample countries, including European and euro-area countries; and 3) convergence in the volatility of business cycles across countries.},
author = {{Del Negro}, Marco and Otrok, Christopher},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Del Negro, Otrok - 2008 - Dynamic Factor Models with Time-Varying Parameters Measuring Changes in International Business Cycles.pdf:pdf},
journal = {Federal Reserve Bank of New York Staff Reports},
keywords = {Bayesian factor models,G,time-varying parameters},
number = {326},
pages = {1--46},
title = {{Dynamic Factor Models with Time-Varying Parameters: Measuring Changes in International Business Cycles}},
url = {http://www.newyorkfed.org/research/staff{\_}reports/sr326.pdf{\%}5Cnpapers2://publication/uuid/170539DE-BB71-4AE2-82D2-40974713131A},
year = {2008}
}
@article{Rodriguez2010,
author = {Rodriguez, Abel and Puggioni, Gavino},
doi = {10.1016/j.ijforecast.2010.01.009},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rodriguez, Puggioni - 2010 - Mixed Frequency Models Bayesian Approaches to Estimation and Prediction.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {gross national product,interest rates,mixed frequency data,model averaging,model selection},
month = {apr},
number = {2},
pages = {293--311},
publisher = {Elsevier B.V.},
title = {{Mixed Frequency Models: Bayesian Approaches to Estimation and Prediction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207010000154},
volume = {26},
year = {2010}
}
@article{Hepenstrick2016a,
author = {Hepenstrick, Christian and Marcellino, Massimiliano},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hepenstrick, Marcellino - 2016 - Forecasting with Large Unbalanced Datasets The Mixed Frequency Three-Pass Regression Filter.pdf:pdf},
journal = {Working Paper},
keywords = {Dynamic Factor Models,GDP Nowcas,Mixed Frequency},
title = {{Forecasting with Large Unbalanced Datasets: The Mixed Frequency Three-Pass Regression Filter}},
year = {2016}
}
@article{Colombier2011,
author = {Colombier, Carsten},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Colombier - 2011 - Konjunktur und Wachstum Teil I Eine Betrachtung aus theoretischer Sicht.pdf:pdf},
number = {16},
title = {{Konjunktur und Wachstum Teil I Eine Betrachtung aus theoretischer Sicht}},
year = {2011}
}
@article{Otrok2001,
abstract = {Lucas (Models of Business Cycles, Basil Blackwell, New York, 1987) argues that the gain from eliminating aggregate fluctuations is trivial. However, a number of researchers have altered assumptions on preferences and found that the gain from eliminating business cycles is potentially very large. This paper estimates the welfare cost of business cycles, allowing for potential time-non-separabilities in preferences, where discipline is placed on the choice of preference parameters by requiring that preferences be consistent with observed fluctuations in a general equilibrium model of business cycles. The estimates of the non-separability parameters are very different than the forms used elsewhere, leading to a small welfare cost of business cycles.},
author = {Otrok, Christopher},
doi = {10.1016/S0304-3932(00)00052-0},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Otrok - 2001 - On measuring the welfare cost of business cycles.pdf:pdf},
isbn = {0304-3932},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {Business cycles,E32,Non-separable preferences},
number = {1},
pages = {61--92},
title = {{On measuring the welfare cost of business cycles}},
volume = {47},
year = {2001}
}
@article{Sarferaz2016,
abstract = {Recent studies using long-run restrictions question the valid- ity of the technology-driven real business cycle hypothesis. We propose an alternative identification that maximizes the contribution of technology shockstotheforecast-errorvarianceoflaborproductivityatalongbutfinite horizon. In small-sample Monte Carlo experiments, our identification out- performs standard long-run restrictions by significantly reducing the bias in the short-run impulse responses and raising their estimation precision. Unlike its long-run restriction counterpart, when our Max Share identifica- tion technique is applied to U.S. data, it delivers the robust result that hours worked responds negatively to positive technology shocks.},
author = {Ritschl, Albrecht and Sarferaz, Samad and Uebele, Martin},
doi = {10.1162/REST},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ritschl, Sarferaz, Uebele - 2016 - The U.S. Business Cycle, 1867–2006 A Dynamic Factor Approach.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {1},
pages = {159--172},
pmid = {21860536},
title = {{The U.S. Business Cycle, 1867–2006: A Dynamic Factor Approach}},
volume = {98},
year = {2016}
}
@book{Graham1934,
author = {Graham, Benjamin and Dodd, David L.},
edition = {6. Edition},
pages = {1--700},
publisher = {McGraw-Hill},
title = {{Security Analysis}},
year = {1934}
}
@article{Morley2011,
abstract = {The Beveridge-Nelson decomposition calculates trend and cycle for an integrated time series. However, there are two ways to interpret the results from the decomposition. One interpretation is that the optimal long-run forecast (minus any deterministic drift) used to calculate the Beveridge-Nelson trend corresponds to an estimate of an unobserved permanent component. The other interpretation is that the optimal long-run forecast defines an observable permanent component. This paper examines some issues surrounding these two interpretations and provides empirical support for interpreting the Beveridge- Nelson trend as an estimate when considering macroeconomic data.},
author = {Morley, James C.},
doi = {10.1017/S1365100510000118},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Morley - 2011 - The two interpretations of the Beveridge-Nelson decomposition.pdf:pdf},
isbn = {1365100510},
issn = {13651005},
journal = {Macroeconomic Dynamics},
keywords = {Beveridge-Nelson Decomposition,State-Space Models,Trend/cycle Decomposition,Unobserved-Components Models},
number = {3},
pages = {419--439},
title = {{The two interpretations of the Beveridge-Nelson decomposition}},
volume = {15},
year = {2011}
}
@article{Caverzasi2015,
author = {Caverzasi, E. and Godin, A.},
doi = {10.1093/cje/beu021},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Caverzasi, Godin - 2015 - Post-Keynesian Stock-Flow-Consistent Modelling A Survey.pdf:pdf},
issn = {0309-166X},
journal = {Cambridge Journal of Economics},
keywords = {1,a relatively new family,b5,c69,e12,jel classifications,literature review,of,post-keynesian,recent post-keynesian literature has,stock-flow consistent,stock-flow-consistent models,witnessed the rise of},
number = {1},
pages = {157--187},
title = {{Post-Keynesian Stock-Flow-Consistent Modelling: A Survey}},
url = {http://cje.oxfordjournals.org/cgi/doi/10.1093/cje/beu021},
volume = {39},
year = {2015}
}
@article{Fama2006,
author = {Fama, Eugene F. and French, Kenneth R.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama, French - 2006 - The Value Premium and the CAPM.pdf:pdf},
journal = {Journal of Finance},
number = {5},
pages = {2163--2186},
title = {{The Value Premium and the CAPM}},
volume = {61},
year = {2006}
}
@article{Kendall1953,
author = {Kendall, Maurice G.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kendall - 1953 - The Analysis of Economic Time Series - Part I Prices.pdf:pdf},
journal = {Journal of the Royal Statistical Society},
number = {1},
pages = {11--34},
title = {{The Analysis of Economic Time Series - Part I: Prices}},
volume = {116},
year = {1953}
}
@article{Benes2010,
author = {Benes, J. and Clinton, K. and Garcia-Saltos, R. and Johnson, M. and Laxton, D. and Manchev, P. and Matheson, T.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Benes et al. - 2010 - Estimating potential output with a multivariate filter.pdf:pdf},
journal = {IMF Working Papers},
keywords = {author,cyclical government deficits,fiscal policy,government debt,inflation,monetary policy,output gap,potential output,s e-mail address,structural government deficits,unemployment},
title = {{Estimating potential output with a multivariate filter}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1751398},
volume = {285},
year = {2010}
}
@article{Bikker2002,
author = {Bikker, Jacob A. and Hu, Haixia},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bikker, Hu - 2002 - Cyclical Patterns in Profits, Provisioning and Lending of Banks and Procyclicality of the New Basel Capital Requirem.pdf:pdf},
journal = {BNL Quarterly Review},
number = {221},
pages = {143--175},
title = {{Cyclical Patterns in Profits, Provisioning and Lending of Banks and Procyclicality of the New Basel Capital Requirements}},
volume = {55},
year = {2002}
}
@article{Geweke2012,
abstract = {The assumption that one of a set of prediction models is a literal description of reality formally underlies many formal econometric methods, including Bayesian model averaging and most approaches to model selection. Prediction pooling does not invoke this assumption and leads to predictions that improve on those based on Bayesian model averaging, as assessed by the log predictive score. The paper shows that the improvement is substantial using a pool consisting of a dynamic stochastic general equilibrium model, a vector autoregression, and a dynamic factor model, in conjunction with standard US postwar quarterly macroeconomic time series. [ABSTRACT FROM AUTHOR]},
author = {Geweke, John and Amisano, Gianni},
doi = {10.1257/aer.102.3.482},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Geweke, Amisano - 2012 - Prediction with misspecified models.pdf:pdf},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {3},
pages = {482--486},
title = {{Prediction with misspecified models}},
volume = {102},
year = {2012}
}
@article{Output,
author = {Kichian, Maral},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kichian - 1999 - Measuring Potential Output within a State-Space Framework.pdf:pdf},
journal = {Bank of Canada Working Paper},
title = {{Measuring Potential Output within a State-Space Framework}},
volume = {9},
year = {1999}
}
@article{Change2015,
abstract = {In this paper, we propose a time-varying parameter VAR model with stochastic volatility which allows for estimation on data sampled at different frequencies. Our contribution is two- fold. First, we extend the methodology developed by Cogley and Sargent (2005), and Primiceri (2005), to a mixed-frequency setting. In particular, our approach allows for the inclusion of two different categories of variables (high-frequency and low-frequency) into the same time varying model. Second, we use this model to study the macroeconomic effects of government spending shocks in Italy over the 1988Q4-2013Q3 period. Italy - as well as most other euro area economies - is characterised by short quarterly time series for fiscal variables, whereas annual data are generally available for a longer sample before 1999. Our results show that the proposed time- varying mixed-frequency model improves on the performance of a simple linear interpolation model in generating the true path of the missing observations. Second, our empirical analysis suggests that government spending shocks tend to have positive effects on output in Italy. The fiscal multiplier, which is maximized at the one year horizon, follows a U-shape over the sample considered: it peaks at around 1.5 at the beginning of the sample, it then stabilizes between 0.8 and 0.9 from the mid-1990s to the late 2000s, before rising again to above unity during of the recent crisis.},
author = {Cimadomo, Jacopo and D'Agostino, Antonello},
doi = {10.2866/991811},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Cimadomo, D'Agostino - 2015 - Combining time-variation and mixed-frequencies an analysis of government spending multipliers in Italy.pdf:pdf},
journal = {European Central Bank, Working Paper},
keywords = {Time variation,government s,mixed-frequency data},
number = {October},
title = {{Combining time-variation and mixed-frequencies: an analysis of government spending multipliers in Italy}},
url = {https://ideas.repec.org/s/ecb/ecbwps.html.},
volume = {1856},
year = {2015}
}
@article{Aspris2013,
author = {Aspris, Angelo and Finch, Nigel and Foley, Sean and Meyer, Zachary},
doi = {10.1111/auar.12038},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Aspris et al. - 2013 - Fundamental-based Market Strategies.pdf:pdf},
issn = {10356908},
journal = {Australian Accounting Review},
month = {dec},
number = {4},
pages = {380--392},
title = {{Fundamental-based Market Strategies}},
url = {http://doi.wiley.com/10.1111/auar.12038},
volume = {23},
year = {2013}
}
@article{Phillips2015,
abstract = {We analyze trend elimination methods and business cycle estimation by data {\ldots}ltering of the type introduced by Whittaker (1923) and popularized in eco-nomics in a particular form by Hodrick and Prescott (1980/1997; HP). A limit theory is developed for the HP {\ldots}lter for various classes of stochastic trend, trend break, and trend stationary data. Properties of the {\ldots}ltered series are shown to depend closely on the choice of the smoothing parameter (For instance, when = O(n 4) where n is the sample size, and the HP {\ldots}lter is applied to an I(1) process, the {\ldots}lter does not remove the stochastic trend in the limit as n ! 1. Instead, the {\ldots}lter produces a smoothed Gaussian limit process that is di¤erentiable to the 4'th order. The residual 'cyclical' process has the ran-dom wandering non-di¤erentiable characteristics of Brownian motion, thereby explaining the frequently observed 'spurious cycle' e¤ect of the HP {\ldots}lter. On the other hand, when = o(n); the {\ldots}lter reproduces the limit Brownian motion and eliminates the stochastic trend giving a zero 'cyclical'process. Simulations reveal that the = O(n 4) limit theory provides a good approximation to the actual HP {\ldots}lter for sample sizes common in practical work. When it is used as a trend removal device, the HP {\ldots}lter therefore typically fails to eliminate stochas-tic trends, contrary to what is now standard belief in applied macroeconomics. The {\ldots}ndings are related to recent public debates about the long run e¤ects of the global {\ldots}nancial crisis.},
author = {Phillips, Peter C B and Jin, Sainan},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Phillips, Jin - 2015 - Business Cycles, Trend Elimination, and the HP Filter.pdf:pdf},
journal = {Cowles Foundation Discussion Paper},
keywords = {Detrending,Graduation,Hodrick Prescott {\ldots}lter,Integrated process,Limit theory,Smoothing,Trend break,Whittaker {\ldots}lter},
title = {{Business Cycles, Trend Elimination, and the HP Filter}},
url = {http://cowles.econ.yale.edu/},
volume = {2005},
year = {2015}
}
@article{Boivin2006a,
abstract = {Factors estimated from large macroeconomic panels are being used in an increasing number of applications. However, little is known about how the size and the composition of the data affect the factor estimates. In this paper, we question whether it is possible to use more series to extract the factors, and yet the resulting factors are less useful for forecasting, and the answer is yes. Such a problem tends to arise when the idiosyncratic errors are cross-correlated. It can also arise if forecasting power is provided by a factor that is dominant in a small dataset but is a dominated factor in a larger dataset. In a real time forecasting exercise, we find that factors extracted from as few as 40 pre-screened series often yield satisfactory or even better results than using all 147 series. Weighting the data by their properties when constructing the factors also lead to improved forecasts. Our simulation analysis is unique in that special attention is paid to cross-correlated idiosyncratic errors, and we also allow the factors to have stronger loadings on some groups of series than others. It thus allows us to better understand the properties of the principal components estimator in empirical applications. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Boivin, Jean and Ng, Serena},
doi = {10.1016/j.jeconom.2005.01.027},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Boivin, Ng - 2006 - Are more data always better for factor analysis.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Factor models,Forecasting,Large N and T,Principal components},
number = {1},
pages = {169--194},
title = {{Are more data always better for factor analysis?}},
volume = {132},
year = {2006}
}
@article{Bai2017,
abstract = {It is known that the common factors in a large panel of data can be consistently estimated by the method of principal components, and principal components can be constructed by iterative least squares regressions. Replacing least squares with ridge regressions turns out to have the effect of shrinking the singular values of the common component and possibly reducing its rank. The method is used in the machine learning literature to recover low-rank matrices. We study the procedure from the perspective of estimating a minimum-rank approximate factor model. We show that the constrained factor estimates are biased but can be more efficient in terms of mean-squared errors. Rank consideration suggests a data-dependent penalty for selecting the number of factors. The new criterion is more conservative in cases when the nominal number of factors is inflated by the presence of weak factors or large measurement noise. The framework is extended to incorporate a priori linear constraints on the loadings. We provide asymptotic results that can be used to test economic hypotheses.},
archivePrefix = {arXiv},
arxivId = {1708.08137},
author = {Bai, Jushan and Ng, Serena},
eprint = {1708.08137},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bai, Ng - 2017 - Principal Components and Regularized Estimation of Factor Models.pdf:pdf},
keywords = {low rank decomposi-,robust principal components,singular-value thresholding},
title = {{Principal Components and Regularized Estimation of Factor Models}},
url = {http://arxiv.org/abs/1708.08137},
volume = {1658770},
year = {2017}
}
@article{Banbura2014,
abstract = {In this paper we propose a methodology to estimate a dynamic factor model on data sets with an arbitrary pattern of missing data. We modify the Expectation Maximisation (EM) algorithm as proposed for a dynamic factor model by Watson and Engle (1983) to the case with general pattern of missing data. We also extend the model to the case with serially correlated idiosyncratic component. The framework allows to handle efficiently and in an automatic manner sets of indicators characterized by different publication delays, frequencies and sample lengths. This can be relevant e.g. for young economies for which many indicators are compiled only since recently. We also show how to extract a model based news from a statistical data release within our framework and we derive the relationship between the news and the resulting forecast revision. This can be used for interpretation in e.g. nowcasting applications as it allows to determine the sign and size of a news as well as its contribution to the revision, in particular in case of simultaneous data releases. We evaluate the methodology in a Monte Carlo experiment and we apply it to nowcasting and backdating of euro area GDP.},
archivePrefix = {arXiv},
arxivId = {1099-1255},
author = {Ba{\'{n}}bura, Marta and Modugno, Michele},
doi = {10.1002/jae.2306},
eprint = {1099-1255},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ba{\'{n}}bura, Modugno - 2014 - Maximum likelihood estimation of factor models on datasets with arbitrary pattern of missing data.pdf:pdf},
isbn = {1099-1255},
issn = {08837252},
journal = {Journal of Applied Econometrics},
keywords = {Factor Models, Forecasting, Large Cross-Sections,},
number = {1},
pages = {133--160},
pmid = {15003161},
title = {{Maximum likelihood estimation of factor models on datasets with arbitrary pattern of missing data}},
volume = {29},
year = {2014}
}
@article{Barberis1998,
abstract = {Recent empirical research in finance has uncovered two families of pervasive regularities: underreaction of stock prices to news such as earnings announcements, and overreaction of stock prices to a series of good or bad news. In this paper, we present a parsimonious model of investor sentiment, or of how investors form beliefs, which is consistent with the empirical findings. The model is based on psychological evidence and produces both underreaction and overreaction for a wide range of parameter values.},
author = {Barberis, Nicholas and Shleifer, Andrei and Vishny, Robert},
doi = {http://dx.doi.org/10.1016/S0304-405X(98)00027-0},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Barberis, Shleifer, Vishny - 1998 - A Model of Investor Sentiment.pdf:pdf},
isbn = {0304-405X},
issn = {0304-405X},
journal = {Journal of Financial Economics},
keywords = {Investor sentiment,Overreaction,Underreaction,investor sentiment,overreaction,underreaction},
number = {3},
pages = {307--343},
title = {{A Model of Investor Sentiment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304405X98000270{\%}5Cnhttp://www.sciencedirect.com/science/article/pii/S0304405X98000270},
volume = {49},
year = {1998}
}
@article{Lucas2003,
author = {Lucas, Robert E.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lucas - 2003 - Macroeconomic Priorities †.pdf:pdf},
journal = {American Economic Review},
number = {1},
pages = {1--13},
title = {{Macroeconomic Priorities †}},
volume = {93},
year = {2003}
}
@article{Clark2011,
abstract = {Central banks and other forecasters are increasingly interested in various aspects of density forecasts. However, recent sharp changes in macroeconomic volatility, including the Great Moderation and the more recent sharp rise in volatility associated with increased variation in energy prices and the deep global recession?pose significant challenges to density forecasting. Accordingly, this paper examines, with real-time data, density forecasts of U.S. GDP growth, unemployment, inflation, and the federal funds rate from Bayesian vector autoregression (BVAR) models with stochastic volatility. The results indicate that adding stochastic volatility to BVARs materially improves the real-time accuracy of density forecasts. This article has supplementary material online.$\backslash$nCentral banks and other forecasters are increasingly interested in various aspects of density forecasts. However, recent sharp changes in macroeconomic volatility, including the Great Moderation and the more recent sharp rise in volatility associated with increased variation in energy prices and the deep global recession?pose significant challenges to density forecasting. Accordingly, this paper examines, with real-time data, density forecasts of U.S. GDP growth, unemployment, inflation, and the federal funds rate from Bayesian vector autoregression (BVAR) models with stochastic volatility. The results indicate that adding stochastic volatility to BVARs materially improves the real-time accuracy of density forecasts. This article has supplementary material online.},
author = {Clark, Todd E.},
doi = {10.1198/jbes.2010.09248},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Clark - 2011 - Real-Time Density Forecasts From Bayesian Vector Autoregressions With Stochastic Volatility.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {bayesian methods,steady-state prior},
number = {3},
pages = {327--341},
title = {{Real-Time Density Forecasts From Bayesian Vector Autoregressions With Stochastic Volatility}},
volume = {29},
year = {2011}
}
@article{Schumacher2008,
abstract = {This paper discusses a factor model for short-term forecasting of GDP growth using a large number of monthly and quarterly time series in real-time. To take into account the different periodicities of the data and missing observations at the end of the sample, the factors are estimated by applying an EM algorithm, combined with a principal components estimator. We discuss some in-sample properties of the estimator in a real-time environment and propose alternative methods for forecasting quarterly GDP with monthly factors. In the empirical application, we use a novel real-time dataset for the German economy. Employing a recursive forecast experiment, we evaluate the forecast accuracy of the factor model with respect to German GDP. Furthermore, we investigate the role of revisions in forecast accuracy and assess the contribution of timely monthly observations to the forecast performance. Finally, we compare the performance of the mixed-frequency model with that of a factor model, based on time-aggregated quarterly data. ?? 2008 International Institute of Forecasters.},
author = {Schumacher, Christian and Breitung, J{\"{o}}rg},
doi = {10.1016/j.ijforecast.2008.03.008},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Schumacher, Breitung - 2008 - Real-time forecasting of German GDP based on a large factor model with monthly and quarterly data.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {C53,E37,EM algorithm,Factor models,Forecasting,GDP,Principal components},
number = {3},
pages = {386--398},
title = {{Real-time forecasting of German GDP based on a large factor model with monthly and quarterly data}},
volume = {24},
year = {2008}
}
@article{Lewellen2002,
abstract = {This article studies momentum in stock returns, focusing on the role of industry, size, and book-to-market (B/M) factors. Size and B/M portfolios exhibit momentum as strong as that in individual stocks and industries. The size and B/M portfolios are well diversified, so momentum cannot be attributed to firm- or industry-specific returns. Further, industry, size, and B/M portfolios are negatively autocorrelated and cross-serially correlated over intermediate horizons. The evidence suggests that stocks covary “too strongly” with each other. I argue that excess covariance, not underreaction, explains momentum in the portfolios.},
author = {Lewellen, Jonathan},
doi = {10.1093/rfs/15.2.533},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lewellen - 2002 - Momentum and Autocorrelation in Stock Returns.pdf:pdf},
isbn = {08939454},
issn = {14657368},
journal = {Review of Financial Studies},
number = {2},
pages = {533--563},
title = {{Momentum and Autocorrelation in Stock Returns}},
url = {http://rfs.oupjournals.org/cgi/doi/10.1093/rfs/15.2.533},
volume = {15},
year = {2002}
}
@article{Assmann2016,
abstract = {Due to their indeterminacies, static and dynamic factor models require identifying assumptions to guarantee uniqueness of the parameter estimator. The indeterminacy of the parameter estimator with respect to an orthogonal transformation is known as the rotation problem. The typical strategy in Bayesian factor analysis to solve the rotation problem is to introduce ex-ante constraints on certain model parameters via degenerate and truncated prior distributions. This strategy, however, results in posterior distributions whose shapes depend on the ordering of the variables in the data set. We propose an alternative approach where the rotation problem is solved ex-post using Procrustean postprocessing. The resulting order invariance of the posterior estimator is illustrated in a simulation study and an empirical application using an established data set containing 120 macroeconomic time series. Favorable properties of the ex-post approach with respect to convergence, statistical and numerical accuracy are revealed.},
author = {A{\ss}mann, Christian and Boysen-Hogrefe, Jens and Pape, Markus},
doi = {10.1016/j.jeconom.2015.10.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/A{\ss}mann, Boysen-Hogrefe, Pape - 2016 - Bayesian analysis of static and dynamic factor models An ex-post approach towards the rotation pro.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Bayesian estimation,Factor models,Multimodality,Ordering problem,Orthogonal transformation,Rotation problem},
number = {1},
pages = {190--206},
publisher = {Elsevier B.V.},
title = {{Bayesian analysis of static and dynamic factor models: An ex-post approach towards the rotation problem}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.10.010},
volume = {192},
year = {2016}
}
@article{Henkel2011,
author = {Henkel, Sam James and Martin, J. Spencer and Nardari, Federico},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Henkel, Martin, Nardari - 2011 - Time-Varying Short-Horizon Predictability.pdf:pdf},
journal = {Journal of Financial Economics},
keywords = {asset pricing,at the kelley school,business fluctuations,e32,e44,economy,financial,g11,g12,indiana university and a,jel codes,markets and the macro,of business,portfolio choice,sam james henkel is,stock return predictability,univer-,visiting scholar at the},
number = {3},
pages = {560--580},
title = {{Time-Varying Short-Horizon Predictability}},
volume = {99},
year = {2011}
}
@article{Guhaniyogi2015,
abstract = {As an alternative to variable selection or shrinkage in high dimensional regression, we propose to randomly compress the predictors prior to analysis. This dramatically reduces storage and computational bottlenecks, performing well when the predictors can be projected to a low dimensional linear subspace with minimal loss of information about the response. As opposed to existing Bayesian dimensionality reduction approaches, the exact posterior distribution conditional on the compressed data is available analytically, speeding up computation by many orders of magnitude while also bypassing robustness issues due to convergence and mixing problems with MCMC. Model averaging is used to reduce sensitivity to the random projection matrix, while accommodating uncertainty in the subspace dimension. Strong theoretical support is provided for the approach by showing near parametric convergence rates for the predictive density in the large p small n asymptotic paradigm. Practical performance relative to competitors is illustrated in simulations and real data applications.},
archivePrefix = {arXiv},
arxivId = {1303.0642},
author = {Guhaniyogi, Rajarshi and Dunson, David B.},
doi = {10.1080/01621459.2014.969425},
eprint = {1303.0642},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Guhaniyogi, Dunson - 2015 - Bayesian Compressed Regression.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Compressed sensing,Data compression,Dimensionality reduction,Large p, small n,Random projection,Sparsity,Sufficient dimension reduction},
number = {512},
pages = {1500--1514},
title = {{Bayesian Compressed Regression}},
volume = {110},
year = {2015}
}
@article{Fama1998a,
abstract = {Market efficiency survives the challenge from the literature on long-term return anomalies. Consistent with the market efficiency hypothesis that the anomalies are chance results, apparent overreaction to information is about as common as underreaction, and post-event continuation of pre-event abnormal returns is about as frequent as post-event reversal. Most important, consistent with the market efficiency prediction that apparent anomalies can be due to methodology, most long-term return anomalies tend to disappear with reasonable changes in technique.},
author = {Fama, Eugene F.},
doi = {10.1016/S0304-405X(98)00026-9},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama - 1998 - Market Efficiency, Long-Term Returns, and Behavioral Finance.pdf:pdf},
isbn = {0304405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Behavioral finance,Market efficiency},
number = {3},
pages = {283--306},
pmid = {12134001},
title = {{Market Efficiency, Long-Term Returns, and Behavioral Finance}},
url = {http://www.sciencedirect.com/science/article/B6VBX-408CBS1-1/2/79aebf2e4704c12e3799ea68c99df505},
volume = {49},
year = {1998}
}
@article{Forni2016,
author = {Forni, Mario and Giovannelli, Alessandro and Lippi, Marco and Soccorsi, Stefano},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Forni et al. - 2016 - Dynamic Factor Model with Infinite Dimensional Factor Space Forecasting.pdf:pdf},
number = {March},
title = {{Dynamic Factor Model with Infinite Dimensional Factor Space: Forecasting}},
year = {2016}
}
@article{Andrews1991,
author = {Andrews, Donald W. K.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Andrews - 1991 - Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation.pdf:pdf},
journal = {Econometrica},
number = {3},
pages = {817--858},
title = {{Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation}},
volume = {59},
year = {1991}
}
@article{Lo2000a,
abstract = {Technical analysis, also known as “charting,” has been a part of financial practice for many decades, but this discipline has not received the same level of academic scrutiny and acceptance as more traditional approaches such as fundamental analy- sis. One of the main obstacles is the highly subjective nature of technical analy- sis—the presence of geometric shapes in historical price charts is often in the eyes of the beholder. In this paper, we propose a systematic and automatic approach to technical pattern recognition using nonparametric kernel regression, and we apply this method to a large number of U.S. stocks from 1962 to 1996 to evaluate the effectiveness of technical analysis. By comparing the unconditional empirical distribution of daily stock returns to the conditional distribution—conditioned on specific technical indicators such as head-and-shoulders or double-bottoms—we find that over the 31-year sample period, several technical indicators do provide incremental information and may have some practical value.},
author = {Lo, Andrew W. and Mamaysky, Harry and Wang, Jiang},
doi = {10.1111/0022-1082.00265},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lo, Mamaysky, Wang - 2000 - Foundations of Technical Analysis Computational Algorithms, Statistical Inference, and Empirical Implementat.pdf:pdf},
isbn = {1540-6261},
issn = {0022-1082},
journal = {The Journal of Finance},
number = {4},
pages = {1705--1770},
pmid = {19724231},
title = {{Foundations of Technical Analysis: Computational Algorithms, Statistical Inference, and Empirical Implementation}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/0022-1082.00265/abstract{\%}5Cnhttp://doi.wiley.com/10.1111/0022-1082.00265},
volume = {55},
year = {2000}
}
@article{Chan2003,
abstract = {Using a comprehensive database of headlines about individual companies, I examine monthly returns following public news. I compare them to stocks with similar returns, but no identifiable public news. There is a difference between the two sets. I find strong drift after bad news. Investors seem to react slowly to this information. I also find reversal after extreme price movements unaccompanied by public news. The separate patterns appear even after adjustments for risk exposure and other effects. They are, however, mainly seen in smaller, more illiquid stocks. These findings support some integrated theories of investor over- and underreaction. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Chan, Wesley C.},
doi = {10.1016/S0304-405X(03)00146-6},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chan - 2003 - Stock Price Reaction to News and No-News Drift and Reversal After Headlines.pdf:pdf},
isbn = {0304-405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Information diffusion,Momentum strategies,News},
number = {2},
pages = {223--260},
title = {{Stock Price Reaction to News and No-News: Drift and Reversal After Headlines}},
volume = {70},
year = {2003}
}
@article{Beveridge1981,
abstract = {This paper introduces a general procedure for decomposition of non-stationary time series into a permanent and transitory component allowing both components to be stochastic. The permanent component is shown to be a random walk with drift and the transitory or cyclical component is a stationary process with mean zero. The decomposition methodology, which depends only on past data and therefore is computable in 'real time', is applied to the problem of measuring and dating business 'cycles' in the portwar U.S. economy. We find that measured expansions and contractions are of roughly equivalent duration and that our dating of cyclical episodes tends to lead the traditional NBER dating and, to a lesser extent, the 'growth cycle' chronology of Zarnowitz and Boschan (1977). {\textcopyright} 1981.},
author = {Beveridge, Stephen and Nelson, Charles R.},
doi = {10.1016/0304-3932(81)90040-4},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Beveridge, Nelson - 1981 - A new approach to decomposition of economic time series into permanent and transitory components with particu.pdf:pdf},
isbn = {0304-3932},
issn = {03043932},
journal = {Journal of Monetary Economics},
number = {2},
pages = {151--174},
pmid = {12456},
title = {{A new approach to decomposition of economic time series into permanent and transitory components with particular attention to measurement of the 'business cycle'}},
volume = {7},
year = {1981}
}
@article{Interaction2008,
author = {Bai, Jushan and Wang, Peter},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bai, Wang - 2008 - Identification and Estimation of Dynamic Factor Models.pdf:pdf},
journal = {Business},
number = {8225},
title = {{Identification and Estimation of Dynamic Factor Models}},
year = {2008}
}
@book{Stock2016,
abstract = {This chapter provides an overview of and user's guide to dynamic factor models (DFMs), their estimation, and their uses in empirical macroeconomics. It also surveys recent developments in methods for identifying and estimating SVARs, an area that has seen important developments over the past 15 years. The chapter begins by introducing DFMs and the associated statistical tools, both parametric (state-space forms) and nonparametric (principal components and related methods). After reviewing two mature applications of DFMs, forecasting and macroeconomic monitoring, the chapter lays out the use of DFMs for analysis of structural shocks, a special case of which is factor-augmented vector autoregressions (FAVARs). A main focus of the chapter is how to extend methods for identifying shocks in structural vector autoregression (SVAR) to structural DFMs. The chapter provides a unification of SVARs, FAVARs, and structural DFMs and shows both in theory and through an empirical application to oil shocks how the same identification strategies can be applied to each type of model.},
author = {Stock, J. H. and Watson, M. W.},
booktitle = {Handbook of Macroeconomics},
doi = {10.1016/bs.hesmac.2016.04.002},
edition = {1},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2016 - Dynamic Factor Models, Factor-Augmented Vector Autoregressions, and Structural Vector Autoregressions in Macroeco.pdf:pdf},
isbn = {9780444594877},
issn = {15740048},
keywords = {Factor-augmented vector autoregressions,Large-model forecasting,Nowcasting,Principal components,State-space models,Structural shocks,Structural vector autoregressions},
pages = {415--525},
publisher = {Elsevier B.V.},
title = {{Dynamic Factor Models, Factor-Augmented Vector Autoregressions, and Structural Vector Autoregressions in Macroeconomics}},
url = {http://dx.doi.org/10.1016/bs.hesmac.2016.04.002},
volume = {2},
year = {2016}
}
@article{Malkiel2003a,
abstract = {This paper presents the case for and the evidence in favour of passive investment strategies and examines the major criticisms of the technique. I conclude that the evidence strongly supports passive investment management in all markets—small- capitalisation stocks as well as large-capitalisation equities, US markets as well as international markets, and bonds as well as stocks. Recent attacks on the efficient market hypothesis do not weaken the case for indexing.},
author = {Malkiel, Burton G.},
doi = {10.1111/1468-036X.00205},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Malkiel - 2003 - Passive Investment Strategies and Efficient Markets.pdf:pdf},
issn = {1354-7798},
journal = {European Financial Management},
keywords = {efficient markets,g11,g14,jel classification,passive investment strategies},
number = {1},
pages = {1--10},
title = {{Passive Investment Strategies and Efficient Markets}},
url = {http://doi.wiley.com/10.1111/1468-036X.00205},
volume = {9},
year = {2003}
}
@article{Giannone2008,
abstract = {A formal method is developed for evaluating the marginal impact that intra-monthly data releases have on current-quarter forecasts (nowcasts) of real gross domestic product (GDP) growth. The method can track the real-time flow of the type of information monitored by central banks because it can handle large data sets with staggered data-release dates. Each time new data are released, the nowcasts are updated on the basis of progressively larger data sets that, reflecting the unsynchronized data-release dates, have a "jagged edge" across the most recent months. ?? 2008 Elsevier B.V.},
author = {Giannone, Domenico and Reichlin, Lucrezia and Small, David},
doi = {10.1016/j.jmoneco.2008.05.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Giannone, Reichlin, Small - 2008 - Nowcasting The Real-Time Informational Content of Macroeconomic Data.pdf:pdf},
isbn = {03043932},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {Factor model,Forecasting,Monetary policy,Nowcast,Real-time data},
number = {4},
pages = {665--676},
title = {{Nowcasting: The Real-Time Informational Content of Macroeconomic Data}},
volume = {55},
year = {2008}
}
@article{Ando2010,
abstract = {Computationally efficient simulation methods for hierarchical Bayesian analysis of the seemingly unrelated regression (SUR) and simultaneous equa- tions models (SEM) are proposed and applied. These methods combine a direct Monte Carlo (DMC) approach and an importance sampling procedure to calculate Bayesian estimation and prediction results, namely, Bayesian posterior densities for parameters, predictive densities for future values of variables and associated moments, intervals and other quantities. The results obtained by our approach are compared to those yielded by use of MCMC techniques. Finally, we show that our algorithm can be applied to the Bayesian analysis of state space models},
author = {Ando, Tomohiro and Zellner, Arnold},
doi = {10.1214/10-BA503},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ando, Zellner - 2010 - Hierarchical Bayesian analysis of the seemingly unrelated regression and simultaneous equations models using a co.pdf:pdf},
isbn = {9781424444410},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Bayesian estimation and prediction,Direct Monte Carlo,Hierarchical priors importance sampling,Markov Chain Monte Carlo},
number = {1},
pages = {65--96},
title = {{Hierarchical Bayesian analysis of the seemingly unrelated regression and simultaneous equations models using a combination of Direct Monte Carlo and importance sampling techniques}},
volume = {5},
year = {2010}
}
@article{Miess2016,
author = {Miess, Michael Gregor and Schmelzer, Stefan},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Miess, Schmelzer - 2016 - Stock-flow Consistent Modelling of Real-Financial Cycles and Balance Sheet Dynamics Institute for Advanced Stu.pdf:pdf},
keywords = {cycles,e12,e17,e32,e44,e61,e63,financial,financial fragility,financial regulation,forecasting,jel classification numbers,macroeconomic model,stock-flow consistent,sustainable growth},
number = {June},
title = {{Stock-flow Consistent Modelling of Real-Financial Cycles and Balance Sheet Dynamics Institute for Advanced Studies and Vienna University of Economics and Business}},
year = {2016}
}
@article{Fernandez-Villaverde2007,
abstract = {The dynamics of a linear (or linearized) dynamic stochastic economic model can be expressed in terms of matrices (A, B, C, D) that define a state space system for a vector of observables. An associated state space system (A, ˆ B,C, ˆD) determines a vector autoregression for those same observables. We present a simple condition for checking when these two state space systems match up and when they do not when there are equal numbers of economic and VAR shocks. We illustrate our condition with a permanent income example. JEL C32, E32) ABSTRACT FROM AUTHOR},
author = {Fern{\'{a}}ndez-Villaverde, Jes{\'{u}}s and Rubio-Ram{\'{i}}rez, Juan F. and Sargent, Thomas J. and Watson, Mark W.},
doi = {10.1257/aer.97.3.1021},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fern{\'{a}}ndez-Villaverde et al. - 2007 - ABCs (and Ds) of understanding VARs.pdf:pdf},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {3},
pages = {1021--1026},
pmid = {17746758},
title = {{ABCs (and Ds) of understanding VARs}},
volume = {97},
year = {2007}
}
@article{Borio2017,
abstract = {This paper argues that incorporating information about the financial cycle is important to improve measures of potential output and output gaps. Conceptually, identifying potential output with non-inflationary output is too restrictive. Potential output is seen as sustainable; yet experience indicates that output may be on an unsustainable path even if inflation is low and stable whenever financial imbalances are building up. More generally, as long as potential output is identified with the non-cyclical component of output fluctuations and financial factors play a key role in explaining the cyclical part, ignoring these factors leaves out valuable information. Within a simple and transparent framework, we show that including information about the financial cycle can yield measures of potential output and output gaps that are not only estimated more precisely, but also much more robust in real time. In the context of policy applications, such "finance-neutral" output gaps are shown to yield more reliable estimates of cyclically adjusted budget balances and to serve as complementary guides for monetary policy.},
author = {Borio, Claudio and Disyatat, Piti and Juselius, Mikael},
doi = {10.1093/oep/afw063},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Borio, Disyatat, Juselius - 2017 - Rethinking potential output Embedding information about the financial cycle.pdf:pdf},
issn = {14643812},
journal = {Oxford Economic Papers},
number = {3},
pages = {655--677},
title = {{Rethinking potential output: Embedding information about the financial cycle}},
volume = {69},
year = {2017}
}
@book{Graham1949,
author = {Graham, Benjamin},
edition = {4th},
pages = {1--591},
publisher = {Harper Business},
title = {{The Intelligent Investor}},
year = {1949}
}
@article{Jegadeesh1993,
author = {Jegadeesh, Narasimhan and Titman, Sheridan},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jegadeesh, Titman - 1993 - Returns to Buying Winners and Selling Losers Implications for Stock Market Efficiency.pdf:pdf},
journal = {Journal of Finance},
number = {1},
pages = {65--91},
title = {{Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency}},
volume = {48},
year = {1993}
}
@article{Chan2004,
author = {Chan, Louis K. C. and Lakonishok, Josef},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chan, Lakonishok - 2004 - Value and Growth Investing Review and Update.pdf:pdf},
journal = {Financial Analysts Journal},
number = {1},
pages = {71--86},
title = {{Value and Growth Investing: Review and Update}},
volume = {60},
year = {2004}
}
@article{Fama1970,
abstract = {N/A},
author = {Fama, Eugene F.},
doi = {10.1111/j.1540-6261.1970.tb00518.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama - 1970 - Efficient Capital Markets A Review of Theory and Empirical Work.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
number = {2},
pages = {383--417},
pmid = {19724231},
title = {{Efficient Capital Markets: A Review of Theory and Empirical Work}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1970.tb00518.x/full},
volume = {25},
year = {1970}
}
@misc{Casleton2010,
author = {Casleton, Emily M.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Casleton - 2010 - Analysis of Bayesian Dynamic Linear Models.pdf:pdf},
pages = {1--16},
title = {{Analysis of Bayesian Dynamic Linear Models}},
year = {2010}
}
@article{Grassi2015,
abstract = {This paper deals with the estimation of monthly indicators of economic activity for the Euro area and its largest member countries that possess the following attributes: relevance, representativeness and timeliness. Relevance is determined by comparing our monthly indicators to the gross domestic product at chained volumes, as the most important measure of the level of economic activity. Representativeness is achieved by considering a very large number of (timely) time series of monthly indicators relating to the level of economic activity, providing a more or less complete coverage. The indicators are modelled using a large-scale parametric factor model. We discuss its specification and provide details of the statistical treatment. Computational efficiency is crucial for the estimation of large-scale parametric factor models of the dimension used in our application (considering about 170 series). To achieve it, we apply state-of-the-art state space methods that can handle temporal aggregation, and any pattern of missing values.},
author = {Grassi, Stefano and Proietti, Tommaso and Frale, Cecilia and Marcellino, Massimiliano and Mazzi, Gianluigi},
doi = {10.1016/j.ijforecast.2014.08.015},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Grassi et al. - 2015 - EuroMInd-C A disaggregate monthly indicator of economic activity for the Euro area and member countries.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Dynamic factor models,Index of coincident indicators,Multivariate state space models,Quarterly national accounts,Temporal disaggregation},
number = {3},
pages = {712--738},
publisher = {Elsevier B.V.},
title = {{EuroMInd-C: A disaggregate monthly indicator of economic activity for the Euro area and member countries}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2014.08.015},
volume = {31},
year = {2015}
}
@article{Horvath1998,
author = {Horvath, Michael},
doi = {10.1006/redy.1998.0028},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Horvath - 1998 - Cyclicality and Sectoral Linkages Aggregate Fluctuations from Independent Sectoral Shocks.pdf:pdf},
issn = {10942025},
journal = {Review of Economic Dynamics},
keywords = {aggregate fluctuations,comovement,input,sectoral interaction},
month = {oct},
number = {4},
pages = {781--808},
title = {{Cyclicality and Sectoral Linkages: Aggregate Fluctuations from Independent Sectoral Shocks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S109420259890028X},
volume = {1},
year = {1998}
}
@article{Bai2013a,
abstract = {We examine the relationship between Mi(xed) Da(ta) S(ampling) (MIDAS) regressions and the Kalman filter when forecasting with mixed frequency data. In general, state space models involve a system of equations, whereas MIDAS regressions involve a single equation. As a consequence, MIDAS regressions might be less efficient, but could also be less prone to parameter estimation error and/or specification errors. We examine how MIDAS regressions and Kalman filters match up under ideal circumstances, that is in population, and in cases where all the stochastic processes—low and high frequency—are correctly specified. We characterize cases where the MIDAS regression exactly replicates the steady state Kalman filter weights. We compare MIDAS and Kalman filter forecasts in population where the state space model is misspecified. We also compare MIDAS and Kalman filter forecasts in small samples. The paper concludes with an empirical application. Overall we find that the MIDAS and Kalman filter methods give similar ...},
author = {Bai, Jennie and Ghysels, Eric and Wright, Jonathan H.},
doi = {10.1080/07474938.2012.690675},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bai, Ghysels, Wright - 2013 - State Space Models and MIDAS Regressions.pdf:pdf},
issn = {0747-4938},
journal = {Econometric Reviews},
keywords = {C22,C52,Kalman filter,Mixed frequency data},
number = {7},
pages = {779--813},
title = {{State Space Models and MIDAS Regressions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07474938.2012.690675},
volume = {32},
year = {2013}
}
@article{Cheung2017,
abstract = {Previous assessments of nominal exchange rate determination, following Meese and Rogoff (1983) have focused upon a narrow set of models. Cheung et al. (2005) augmented the usual suspects with productivity based models, and "behavioral equilibrium exchange rate" models, and assessed performance at horizons of up to 5 years. In this paper, we further expand the set of models to include Taylor rule fundamentals, yield curve factors, and incorporate shadow rates and risk and liquidity factors. The performance of these models is compared against the random walk benchmark. The models are estimated in error correction and first-difference specifications. We examine model performance at various forecast horizons (1 quarter, 4 quarters, 20 quarters) using differing metrics (mean squared error, direction of change), as well as the " consistency " test of Cheung and Chinn (1998). No model consistently outperforms a random walk, by a mean squared error measure, although purchasing power parity does fairly well. Moreover, along a direction-of-change dimension, certain structural models do outperform a random walk with statistical significance. While one finds that these forecasts are cointegrated with the actual values of exchange rates, in most cases, the elasticity of the forecasts with respect to the actual values is different from unity. Overall, model/specification/currency combinations that work well in one period will not necessarily work well in another period},
author = {Cheung, Yin-Wong and Chinn, Menzie D and Pascual, Antonio Garcia and Zhang, Yi and Dedola, Luca and Ehrmann, Michael and Hartmann, Philipp and Mark, Nelson and Rossi, Barbara and {Ca 'zorzi}, Michele and West, Kenneth},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Cheung et al. - 2017 - Exchange Rate Prediction Redux New Models, New Data, New Currencies.pdf:pdf},
title = {{Exchange Rate Prediction Redux: New Models, New Data, New Currencies}},
url = {http://www.nber.org/papers/w23267},
year = {2017}
}
@article{Wickramasuriya2015,
abstract = {Large collections of time series often have aggregation constraints due to product or geographical hierarchies. The forecasts for the disaggregated series are usually required to add up exactly to the forecasts of the aggregated series, a constraint known as " aggregate consistency " . The combination forecasts proposed by Hyndman et al. (2011) are based on a Generalized Least Squares (GLS) estimator and require an estimate of the covariance matrix of the reconciliation errors (i.e., the errors that arise due to aggregate inconsistency). We show that this is impossible to estimate in practice due to identifiability conditions. We propose a new combination forecasting approach that incorporates the information from a full covariance matrix of forecast errors in obtaining a set of aggregate consistent forecasts. Our approach minimizes the mean squared error of the aggregate consistent forecasts across the en-tire collection of time series under the assumption of unbiasedness. The minimization problem has a closed form solution. We make this solution scalable by providing a computationally less demanding alternative representation. We evaluate the performance of the proposed method compared to alternative methods using a series of simulation designs which take into account various features of the collected time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that the proposed method works well with artificial and real data.},
author = {Wickramasuriya, Shanika L and Athanasopoulos, George and Hyndman, Rob J},
doi = {10.1080/01621459.2018.1448825},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Wickramasuriya, Athanasopoulos, Hyndman - 2018 - Forecasting hierarchical and grouped time series through trace minimization(2).pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Hierarchical time series,contemporaneous error correla-tion,forecasting,reconciliation,trace minimization},
publisher = {Taylor {\&} Francis},
title = {{Forecasting hierarchical and grouped time series through trace minimization}},
url = {https://www.monash.edu/business/econometrics-and-business-statistics/research/publications/ebs/wp15-15.pdf},
year = {2018}
}
@article{Sarferaz2009,
author = {Sarferaz, Samad},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sarferaz - 2009 - Essays on Business Cycle Analysis and Demography.pdf:pdf},
title = {{Essays on Business Cycle Analysis and Demography}},
year = {2009}
}
@article{Thaler1985,
abstract = {Research in experimental psychology suggests that, in violation of Bayes' rule, most people tend to "overreact" to unexpected and dramatic news events. This study of market efficiency investigates whether such behavior affects stock prices. The empirical evidence, based on CRSP monthly return data, is consistent with the overreaction hypothesis. Substantial weak form market inefficiencies are discovered. The results also shed new light on the January returns earned by prior "winners" and "losers." Portfolios of losers experience exceptionally large January returns as late as five years after portfolio formation.},
author = {Thaler, Richard and {De Bondt}, Werner F M},
doi = {10.1111/j.1540-6261.1985.tb05004.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Thaler, De Bondt - 1985 - Does the Stock Market Overreact.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
keywords = {Behavioral Finance},
number = {3},
pages = {793--805},
pmid = {4653695},
title = {{Does the Stock Market Overreact?}},
url = {http://www.jstor.org/stable/2327804{\%}5Cnhttp://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1985.tb05004.x/full},
volume = {40},
year = {1985}
}
@article{Conrad2012,
abstract = {We examine whether risk characteristics of stocks interact with return continuation and reversals. We find that a momentum portfolio whose winner stocks are chosen from high expected return securities, and whose loser stocks are chosen from low expected return securities, has significant momentum profits, but shows no evidence of subsequent reversals. In contrast, a momentum portfolio that buys low expected return winners and sells high expected return losers has no significant momentum but strong reversals. Overall, we find evidence that intermediate-horizon momentum and longer-horizon reversal patterns may not be linked. Our results have implications for several explanations of momentum profits.},
author = {Conrad, Jennifer S. and Yavuz, M. Deniz},
doi = {10.2139/ssrn.2011148},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Conrad, Yavuz - 2015 - Momentum and Reversal Does What Goes Up Always Come Down.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {behavioral finance,momentum,return predictability,reversal},
pages = {0--43},
title = {{Momentum and Reversal: Does What Goes Up Always Come Down?}},
url = {http://www.ssrn.com/abstract=2011148},
year = {2015}
}
@misc{Geweke1996,
abstract = {This article provides an exact Bayesian framework for analyzing the arbitrage pricing theory (APT). Based on the Gibbs sampler, we show how to obtain the exact posterior distributions for functions of interest in the factor model. In particular, we propose a measure of the APT pricing deviations and obtain its exact posterior distribution. Using monthly portfolio returns grouped by industry and market capitalization, we find that there is little improvement in reducing the pricing errors by including more factors beyond the first one.},
author = {Geweke, John and Zhou, Guofu},
booktitle = {Review of Financial Studies},
doi = {10.1093/rfs/9.2.557},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Geweke, Zhou - 1996 - Measuring the pricing error of the arbitrage pricing theory.pdf:pdf},
isbn = {0893-9454},
issn = {14657368},
number = {2},
pages = {557--587},
title = {{Measuring the pricing error of the arbitrage pricing theory}},
url = {http://rfs.oupjournals.org/cgi/doi/10.1093/rfs/9.2.557},
volume = {9},
year = {1996}
}
@article{Piotroski2001,
author = {Piotroski, Joseph D.},
doi = {10.2139/ssrn.249510},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Piotroski - 2001 - Value Investing The Use of Historical Financial Statement Information to Separate Winners from Losers.pdf:pdf},
issn = {1556-5068},
journal = {Journal of Accounting Research},
number = {Supplement 2000},
pages = {1--41},
title = {{Value Investing: The Use of Historical Financial Statement Information to Separate Winners from Losers}},
url = {http://www.ssrn.com/abstract=249510},
volume = {38},
year = {2001}
}
@article{Doz2011,
abstract = {This paper shows consistency of a two-step estimation of the factors in a dynamic approximate factor model when the panel of time series is large (n large). In the first step, the parameters of the model are estimated from an OLS on principal components. In the second step, the factors are estimated via the Kalman smoother. The analysis develops the theory for the estimator considered in Giannone et al. (2004) and Giannone et al. (2008) and for the many empirical papers using this framework for nowcasting. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Doz, Catherine and Giannone, Domenico and Reichlin, Lucrezia},
doi = {10.1016/j.jeconom.2011.02.012},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Doz, Giannone, Reichlin - 2011 - A two-step estimator for large approximate dynamic factor models based on Kalman filtering.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Factor models,Kalman filter,Large cross-sections,Principal components},
number = {1},
pages = {188--205},
pmid = {1262605},
publisher = {Elsevier B.V.},
title = {{A two-step estimator for large approximate dynamic factor models based on Kalman filtering}},
url = {http://dx.doi.org/10.1016/j.jeconom.2011.02.012},
volume = {164},
year = {2011}
}
@article{Lakonishok1992a,
abstract = {This paper uses new data on the holdings of 769 tax-exempt (predominantly pension) funds, to evaluate the potential effect of their trading on stock prices. We address two aspects of trading by these money managers: herding, which refers to buying (selling) simultaneously the same stocks as other managers buy (sell), and positive-feedback trading, which refers to buying past winners and selling past losers. These two aspects of trading are commonly a part of the argument that institutions destabilize stock prices. The evidence suggests that pension managers do not strongly pursue these potentially destabilizing practices.},
author = {Lakonishok, Josef and Shleifer, Andrei and Vishny, Robert W.},
doi = {10.1093/rfs/hhq137},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lakonishok, Shleifer, Vishny - 1992 - The Impact of Institutional Stock Prices.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
pages = {23--43},
title = {{The Impact of Institutional Stock Prices}},
volume = {32},
year = {1992}
}
@article{Barnett2014,
abstract = {Evidence from a large and growing body of empirical literature strongly suggests that there have been changes in the inflation and output dynamics in the United Kingdom. The majority of these papers base their results on a class of econometric models that allows for time-variation in the coefficients and volatilities of shocks. While these models have been used extensively for studying evolving dynamics and for structural analysis, there has been little evidence that they are useful for forecasting UK output growth and inflation. This paper attempts to fill this gap by comparing the performances of a wide range of time-varying parameter models in forecasting output growth and inflation. We find that allowing for time-varying parameters can lead to large and statistically significant gains in forecast accuracy. {\textcopyright} 2013 The Bank of England.},
author = {Barnett, Alina and Mumtaz, Haroon and Theodoridis, Konstantinos},
doi = {10.1016/j.ijforecast.2013.06.002},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Barnett, Mumtaz, Theodoridis - 2014 - Forecasting UK GDP growth and inflation under structural change. A comparison of models with time-.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecast comparison,Regime switching,Time-varying parameters,Vector autoregressions},
number = {1},
pages = {12--143},
publisher = {Elsevier B.V.},
title = {{Forecasting UK GDP growth and inflation under structural change. A comparison of models with time-varying parameters}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2013.06.002},
volume = {30},
year = {2014}
}
@article{DeJong1988,
author = {Jong, Piet De},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jong - 1988 - The Likelihood for a State Space Model.pdf:pdf},
journal = {Biometrika},
number = {1},
pages = {165--169},
title = {{The Likelihood for a State Space Model}},
volume = {75},
year = {1988}
}
@article{Wei2010,
abstract = {The answer to the title question is “Yes.” Examining stocks traded on the NYSE, AMEX and NASDAQ for the period of 1964 to 2009, this study discovers that, while momemtum prevails among small stocks, momentum and reversals coexist among large stocks for a holding period of up to three months. The momentum/reversal divide is along the volatility dimension: Large-cap, low-volatility stocks exhibit reversals while large-cap, high-volatility stocks experience momentum. This new discovery cannot be rationalized with either risk-based or behavioral-based explanations and, as a result, presents itself as a fresh puzzle to the literature.},
author = {Wei, Jason Zhanshun},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Wei - 2010 - Do Momentum and Reversals Coexist.pdf:pdf},
journal = {Working Paper},
keywords = {firm size,momentum,return predictability,reversals,underreaction,volatility},
title = {{Do Momentum and Reversals Coexist?}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1679464},
year = {2010}
}
@article{Evans2005,
abstract = {This paper describes a method for calculating daily real- time estimates of the current state of the U.S. economy. The estimates are computed from data on scheduled U.S. macro- economic announcements using an econometric model that al- lows for variable reporting lags, temporal aggregation, and other complications in the data. The model can be applied to find real-time estimates of GDP, inflation, unemployment, or any other macroeconomic variable of interest. In this paper, I focus on the problem of estimating the current level of and growth rate in GDP. I construct daily real-time estimates of GDP that incorporate public information known on the day in question. The real-time estimates produced by the model are uniquely suited to studying how perceived developments in the macroeconomy are linked to asset prices over a wide range of frequencies. The estimates also provide, for the first time, daily time series that can be used in practical policy decisions.},
author = {Evans, Martin D.},
doi = {10.2139/ssrn.646103},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Evans - 2005 - Where Are We Now Real-Time Estimates of the Macroeconomy.pdf:pdf},
issn = {1556-5068},
journal = {International Journal of Central Banking},
pages = {127--175},
title = {{Where Are We Now? Real-Time Estimates of the Macroeconomy}},
year = {2005}
}
@misc{Jegadeesh1995,
abstract = {We show that the pattern of short-term negative serial covariances for stock returns over different return measurement intervals is consistent with the implications of inventory-based microstructure models. We develop different testable implications of these models and document supporting evidence. Our findings indicate that to a large extent the short-horizon return revearsals can be explained by dealer-inventory-related market microstructure effects},
author = {Jegadeesh, Narasimhan and Titman, Sheridan},
booktitle = {Journal of Financial Intermediation},
doi = {10.1006/jfin.1995.1006},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jegadeesh, Titman - 1995 - Short-Horizon Return Reversals and the Bid-Ask Spread.pdf:pdf},
isbn = {1042-9573},
issn = {10429573},
number = {2},
pages = {116--132},
title = {{Short-Horizon Return Reversals and the Bid-Ask Spread}},
url = {http://www.sciencedirect.com/science/article/pii/S1042957385710066},
volume = {4},
year = {1995}
}
@article{Caiani2016,
abstract = {The paper moves from a discussion of the challenges posed by the crisis to standard macroeconomics and the solutions adopted within the DSGE community. Although several recent improvements have enhanced the realism of standard models, we argue that major drawbacks still undermine their reliability. In particular, DSGE models still fail to recognize the complex adaptive nature of economic systems, and the implications of money endogeneity. The paper argues that a coherent and exhaustive representation of the inter-linkages between the real and financial sides of the economy should be a pivotal feature of every macroeconomic model and proposes a macroeconomic framework based on the combination of the Agent Based and Stock Flow Consistent approaches. The papers aims at contributing to the nascent AB-SFC literature under two fundamental respects: first, we develop a fully decentralized AB-SFC model with several innovative features, and we thoroughly validate it in order to check whether the model is a good candidate for policy analysis applications. Results suggest that the properties of the model match many empirical regularities, ranking among the best performers in the related literature, and that these properties are robust across different parameterizations. Second, the paper has also a methodological purpose in that we try to provide a set or rules and tools to build, calibrate, validate, and display AB-SFC models.},
author = {Caiani, Alessandro and Godin, Antoine and Caverzasi, Eugenio and Gallegati, Mauro and Kinsella, Stephen and Stiglitz, Joseph E.},
doi = {10.1016/j.jedc.2016.06.001},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Caiani et al. - 2016 - Agent Based-Stock Flow Consistent Macroeconomics Towards a Benchmark Model.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {Agent based macroeconomics,Bank regulation,Business cycles,Stock flow consistent models},
pages = {375--408},
publisher = {Elsevier},
title = {{Agent Based-Stock Flow Consistent Macroeconomics: Towards a Benchmark Model}},
url = {http://dx.doi.org/10.1016/j.jedc.2016.06.001},
volume = {69},
year = {2016}
}
@article{Banerjee2009,
abstract = {Motivated by the insight of Keynes (1936) on the importance of higher-order beliefs in financial markets, we examine the role of such beliefs in generating drift in asset prices. We show that in a dynamic setting, a higher-order difference of opinions is necessary for heterogeneous beliefs to generate price drift. Such drift does not arise in standard difference of opinion models, since investors' beliefs are assumed to be common knowledge. Our results stand in contrast to those of Allen, Morris, and Shin (2006) and others, as we argue that in rational expectation equilibria, heterogeneous beliefs do not lead to price drift.},
author = {Banerjee, Snehal and Kaniel, Ron and Kremer, Ilan},
doi = {10.1093/rfs/hhp014},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Banerjee, Kaniel, Kremer - 2009 - Price Drift as an Outcome of Differences in Higher-Order Beliefs.pdf:pdf},
isbn = {08939454},
issn = {08939454},
journal = {Review of Financial Studies},
number = {9},
pages = {3707--3734},
pmid = {15582071},
title = {{Price Drift as an Outcome of Differences in Higher-Order Beliefs}},
volume = {22},
year = {2009}
}
@book{Greenberg2008,
author = {Greenberg, Edward},
publisher = {Cambridge University Press},
title = {{Introduction to Bayesian Econometrics}},
year = {2008}
}
@article{Beauchemin2013,
author = {Beauchemin, Kenneth},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Beauchemin - 2013 - A 14-Variable Mixed-Frequency VAR Model.pdf:pdf},
keywords = {bayesian vector autoregression,c11,c32,c53,forecasting,jel classi fi cation},
number = {December},
title = {{A 14-Variable Mixed-Frequency VAR Model}},
year = {2013}
}
@techreport{Stiglitz2009,
abstract = {The report distinguishes between an assessment of current well-being and an assessment of sustainability, whether this can last over time. Current well-being has to do with both economic resources, such as income, and with non-economic resources aspect of peoples life.},
author = {Stiglitz, Joseph E and Sen, Amartya and Fitoussi, Jean-Paul},
booktitle = {Sustainable Development},
doi = {10.2139/ssrn.1714428},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stiglitz, Sen, Fitoussi - 2009 - Report by the Commission on the Measurement of Economic Performance and Social Progress.pdf:pdf},
isbn = {1595585192},
issn = {15565068},
keywords = {fitoussi,gdb,happiness,sen,stiglitz,wellfare},
pages = {292},
title = {{Report by the Commission on the Measurement of Economic Performance and Social Progress}},
url = {http://www.ssrn.com/abstract=1714428},
volume = {12},
year = {2009}
}
@book{Shleifer2000,
author = {Shleifer, Andrei},
pages = {1--224},
publisher = {Oxford University Press},
title = {{Inefficient Markets: An Introduction to Behavioral Finance}},
year = {2000}
}
@book{Eurostat2010,
author = {Eurostat},
doi = {10.2785/35091},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Eurostat - 2010 - European System of Accounts 2010.pdf:pdf},
isbn = {9789279312427},
title = {{European System of Accounts 2010}},
year = {2010}
}
@article{Schorfheide2015,
abstract = {This paper develops a vector autoregression (VAR) for macroeconomic time series which are observed at mixed frequencies – quarterly and monthly. The mixed-frequency VAR is cast in state-space form and estimated with Bayesian methods under a Minnesota-style prior. Using a real-time data set, we generate and evaluate forecasts from the mixed-frequency VAR and compare them to forecasts from a VAR that is estimated based on data time-aggregated to quarterly frequency. We document how information that becomes available within the quarter improves the forecasts in real time.},
author = {Schorfheide, Frank and Song, Dongho},
doi = {10.1080/07350015.2014.954707},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Schorfheide, Song - 2015 - Real-Time Forecasting with a Mixed-Frequency VAR.pdf:pdf},
isbn = {4144632733},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Bayesian statistical decision theory,Forecasting,Vector autoregression},
number = {April 2017},
pages = {366--380},
title = {{Real-Time Forecasting with a Mixed-Frequency VAR}},
url = {http://ideas.repec.org/p/fip/fedmwp/701.html},
volume = {33},
year = {2015}
}
@article{Caginalp1995,
author = {Caginalp, G. and Constantine, G.},
doi = {10.1080/13504869500000012},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Caginalp, Constantine - 1995 - Statistical Inference and Modelling of Momentum in Stock Prices.pdf:pdf},
issn = {1350-486X},
journal = {Applied Mathematical Finance},
number = {4},
pages = {225--242},
title = {{Statistical Inference and Modelling of Momentum in Stock Prices}},
volume = {2},
year = {1995}
}
@book{Butler1996,
author = {Butler, Leo},
booktitle = {Bank of Canada Working Paper},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Butler - 1996 - A Semi-Structural Method to Estimate Potential Output Combining Economic Theory with a Time-Series Filter.pdf:pdf},
isbn = {0662251016},
title = {{A Semi-Structural Method to Estimate Potential Output: Combining Economic Theory with a Time-Series Filter}},
year = {1996}
}
@article{Kapetanios2015,
abstract = {Abstract Density forecast combinations are becoming increasingly popular as a means of improving forecast 'accuracy', as measured by a scoring rule. In this paper we generalise this literature by letting the combination weights follow more general schemes. Sieve estimation is used to optimise the score of the generalised density combination where the combination weights depend on the variable one is trying to forecast. Specific attention is paid to the use of piecewise linear weight functions that let the weights vary by region of the density. We analyse these schemes theoretically, in Monte Carlo experiments and in an empirical study. Our results show that the generalised combinations outperform their linear counterparts.},
author = {Kapetanios, G. and Mitchell, J. and Price, S. and Fawcett, N.},
doi = {10.1016/j.jeconom.2015.02.047},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kapetanios et al. - 2015 - Generalised density forecast combinations.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Density forecasting,Model combination,Scoring rules},
number = {1},
pages = {150--165},
publisher = {Elsevier B.V.},
title = {{Generalised density forecast combinations}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.02.047},
volume = {188},
year = {2015}
}
@article{Musso2005,
author = {Musso, Alberto and Westermann, Thomas},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Musso, Westermann - 2005 - Assessing potential output growth in the euro area a growth accounting perspective.pdf:pdf},
journal = {ECB Occasional Paper Series},
title = {{Assessing potential output growth in the euro area: a growth accounting perspective}},
volume = {22},
year = {2005}
}
@article{Israel2013,
author = {Israel, Ronen and Moskowitz, Tobias J.},
doi = {10.1016/j.jfineco.2012.11.005},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Israel, Moskowitz - 2013 - The role of shorting, firm size, and time on market anomalies.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Asset pricing,Market anomalies,Market efficiency,Momentum,Size,Value},
month = {may},
number = {2},
pages = {275--301},
publisher = {Elsevier},
title = {{The role of shorting, firm size, and time on market anomalies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304405X12002401},
volume = {108},
year = {2013}
}
@article{Primiceri2005,
author = {Primiceri, Giorgio},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Primiceri - 2005 - Time Varying Structural Vector Autoregressions.pdf:pdf},
journal = {Review of Economic Studies},
keywords = {multivariate stochastic volatility,time varying coefficients},
number = {3},
pages = {821--852},
title = {{Time Varying Structural Vector Autoregressions}},
url = {http://www.yahoo.com/},
volume = {72},
year = {2005}
}
@book{Bodie2010,
author = {Bodie, Zvi and Kane, Alex and Marcus, Alan},
edition = {9th},
pages = {371--428},
publisher = {McGraw-Hill/Irwin},
title = {{Investments}},
year = {2010}
}
@article{Beyeler,
author = {Beyeler, Simon and Kaufmann, Sylvia},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Beyeler, Kaufmann - Unknown - Factor augmented VAR revisited - A sparse dynamic factor model approach.pdf:pdf},
title = {{Factor augmented VAR revisited - A sparse dynamic factor model approach}}
}
@misc{Buffett1984,
author = {Buffett, Warren},
booktitle = {Hermes},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Buffett - 1984 - The Superinvestors of Graham-and-Doodsville.pdf:pdf},
pages = {4--15},
title = {{The Superinvestors of Graham-and-Doodsville}},
year = {1984}
}
@article{Koop2010,
author = {Koop, Gary and Korobilis, Dimitris},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koop, Korobilis - 2010 - Bayesian Multivariate Time Series Methods for Empirical Macroeconomics.pdf:pdf},
journal = {Foundations and Trends in Econometrics},
number = {4},
pages = {267--358},
publisher = {now Publishers, Delft},
title = {{Bayesian Multivariate Time Series Methods for Empirical Macroeconomics}},
volume = {3},
year = {2010}
}
@article{Asness1997,
author = {Asness, Clifford S.},
doi = {10.2469/faj.v53.n2.2069},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Asness - 1997 - The Interaction of Value Strategies and Momentum.pdf:pdf},
issn = {0015198X},
journal = {Financial Analysts Journal},
number = {2},
pages = {29--36},
title = {{The Interaction of Value Strategies and Momentum}},
volume = {53},
year = {1997}
}
@article{LeBreton2009,
abstract = {The financial crisis has enhanced the need for close monitoring of financial flows in the economy of the euro area and at the global level focusing, in particular, on the development of financial imbalances and financial intermediation. In this context flow-of-funds analysis appears particularly useful, as flow-of-funds data provide the most comprehensive and consistent set of macro-financial information for all sectors in the economy. This occasional paper presents different uses of flow-of-funds statistics for economic and monetary analysis in the euro area. Flow-of-funds data for the euro area have developed progressively over the past decade. The first data were published in 2001, and fully-fledged quarterly integrated economic and financial accounts by institutional sector have been published since 2007. The paper illustrates how flow-of-funds data enable portfolio shifts between money and other financial assets to be assessed and trends in bank intermediation to be monitored, in particular. Based on data (and first published estimates) on financial wealth over the period 1980-2007, the paper analyses developments in the balance sheet of households and non-financial corporations in euro area countries over the last few decades and looks at financial soundness indicators using flow-of-funds data, namely debt and debt service ratios, and measures of financial wealth. Interactions with housing investment and saving are also analysed. In addition, the paper shows how flow-of-funds data can be used for assessing financial stability. Finally, the paper presents the framework for and use of flow-of-funds projections produced in the context of the Eurosystem staff macroeconomic projection exercises, and reports the outcome of a sensitivity analysis that considers the impact of interest rate changes on the interest payments and receipts of households and non-financial corporations.},
author = {{Le Breton}, Gwena{\"{e}}l and Duc, Louis B{\^{e}}},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Le Breton, Duc - 2009 - Flow-of-Fund Analysis at the ECB.pdf:pdf},
issn = {{\textless}null{\textgreater}},
journal = {ECB Occasional Paper Series},
keywords = {Flow of funds,financial account,saving,sector b},
number = {105},
pages = {1--46},
title = {{Flow-of-Fund Analysis at the ECB}},
url = {http://www.ecb.int/pub/pdf/scpops/ecbocp105.pdf{\%}5Cnpapers2://publication/uuid/D6E6BCD6-8CD7-4912-8FD8-1184809FBA82},
year = {2009}
}
@article{Blinder2005,
author = {Blinder, Alan S. and Morgan, John},
journal = {Journal of Money, Credit and Banking},
number = {5},
pages = {798--811},
title = {{Are Two Heads Better Than One? Monetary Policy by Committee}},
volume = {37},
year = {2005}
}
@incollection{Bernanke1999,
author = {Bernanke, Ben S. and Gertler, Mark and Gilchrist, Simon},
booktitle = {Handbook of Macroeconomics},
doi = {10.1016/S1574-0048(99)10034-X},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bernanke, Gertler, Gilchrist - 1999 - The Financial Accelerator in a Quantitative Business Cycle Framework.pdf:pdf},
isbn = {9780444501585},
issn = {15740048},
pages = {1341--1393},
title = {{The Financial Accelerator in a Quantitative Business Cycle Framework}},
volume = {1},
year = {1999}
}
@article{Fama1998,
abstract = {Value stocks have higher returns than growth stocks in markets around the world. For the period 1975 through 1995, the difference between the average returns on global portfolios of high and low book-to-market stocks is 7.68 percent per year, and value stocks outperform growth stocks in twelve of thirteen major markets. An international capital asset pricing model cannot explain the value premium, but a two-factor model that includes a risk factor for relative distress captures the value premium in international returns.},
author = {Fama, Eugene F. and French, Kenneth R.},
journal = {The Journal of Finance},
number = {6},
pages = {1975--1999},
title = {{Value versus Growth : The International Evidence}},
volume = {53},
year = {1998}
}
@article{Marshall2013a,
abstract = {We compare and contrast time-series momentum trading rules, which have been documented in the last few years, with moving average rules which have been around for decades. These strategies are similar (return correlations are typically in excess of 0.8). However, moving average rules frequently signal earlier entries and exits and this results in meaningful return gains. Both trading rules perform best outside of large stock series which may explain the puzzle of their popularity with investors yet lack of supportive evidence in academic studies which have focused on indices dominated by large stocks.},
author = {Marshall, Ben R and Nguyen, Nhut H. and Visaltanachoti, Nuttawat},
doi = {10.2139/ssrn.2225551},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Marshall, Nguyen, Visaltanachoti - 2013 - Time-Series Momentum Versus Moving Average Trading Rules.pdf:pdf},
issn = {1556-5068},
keywords = {17 april 2012,19 february 2013,first version,moving average,return predictability,technical analysis,this version,time-series momentum},
pages = {1--46},
title = {{Time-Series Momentum Versus Moving Average Trading Rules}},
url = {http://ssrn.com/abstract=2225551},
year = {2013}
}
@article{Forni2005,
abstract = {This article proposes a new forecasting method that makes use of information from a large panel of time series. Like earlier methods, our method is based on a dynamic factor model. We argue that our method improves on a standard principal component predictor in that it fully exploits all the dynamic covariance structure of the panel and also weights the variables according to their estimated signal-to-noise ratio. We provide asymptotic results for our optimal forecast estimator and show that in finite samples, our forecast outperforms the standard principal components predictor.},
author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Reichlin, Lucrezia},
doi = {10.1198/016214504000002050},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Forni et al. - 2005 - The Generalized Dynamic Factor Model.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {dynamic factor model,forecasting,large cross-section,panel data,principal components,time series},
number = {471},
pages = {830--840},
title = {{The Generalized Dynamic Factor Model}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000002050},
volume = {100},
year = {2005}
}
@article{Giorno1995,
abstract = {Ce document passe en revue les diff{\'{e}}rentes m{\'{e}}thodes utilis{\'{e}}es pour estimer la production potentielle dans les pays de l'OCDE et l'utilisation des {\'{e}}carts de production qui a d{\^{e}}coulent pour le calcul des soldes budg{\'{e}}taires structurels. La m{\'{e}}thode utilisant la segmentation de la tendance temporelle pour estimer la production potentielle et qui servait pr{\'{e}}c{\'{e}}demment {\'{a}} calculer les soldes budg{\'{e}}taires structurels est compar{\'{e}}e {\`{a}} deux autres m{\'{e}}thodes : le lissage du PIB r{\'{e}}el {\`{a}} l'aide d'un filtre Hodrick-Prescott et l'estimation de la production potentielle sur la base d'une fonction de production. Il en ressort que l'estimation de la production potentielle par l'approche fonction de production a s'av{\`{e}}re {\^{e}}tre la meilleure m{\'{e}}thode pour estimer les {\'{e}}carts de production et pour calculer les soldes budg{\'{e}}taires structurels, les r{\'{e}}sultats obtenus par lissage du PIB {\'{e}}tant utilis{\'{e}}s comme moyens de v{\'{e}}rification. Pour estimer les soldes budg{\'{e}}taires structurels, on utilise de nouvelles {\'{e}}lasticit{\'{e}}s des prelevement et des d{\'{e}}penses et les {\'{e}}carts par rapport a la production potentielle.},
author = {Giorno, Claude and Richardson, Pete and Roseveare, Deborah and van den Noord, Paul},
doi = {10.1787/533876774515},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Giorno et al. - 1995 - Estimating Potential Output, Output Gaps and Structural Budget Balances.pdf:pdf},
isbn = {02550822},
issn = {1995-2856 (electronic)},
journal = {OECD Economics Department Working Papers},
title = {{Estimating Potential Output, Output Gaps and Structural Budget Balances}},
url = {http://www.oecd.org/eco/outlook/33928808.pdf},
volume = {152},
year = {1995}
}
@article{Grant2017,
abstract = {This paper reconciles two widely used trend–cycle decompositions of GDP that give markedly different estimates: the correlated unobserved components model yields output gaps that are small in amplitude, whereas the Hodrick–Prescott (HP) filter generates large and persistent cycles. By embedding the HP filter in an unobserved components model, we show that this difference arises due to differences in the way the stochastic trend is modeled. Moreover, the HP filter implies that the cyclical components are serially independent—an assumption that is decidedly rejected by the data. By relaxing this restrictive assumption, the augmented HP filter provides comparable model fit relative to the standard correlated unobserved components model.},
author = {Grant, Angelia L. and Chan, Joshua C.C.},
doi = {10.1016/j.jedc.2016.12.004},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Grant, Chan - 2017 - Reconciling output gaps Unobserved components model and Hodrick–Prescott filter.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {HP filter,Structural break,Trend–cycle decomposition},
pages = {114--121},
title = {{Reconciling output gaps: Unobserved components model and Hodrick–Prescott filter}},
volume = {75},
year = {2017}
}
@article{Arnott2013,
author = {Arnott, Robert D. and Hsu, Jason and Kalesnik, Vitali and Tindall, Phil},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Arnott et al. - 2013 - The Surprising Alpha From Malkiel's Monkey and Upside-Down Strategies.pdf:pdf},
journal = {The Journal of Portfolio Management},
number = {4},
pages = {91--105},
title = {{The Surprising Alpha From Malkiel's Monkey and Upside-Down Strategies}},
volume = {39},
year = {2013}
}
@article{Baresa2013,
author = {Baresa, Suzana and Bogdan, Sinisa and Ivanovic, Zoran},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Baresa, Bogdan, Ivanovic - 2013 - Strategy of Stock Valuation by Fundamental Analysis.pdf:pdf},
journal = {Journal of Economics},
keywords = {discount models,financial indicators,fundamental analysis,g10,intrinsic value,jel classification,stocks},
number = {1},
pages = {45--51},
title = {{Strategy of Stock Valuation by Fundamental Analysis}},
volume = {4},
year = {2013}
}
@book{Anderson1956,
author = {Anderson, T. W. and Rubin, Herman},
booktitle = {Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, Volume 5: Contributions to Econometrics, Industrial Research, and Psychometry},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Anderson, Rubin - 1956 - Statistical Inference in Factor Analysis.pdf:pdf},
title = {{Statistical Inference in Factor Analysis}},
year = {1956}
}
@article{Brunnermeier2008,
author = {Brunnermeier, Markus K.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Brunnermeier - 2008 - Deciphering the Liquidity and Credit Crunch 2007-08.pdf:pdf},
journal = {NBER Working Paper Series},
number = {14612},
pages = {1--33},
title = {{Deciphering the Liquidity and Credit Crunch 2007-08}},
volume = {2008},
year = {2008}
}
@article{Allen2002,
abstract = {The paper lays out an analytical framework for understanding crises in emerging markets based on examination of stock variables in the aggregate balance sheet of a country and the balance sheets of its main sectors (assets and liabilities). It focuses on the risks created by maturity, currency, and capital structure mismatches. This framework draws attention to the vulnerabilities created by debts among residents, particularly those denominated in foreign currency, and it helps to explain how problems in one sector can spill over into other sectors, eventually triggering an external balance of payments crisis. The paper also discusses the potential of macroeconomic policies and official intervention to mitigate the cost of such a crisis.},
author = {Allen, Mark and Rosenberg, Christoph and Keller, Christian and Setser, Brad and Roubini, Nouriel},
doi = {10.5089/9781451957150.001.A001},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Allen et al. - 2002 - A Balance Sheet Approach to Financial Crisis.pdf:pdf},
isbn = {1451957157},
issn = {1934-7073},
journal = {IMF Working Papers},
number = {210},
pages = {1--63},
title = {{A Balance Sheet Approach to Financial Crisis}},
volume = {02},
year = {2002}
}
@article{Athanasopoulos2017,
abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied combination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short-term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that forecasting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident {\&} Emergency departments.},
author = {Athanasopoulos, George and Hyndman, Rob J. and Kourentzes, Nikolaos and Petropoulos, Fotios},
doi = {10.1016/j.ejor.2017.02.046},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Athanasopoulos et al. - 2017 - Forecasting with temporal hierarchies.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Forecast combination,Forecasting,Hierarchical forecasting,Reconciliation,Temporal aggregation},
number = {1},
pages = {60--74},
title = {{Forecasting with temporal hierarchies}},
volume = {262},
year = {2017}
}
@article{Richardson1993,
abstract = {Recent empirical work has uncovered U-shaped patterns of large magnitude in the serial-correlation estimates of multiyear stock returns. The current literature in finance has taken this evidence to mean that there exists a temporary component of stock prices. This article provides an alternative explanation regarding these findings. Specifically, we show that the patterns in serial-correlation estimates and their magnitude observed in previous studies should be expected under the null hypothesis of serial independence.},
author = {Richardson, Matthew},
doi = {10.1080/07350015.1993.10509948},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Richardson - 1993 - Temporary Components of Stock Prices A Skeptic's View.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {autocorrelation,joint test,temporary component},
number = {2},
pages = {199--207},
title = {{Temporary Components of Stock Prices: A Skeptic's View}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07350015.1993.10509948},
volume = {11},
year = {1993}
}
@article{Grant2017a,
abstract = {{\textcopyright} 2017 The Ohio State UniversityWe compare a number of widely used trend-cycle decompositions of output in a formal Bayesian model comparison exercise. This is motivated by the often markedly different results from these decompositions—different decompositions have broad implications for the relative importance of real versus nominal shocks in explaining variations in output. Using U.S. quarterly real GDP, we find that the overall best model is an unobserved components model with two features: (i) a nonzero correlation between trend and cycle innovations and (ii) a break in trend output growth in 2007. The annualized trend output growth decreases from about 3.4{\%} to 1.2{\%}–1.5{\%} after the break. The results also indicate that real shocks are more important than nominal shocks. The slowdown in trend output growth is robust when we expand the set of models to include bivariate unobserved components models.},
author = {Grant, Angelia L. and Chan, Joshua C.C.},
doi = {10.1111/jmcb.12388},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Grant, Chan - 2017 - A Bayesian Model Comparison for Trend-Cycle Decompositions of Output.pdf:pdf},
issn = {15384616},
journal = {Journal of Money, Credit and Banking},
keywords = {Bayesian model comparison,business cycle,structural break,unobserved components},
number = {2-3},
pages = {525--552},
title = {{A Bayesian Model Comparison for Trend-Cycle Decompositions of Output}},
volume = {49},
year = {2017}
}
@article{Vukotic2011,
abstract = {The globalization is breaking-down the idea of national state, which was the base for the development of economic theory which is dominant today. Global economic crisis puts emphasis on limited possibilities of national governments in solving economic problems and general problems of society. Does it also mean that globalization and global economic crisis points out the need to think about new economic theory and new understanding of economics? In this paper I will argue that globalization reveals the need to change dominant economic paradigm from traditional economic theory (mainstream) with macroeconomic stability as the goal of economic policy, to the ``quantum economics{\{}''{\}}, which is based on ``economic quantum{\{}''{\}} and immanent to the increase of wealth (material and. non-material) of every individual in society and promoting set of values immanent to the wealth increase as the goal of economic policy. Practically the question is how we can use global market for our development!},
author = {Vukoti{\'{c}}, Veselin},
doi = {10.2298/PAN1102267V},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Vukoti{\'{c}} - 2011 - Quantum Economics.pdf:pdf},
issn = {1452595X},
journal = {Panoeconomicus},
keywords = {An individual,Development,Economic quantum,Globalization,Innovation},
number = {2},
pages = {267--276},
title = {{Quantum Economics}},
volume = {58},
year = {2011}
}
@article{Jegadeesh1990,
abstract = {This paper presents new empirical evidence of predictability of individual stock returns. The negative first-order serial correlation in monthly stock returns is highly significant. Furthermore, significant positive serial correlation is found at longer lags, and the twelve-month serial correlation is particularly strong. Using the observed systematic behavior of stock return, one-step-ahead return forecasts are made and ten portfolios are formed from the forecasts. The difference between the abnormal returns on the extreme decile portfolios over the period 1934-87 is 2.49 percent per month.},
author = {Jegadeesh, Narasimhan},
doi = {10.2307/2328797},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jegadeesh - 1990 - Evidence of Predictable Behavior of Security Returns.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {The Journal of Finance},
number = {3},
pages = {881--898},
title = {{Evidence of Predictable Behavior of Security Returns}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1990.tb05110.x/abstract},
volume = {45},
year = {1990}
}
@article{Daniel1998,
author = {Daniel, Kent and Hirshleifer, David and Subrahmanyam, Avanidhar},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Daniel, Hirshleifer, Subrahmanyam - 1998 - Investor Psychology and Security Market Under- and Overreactions.pdf:pdf},
isbn = {9781400829125},
journal = {Journal of Finance},
number = {6},
pages = {1839--1886},
title = {{Investor Psychology and Security Market Under- and Overreactions}},
volume = {53},
year = {1998}
}
@article{Rebelo1998,
author = {Rebelo, Sergio},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rebelo - 1998 - The Role of Knowledge and Capital in Economic Growth.pdf:pdf},
title = {{The Role of Knowledge and Capital in Economic Growth}},
year = {1998}
}
@article{Chan2017,
author = {Chan, Joshua and Leon-Gonzalez, Roberto and Strachan, Rodney W.},
doi = {10.1080/01621459.2017.1287080},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chan, Leon-Gonzalez, Strachan - 2017 - Invariant Inference and Efficient Computation in the Static Factor Model.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {1--27},
title = {{Invariant Inference and Efficient Computation in the Static Factor Model}},
year = {2017}
}
@article{Koop2010a,
abstract = {Macroeconomic practitioners frequently work with multivariate time series models such as VARs, factor augmented VARs as well as time- varying parameter versions of these models (including variants with mul- tivariate stochastic volatility). These models have a large number of pa- rameters and, thus, over-parameterization problems may arise. Bayesian methods have become increasingly popular as a way of overcoming these problems. In this monograph, we discuss VARs, factor augmented VARs and time-varying parameter extensions and show how Bayesian inference proceeds. Apart from the simplest of VARs, Bayesian inference requires the use of Markov chain Monte Carlo methods developed for state space models and we describe these algorithms. The focus is on the empiri- cal macroeconomist and we o¤er advice on how to use these models and methods in practice and include empirical illustrations. A website pro- vides Matlab code for carrying out Bayesian inference in these models.},
author = {Koop, Gary and Korobilis, Dimitris},
doi = {10.1561/0800000013},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koop, Korobilis - 2010 - Bayesian Multivariate Time Series Methods for Empirical Macroeconomics.pdf:pdf},
isbn = {160198362X},
keywords = {Bayesian estimation,Empirical macroeconometrics,MCMC,factor models,time-varying parameters,vector autoregressions},
number = {20125},
pages = {1--71},
title = {{Bayesian Multivariate Time Series Methods for Empirical Macroeconomics}},
url = {http://mpra.ub.uni-muenchen.de/20125/{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=JcVn9IJ9wSsC{\&}oi=fnd{\&}pg=PA1{\&}dq=Bayesian+Multivariate+Time+Series+Methods+for+Empirical+Macroeconomics{\&}ots=InDMzdUjna{\&}sig=6ZDjx5WsJvNacnUjOQYWJ9EDiOc},
year = {2010}
}
@article{Steiner2010b,
author = {Steiner, Elizabeth},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Steiner - 2010 - Estimating a Stock-Flow Model for the Swiss Housing Market.pdf:pdf},
journal = {Swiss Journal of Economics and Statistics},
keywords = {hous-,housing demand,housing supply,market disequilibrium,residential investment},
number = {3},
pages = {601--627},
title = {{Estimating a Stock-Flow Model for the Swiss Housing Market}},
volume = {146},
year = {2010}
}
@book{Lemke2006,
author = {Lemke, Wolfgang},
booktitle = {Urban Ecology},
doi = {10.1016/0304-4009(82)90008-0},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lemke - 2006 - Term Structure Modeling and Estimation in a State Space Framework.pdf:pdf},
isbn = {9783642021466},
issn = {03044009},
number = {1},
title = {{Term Structure Modeling and Estimation in a State Space Framework}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304400982900080},
volume = {7},
year = {2006}
}
@article{Forni2015,
abstract = {Factor model methods recently have become extremely popular in the theory and practice of large panels of time series data. Those methods rely on various factor models which all are particular cases of the Generalized Dynamic Factor Model (GDFM) introduced in Forniet al. (2000). That paper, however, rests on Brillinger's dynamic principal components. The corresponding estimators are two-sided filters whose performance at the end of the observation period or for forecasting purposes is rather poor. No such problem arises with estimators based on standard principal components, which have been dominant in this literature. On the other hand, those estimators require the assumption that the space spanned by the factors has finite dimension. In the present paper, we argue that such an assumption is extremely restrictive and potentially quite harmful. Elaborating upon recent results by Anderson and Deistler (2008a, b) on singular stationary processes with rational spectrum, we obtain one-sided representations for the GDFM without assuming finite dimension of the factor space. Construction of the corresponding estimators is also briefly outlined. In a companion paper, we establish consistency and rates for such estimators, and provide Monte Carlo results further motivating our approach.},
author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Zaffaroni, Paolo},
doi = {10.1016/j.jeconom.2013.10.017},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Forni et al. - 2015 - Dynamic Factor Models with Infinite-Dimensional Factor Spaces One-sided Representations.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Generalized dynamic factor models,One-sided representations for dynamic factor model,Vector processes with singular spectral density},
number = {2},
pages = {359--371},
publisher = {Elsevier B.V.},
title = {{Dynamic Factor Models with Infinite-Dimensional Factor Spaces: One-sided Representations}},
url = {http://dx.doi.org/10.1016/j.jeconom.2013.10.017},
volume = {185},
year = {2015}
}
@article{Chen2001,
author = {Chen, Zhiwu and Dong, Ming},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chen, Dong - 2001 - Stock Valuation and Investment Strategies.pdf:pdf},
journal = {Yale ICF Working Paper},
pages = {1--55},
title = {{Stock Valuation and Investment Strategies}},
volume = {00-46},
year = {2001}
}
@article{Marcellino2016b,
abstract = {Large scale factor models have been often adopted both for forecasting and to identify structural shocks and their transmission mechanism. Mixed frequency factor models have been also used in a reduced form context, but not for structural applications, and in this paper we close this gap. First, we adapt a simple technique developed in a small scale mixed frequency VAR and factor context to the large scale case, and compare the resulting model with existing alternatives. Second, using Monte Carlo experiments, we show that the finite sample properties of the mixed frequency factor model estimation procedure are quite good. Finally, to illustrate the method we present three empirical examples dealing with the effects of, respectively, monetary, oil, and fiscal shocks.},
author = {Marcellino, Massimiliano and Sivec, Vasja},
doi = {10.1016/j.jeconom.2016.04.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Marcellino, Sivec - 2016 - Monetary, fiscal and oil shocks Evidence based on mixed frequency structural FAVARs.pdf:pdf},
isbn = {8152835714},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Estimation,Identification,Impulse response function,Mixed frequency data,Structural FAVAR,Temporal aggregation},
number = {2},
pages = {335--348},
title = {{Monetary, fiscal and oil shocks: Evidence based on mixed frequency structural FAVARs}},
volume = {193},
year = {2016}
}
@book{Matson2004,
author = {Matson, Bill and Hardy, Mitchell R.},
pages = {389--391},
publisher = {Data Driven Publishing},
title = {{Data Driven Investing}},
year = {2004}
}
@article{Ghysels2014,
author = {Ghysels, Eric},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ghysels - 2014 - Matlab Toolbox for Mixed Sampling Frequency Data Analysis using MIDAS Regression Models.pdf:pdf},
journal = {University of North Carolina Working Paper},
pages = {1--35},
title = {{Matlab Toolbox for Mixed Sampling Frequency Data Analysis using MIDAS Regression Models}},
year = {2014}
}
@article{Hamilton1988,
author = {Hamilton, James D.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hamilton - 1988 - A Neoclassical Model of Unemployment and the Business Cycle.pdf:pdf},
journal = {Journal of Political Economy},
number = {3},
pages = {593--617},
title = {{A Neoclassical Model of Unemployment and the Business Cycle}},
volume = {96},
year = {1988}
}
@article{Groot2012,
author = {Groot, Wilma and Huij, Joop and Zhou, Weili},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Groot, Huij, Zhou - 2012 - Another Look at Trading Costs and Short-Term Reversal Profits.pdf:pdf},
journal = {Journal of Banking and Finance},
number = {36},
pages = {371--382},
title = {{Another Look at Trading Costs and Short-Term Reversal Profits}},
volume = {2012},
year = {2012}
}
@article{Gertler1989,
author = {Gertler, Mark and Bernanke, Ben S.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gertler, Bernanke - 1989 - Agency Costs, Net Worth, and Business Fluctuations.pdf:pdf},
journal = {The American Economic Review},
number = {1},
pages = {14--31},
title = {{Agency Costs, Net Worth, and Business Fluctuations}},
volume = {79},
year = {1989}
}
@article{Stock2012,
abstract = {This paper provides a simple shrinkage representation that describes the operational characteristics of various forecasting methods designed for a large number of orthogonal predictors (such as principal components). These methods include pretest methods, Bayesian model averaging, empirical Bayes, and bagging. We compare empirically forecasts from these methods to dynamic factor model (DFM) forecasts using a U.S. macroeconomic data set with 143 quarterly variables spanning 1960-2008. For most series, including measures of real economic activity, the shrinkage forecasts are inferior to the DFM forecasts},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1080/07350015.2012.715956},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2012 - Generalized shrinkage methods for forecasting using many predictors.pdf:pdf},
isbn = {0735-0015$\backslash$r1537-2707},
issn = {0735-0015},
journal = {Journal of Business and Economic Statistics},
keywords = {dynamic factor models,empirical Bayes,high dimensional model},
number = {4},
pages = {481--493},
title = {{Generalized shrinkage methods for forecasting using many predictors}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/07350015.2012.715956},
volume = {30},
year = {2012}
}
@article{Hong2000a,
abstract = {Various theories have been proposed to explain momentum in stock returns. We test the gradual-information-diffusion model of Hong and Stein (1999) and establish three key results. First, once one moves past the very smallest stocks, the profitability of momentum strategies declines sharply with firm size. Second, holding size fixed, momentum strategies work better among stocks with low analyst coverage. Finally, the effect of analyst coverage is greater for stocks that are past losers than for past winners. These findings are consistent with the hypothesis that firm-specific information, especially negative information, diffuses only gradually across the investing public.},
author = {Hong, Harrison and Lim, Terence and Stein, Jeremy C},
doi = {10.1111/0022-1082.00206},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hong, Lim, Stein - 2000 - Bad News Travels Slowly Size, Analyst Coverage and the Profitability of Momentum Strategies.pdf:pdf},
isbn = {00221082},
issn = {1540-6261},
journal = {The Journal of Finance},
number = {1},
pages = {265--295},
title = {{Bad News Travels Slowly: Size, Analyst Coverage and the Profitability of Momentum Strategies}},
url = {http://dx.doi.org/10.1111/0022-1082.00206},
volume = {55},
year = {2000}
}
@article{McLean2010,
abstract = {This paper tests whether the persistence of the momentum and reversal effects is the result of idiosyncratic risk limiting arbitrage. Idiosyncratic risk deters arbitrage, regardless of the arbitrageur's diversification. Reversal is prevalent only in high idiosyncratic risk stocks, suggesting that idiosyncratic risk limits arbitrage in reversal mispricing. This finding is robust to controls for transaction costs, informed trading, and systematic relations between idiosyncratic risk and subsequent returns. Momentum is not related to idiosyncratic risk. Momentum generates a smaller aggregate return than reversal, so the findings along with those in related studies suggest that transaction costs are sufficient to prevent arbitrageurs from eliminating momentum mispricing.},
author = {McLean, R. David},
doi = {10.1017/S0022109010000311},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/McLean - 2010 - Idiosyncratic Risk, Long-Term Reversal, and Momentum.pdf:pdf},
isbn = {7804923325},
issn = {0022-1090},
journal = {Journal of Financial and Quantitative Analysis},
number = {04},
pages = {883--906},
pmid = {54590864},
title = {{Idiosyncratic Risk, Long-Term Reversal, and Momentum}},
volume = {45},
year = {2010}
}
@article{Hamilton2017,
abstract = {Here's why. (1) The HP filter produces series with spurious dynamic relations that have no basis in the underlying datagenerating process. (2) A onesided version of the filter reduces but does not eliminate spurious predictability and moreover produces series that do not have the properties sought by most potential users of the HP filter. (3) A statistical formalization of the problem typically produces values for the smoothing parameter vastly at odds with common practice, e.g., a value for $\lambda$ far below 1600 for quarterly data. (4)},
author = {Hamilton, James},
doi = {10.3386/w23429},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hamilton - 2017 - Why You Should Never Use the Hodrick-Prescott Filter.pdf:pdf},
issn = {0034-6535},
journal = {The Review of Economics and Statistics},
title = {{Why You Should Never Use the Hodrick-Prescott Filter}},
url = {http://www.nber.org/papers/w23429.pdf},
year = {2017}
}
@article{Carriero2016,
author = {Carriero, Andrea and Galvao, Ana Beatriz and Kapetanios, George},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Carriero, Galvao, Kapetanios - 2016 - A Comprehensive Evaluation of Macroeconomic Forecasting Methods.pdf:pdf},
keywords = {bvar models,density forecasts,dsge models,factor models,midas models},
title = {{A Comprehensive Evaluation of Macroeconomic Forecasting Methods}},
url = {http://www2.warwick.ac.uk/fac/soc/wbs/subjects/emf/research/papers/a{\_}evaluation{\_}of{\_}macroeconomic{\_}forecasting{\_}methods.pdf},
year = {2016}
}
@article{Fama1993,
author = {Fama, Eugene F. and French, Kenneth R.},
journal = {Journal of Financial Economics},
number = {1},
pages = {3--56},
title = {{Common Risk Factors in the Returns on Stocks and Bonds}},
volume = {33},
year = {1993}
}
@article{Foroni2013,
author = {Foroni, Claudia and Marcellino, Massimiliano},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Foroni, Marcellino - 2013 - A Survey of Econometric Methods for Mixed-Frequency Data.pdf:pdf},
journal = {Norges Bank Research Paper},
title = {{A Survey of Econometric Methods for Mixed-Frequency Data}},
year = {2013}
}
@article{Hodrick1997,
author = {Prescott, Edward C. and Hodrick, Robert J.},
doi = {10.2307/2953682},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Prescott, Hodrick - 1997 - Postwar U. S. Business Cycles An Empirical Investigation.pdf:pdf},
isbn = {00222879},
issn = {00222879},
journal = {Journal of Money, Credit and Banking},
number = {1},
pages = {1--16},
pmid = {12457},
title = {{Postwar U. S. Business Cycles: An Empirical Investigation}},
volume = {29},
year = {1997}
}
@article{Rudebusch1998a,
author = {Rudebusch, Glenn D.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rudebusch - 1998 - Do Monetary Policy in a VAR Make Sense.pdf:pdf},
journal = {International Economic Review},
number = {4},
pages = {907--931},
title = {{Do Monetary Policy in a VAR Make Sense ?}},
volume = {39},
year = {1998}
}
@article{Baurle,
author = {B{\"{a}}urle, Gregor and Steiner, Elizabeth},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/B{\"{a}}urle, Steiner - 2013 - How do individual sectors respond to macroeconomic shocks A structural dynamic factor approach applied to Swiss.pdf:pdf},
journal = {SNB Working Papers},
keywords = {Sectoral value added,dynamic factor model,sign r},
title = {{How do individual sectors respond to macroeconomic shocks? A structural dynamic factor approach applied to Swiss data}},
year = {2013}
}
@article{Jegadeesh2001b,
abstract = {This paper evaluates various explanations for the profitability of momentum strategies documented in Jegadeesh and Titman (1993). The evidence indicates that momentum profits have continued in the 1990's suggesting that the original results were not a product of data snooping bias. The paper also examines the predictions of recent behavioral models that propose that momentum profits are due to delayed overreactions which are eventually reversed. Our evidence provides support for the behavioral models, but this support should be tempered with caution. Although we find no evidence of significant return reversals in the 2 to 3 years following the following formation date, there are significant return reversals 4 to 5 years after the formation date. Our analysis of post-holding period returns sharply rejects a claim in the literature that the observed momentum profits can be explained completely by the cross-sectional dispersion in expected returns. Narasimhan},
author = {Jegadeesh, Narasimhan and Titman, Sheridan},
doi = {10.1111/0022-1082.00342},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jegadeesh, Titman - 2001 - Profitability of Momentum Strategies An Evaluation of Alternative Explanations.pdf:pdf},
isbn = {00221082},
issn = {0022-1082},
journal = {The Journal of Finance},
number = {2},
pages = {699--720},
title = {{Profitability of Momentum Strategies: An Evaluation of Alternative Explanations}},
volume = {56},
year = {2001}
}
@article{Consequences2010,
author = {Orphanides, Athanasios and van Norden, Simon},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Orphanides, van Norden - 2002 - The Unreliability of Output-Gap Estimates in Real Time.pdf:pdf},
journal = {The Review of Economics and Statistics},
number = {4},
pages = {569--583},
title = {{The Unreliability of Output-Gap Estimates in Real Time}},
volume = {84},
year = {2002}
}
@article{Fama1996,
author = {Fama, Eugene F. and French, Kenneth R.},
journal = {Journal of Finance},
number = {1},
pages = {55--84},
title = {{Multifactor Explanations of Asset Pricing Anomalies}},
volume = {51},
year = {1996}
}
@article{Koopman2003,
abstract = {We present algorithms for computing the weights implicitly assigned to observations when estimating unobserved components, by filtering or smoothing, using a model in state space form. The algorithms are based on recursions derived from the Kalman filter and associated smoother. Since the method applies to any model with a linear state space form, it is not restricted to time-invariant systems and it can be used in a number of situations where other methods break down. Applications include the comparison of signal extraction weights with those used by nonparametric procedures and the computation of weights assigned to observations in making forecasts. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Koopman, Siem Jan and Harvey, Andrew},
doi = {10.1016/S0165-1889(02)00061-1},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koopman, Harvey - 2003 - Computing observation weights for signal extraction and filtering.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {Kalman filter,Kernels,Nonparametric regression,State space,Vector autoregression},
number = {7},
pages = {1317--1333},
title = {{Computing observation weights for signal extraction and filtering}},
volume = {27},
year = {2003}
}
@article{Markowitz1952,
author = {Markowitz, Harry Max},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Markowitz - 1952 - Portfolio Selection.pdf:pdf},
journal = {Journal of Finance},
number = {1},
pages = {77--91},
title = {{Portfolio Selection}},
volume = {7},
year = {1952}
}
@article{Cornett2011,
author = {Cornett, Marcia Millon and McNutt, Jamie John and Strahan, Philip E. and Tehranian, Hassan},
doi = {10.1016/j.jfineco.2011.03.001},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Cornett et al. - 2011 - Liquidity Risk Management and Credit Supply in the Financial Crisis.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Financial crisis,Liquidity risk,financial institutions},
month = {aug},
number = {2},
pages = {297--312},
publisher = {Elsevier},
title = {{Liquidity Risk Management and Credit Supply in the Financial Crisis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304405X11000663},
volume = {101},
year = {2011}
}
@article{Morris2012,
author = {Morris, Stephen D},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Morris - 2012 - VARMA Representation of DSGE Models.pdf:pdf},
number = {1},
pages = {1--27},
title = {{VARMA Representation of DSGE Models}},
volume = {138},
year = {2012}
}
@article{Stock2002a,
abstract = {This article studies forecasting a macroeconomic time series variable using a large number of predictors. The predictors are summarized using a small number of indexes constructed by principal component analysis. An approximate dynamic factor model serves as the statistical framework for the estimation of the indexes and construction of the forecasts. The method is used to construct 6-, 12-, and 24-monthahead forecasts for eight monthly U.S. macroeconomic time series using 215 predictors in simulated real time from 1970 through 1998. During this sample period these new forecasts outperformed univariate autoregressions, small vector autoregressions, and leading indicator models.},
author = {Stock, James H and Watson, Mark W},
doi = {10.1198/073500102317351921},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2002 - Macroeconomic Forecasting Using Diffusion Indexes.pdf:pdf},
isbn = {07350015},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Factor model,Forecasting,Principal components},
number = {2},
pages = {147--162},
title = {{Macroeconomic Forecasting Using Diffusion Indexes}},
url = {http://www.tandfonline.com/doi/abs/10.1198/073500102317351921},
volume = {20},
year = {2002}
}
@techreport{B2014,
author = {{Bureau of Economic Analysis}},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bureau of Economic Analysis - 2014 - Concepts and Methods of the U.S. National Income and Product Accounts.pdf:pdf},
number = {February},
title = {{Concepts and Methods of the U.S. National Income and Product Accounts}},
year = {2014}
}
@article{Leamer2010,
author = {Leamer, Edward E.},
doi = {10.1257/jep.24.2.31},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Leamer - 2010 - Tantalus on the Road to Asymptopia.pdf:pdf},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
month = {may},
number = {2},
pages = {31--46},
title = {{Tantalus on the Road to Asymptopia}},
url = {http://pubs.aeaweb.org/doi/abs/10.1257/jep.24.2.31},
volume = {24},
year = {2010}
}
@book{Chatfield2003,
author = {Chatfield, Chris},
edition = {6th},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chatfield - 2003 - The Analysis of Time Series.pdf:pdf},
isbn = {1-58488-317-0},
pages = {1--352},
publisher = {Chapman {\&} Hall/CRC},
title = {{The Analysis of Time Series}},
year = {2003}
}
@article{Rouwenhorst1998,
author = {Rouwenhorst, K. Geert},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rouwenhorst - 1998 - International Momentum Strategies.pdf:pdf},
journal = {Journal of Finance},
number = {1},
pages = {267--284},
title = {{International Momentum Strategies}},
volume = {53},
year = {1998}
}
@article{Keen2013,
author = {Keen, Steve},
doi = {10.1111/1475-4932.12016},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Keen - 2013 - Predicting the 'Global Financial Crisis' Post-Keynesian Macroeconomics.pdf:pdf},
number = {285},
pages = {228--254},
title = {{Predicting the 'Global Financial Crisis': Post-Keynesian Macroeconomics}},
volume = {89},
year = {2013}
}
@article{Malkiel2003b,
author = {Malkiel, Burton G.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Malkiel - 2003 - The Efficient Market Hypothesis and Its Critics.pdf:pdf},
journal = {Journal of Economic Perspectives},
number = {1},
pages = {59--82},
title = {{The Efficient Market Hypothesis and Its Critics}},
volume = {17},
year = {2003}
}
@article{Amenc2013,
abstract = {Alternative equity indexes are likely to outperform traditional cap-weighted indexes over the long term, research results show that such smart beta strategies are exposed to several types of risk, including systematic risk (e.g., factor tilts), specific risk (related to the assumptions and inputs of a strategy), and relative risk (i.e., the risk of potentially severe underperformance) compared to cap-weighted indexes that can last for extended periods of time. Smart beta can play an important role in institutional investors' allocations, but only at the price of implementing a genuine risk-management process. This article discusses a new approach to smart beta investing (Smart Beta 2.0) that not only deviates from the default solution of using market capitalization as the sole criterion for weighting and constituent selection, but also analyzes and manages the risks of such deviations.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Amenc, No{\"{e}}l and Goltz, Felix and Martellini, Lionel},
doi = {10.3905/jii.2013.4.3.015},
eprint = {arXiv:1011.1669v3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Amenc, Goltz, Martellini - 2013 - Smart Beta 2.0.pdf:pdf},
isbn = {9788578110796},
issn = {2154-7238},
journal = {The Journal of Index Investing},
number = {3},
pages = {15--23},
pmid = {25246403},
title = {{Smart Beta 2.0}},
url = {http://www.iijournals.com/doi/abs/10.3905/jii.2013.4.3.015{\#}sthash.g1HU3PCV.Pky5mFWS.dpbs},
volume = {4},
year = {2013}
}
@article{Foroni2014,
abstract = {In this paper, we focus on the different methods which have been proposed in the literature to date for dealing with mixed-frequency and ragged-edge datasets: bridge equations, mixed-data sampling (MIDAS), and mixed-frequency VAR (MF-VAR) models. We discuss their performances for nowcasting the quarterly growth rate of the Euro area GDP and its components, using a very large set of monthly indicators. We investigate the behaviors of single indicator models, forecast combinations and factor models, in a pseudo real-time framework. MIDAS with an AR component performs quite well, and outperforms MF-VAR at most horizons. Bridge equations perform well overall. Forecast pooling is superior to most of the single indicator models overall. Pooling information using factor models gives even better results. The best results are obtained for the components for which more economically related monthly indicators are available. Nowcasts of GDP components can then be combined to obtain nowcasts for the total GDP growth. {\textcopyright} 2013 International Institute of Forecasters.},
author = {Foroni, Claudia and Marcellino, Massimiliano},
doi = {10.1016/j.ijforecast.2013.01.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Foroni, Marcellino - 2014 - A comparison of mixed frequency approaches for nowcasting Euro area macroeconomic aggregates.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bridge models,Factor models,MIDAS,Mixed-frequency VAR,Mixed-frequency data,Nowcasting},
number = {3},
pages = {554--568},
publisher = {Elsevier B.V.},
title = {{A comparison of mixed frequency approaches for nowcasting Euro area macroeconomic aggregates}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2013.01.010},
volume = {30},
year = {2014}
}
@article{Bernard1989,
abstract = {The article focuses on the delayed price response in post-earnings-announcement drift. It states that competing explanations for post-earnings-announcement drift can be placed in two categories: price response to new information is delayed, and that researches fail to adjust raw returns fully for risk due to the use of incomplete or misestimated capital-asset-pricing models (CAPM) to calculate abnormal returns. It summarizes the current state of understanding for post-earnings-announcement drift and comments on delayed price response and CAPM misspecification to explain the drift. It examines the sample and some of the methods used in empirical tests.},
author = {Bernard, Victor L and Thomas, Jacob K},
doi = {10.2307/2491062},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bernard, Thomas - 1989 - Post-Earnings-Announcement Drift Delayed Price Response or Risk Premium.pdf:pdf},
isbn = {00218456},
issn = {00218456},
journal = {Journal of Accounting Research},
keywords = {A priori,BETA (Finance),CAPITAL -- Mathematical models,CAPITAL assets pricing model,CORPORATIONS -- Finance,ECONOMIC forecasting,FINANCE -- Mathematical models,INCOME forecasting,INVESTMENTS,METHODOLOGY,SAMPLING (Statistics),STANDARD deviations},
number = {1989},
pages = {1--36},
title = {{Post-Earnings-Announcement Drift: Delayed Price Response or Risk Premium?}},
volume = {27},
year = {1989}
}
@book{Cochrane2001,
abstract = {Every day, the financial markets bravely price trillions of dollars in such risky securities as stocks, bonds, options, futures, and derivatives. The systematic determination of their values-asset pricing-has developed dramatically in the last few years due to advances in financial theory and econometrics. In one of the most highly anticipated books in financial economics, John Cochrane unifies and brings this science up to date for the benefit of advanced students and professionals. Cochrane traces the pricing of all assets back to a single idea-price equals expected discounted payoff-that captures the macroeconomic risks underlying each security's value. By using a single, stochastic discount factor rather than a separate set of tricks for each asset class, Cochrane builds a unified account of modern asset pricing. He presents applications to stocks, bonds, and options. Each model-consumption-based, CAPM, multifactor, term structure, and option pricing-is derived as a different specification of the discount factor. The discount factor framework also leads to a state-space geometry for mean-variance frontiers and asset pricing models. It puts payoffs in different states of nature on the axes rather than mean and variance of return, leading to a new and conveniently linear geometrical representation of asset pricing ideas. Cochrane approaches empirical work with the Generalized Method of Moments, which studies sample average prices and discounted payoffs to determine whether price does equal expected discounted payoff. He translates between the discount factor, GMM, and state-space language and the beta, mean-variance, and regression language common in empirical work and earlier theory. The book also includes a review of recent empirical work on return predictability, value and other puzzles in the cross section, and equity premium puzzles and their resolution. Written to be a summary for academics and professionals as well as a textbook for advanced graduate students, this book condenses and advances recent scholarship in financial economics.},
author = {Cochrane, John H.},
doi = {10.1016/S1574-0722(07)00042-X},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Cochrane - 2001 - Asset Pricing.pdf:pdf},
isbn = {0691121370},
issn = {00029262},
pages = {438--454},
pmid = {16306313},
publisher = {Princeton University Press},
title = {{Asset Pricing}},
url = {http://www.citeulike.org/group/108/article/975777},
year = {2001}
}
@article{Conrad2012,
abstract = {We examine whether risk characteristics of stocks interact with return continuation and reversals. We find that a momentum portfolio whose winner stocks are chosen from high expected return securities, and whose loser stocks are chosen from low expected return securities, has significant momentum profits, but shows no evidence of subsequent reversals. In contrast, a momentum portfolio that buys low expected return winners and sells high expected return losers has no significant momentum but strong reversals. Overall, we find evidence that intermediate-horizon momentum and longer-horizon reversal patterns may not be linked. Our results have implications for several explanations of momentum profits.},
author = {Conrad, Jennifer S. and Yavuz, M. Deniz},
doi = {10.2139/ssrn.2011148},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Conrad, Yavuz - 2012 - Momentum and Reversal Does What Goes Up Always Come Down.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {behavioral finance,momentum,return predictability,reversal},
pages = {1--43},
title = {{Momentum and Reversal: Does What Goes Up Always Come Down?}},
url = {http://www.ssrn.com/abstract=2011148},
year = {2012}
}
@article{Abildgren2012,
author = {Abildgren, Kim},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Abildgren - 2012 - Business Cycles, Monetary Transmission and Shocks to Financial Stability - Empirical Evidence from a New Set of Danis.pdf:pdf},
journal = {ECB Working Paper Series},
keywords = {Danish economic history,Quarterly national accounts,VAR analysis.,band-pass filters,business cycles,financial stability,monetary transmission},
number = {1458},
pages = {1--77},
title = {{Business Cycles, Monetary Transmission and Shocks to Financial Stability - Empirical Evidence from a New Set of Danish Quarterly National Accounts 1948-2010}},
volume = {2012},
year = {2012}
}
@article{Stock20011,
author = {Stock, James H. and Watson, Mark W.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2011 - Dynamic Factor Models.pdf:pdf},
isbn = {9780195398649},
journal = {Oxford Handbook of Economic Forecasting},
number = {July},
pages = {1--43},
title = {{Dynamic Factor Models}},
url = {http://link.springer.com/article/10.1007/s10182-006-0219-z},
year = {2011}
}
@article{Orphanides2005,
author = {Orphanides, Athanasios and van Norden, Simon},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Orphanides, Norden - 2005 - The Reliability of Inflation Forecasts Based on Output Gap Estimates in Real Time.pdf:pdf},
journal = {Journal of Money, Credit, and Banking},
number = {3},
pages = {583--601},
title = {{The Reliability of Inflation Forecasts Based on Output Gap Estimates in Real Time}},
volume = {37},
year = {2005}
}
@article{Chee2013,
author = {Chee, S. and Sloan, R. and Uysal, A.},
doi = {10.1177/0312896213510715},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chee, Sloan, Uysal - 2013 - A Framework For Value Investing.pdf:pdf},
issn = {0312-8962},
journal = {Australian Journal of Management},
month = {dec},
number = {3},
pages = {599--633},
title = {{A Framework For Value Investing}},
url = {http://aum.sagepub.com/cgi/doi/10.1177/0312896213510715},
volume = {38},
year = {2013}
}
@article{Dupasquier1999,
abstract = {In this paper, we survey some techniques proposed in the literature to measure potential output. Given the reported shortcomings of univariate approaches and mechanical filters, we focus on three simple multivariate methodologies: the multivariate Beveridge-Nelson methodology (MBN), Cochrane's methodology (CO), and the structural VAR methodology with long-run restrictions (LRRO). These methodologies are presented and then applied to U.S. data. The results show that the LRRO estimates provide significant evidence that permanent shocks have more complex dynamics than the random walk assumed in CO and MBN approaches. As in other studies, estimates of the output gap remain imprecise.},
author = {Dupasquier, Chantal and Guay, Alain and St-Amant, Pierre},
doi = {10.1016/S0164-0704(99)00117-2},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Dupasquier, Guay, St-Amant - 1999 - A Survey of Alternative Methodologies for Estimating Potential Output and the Output Gap.pdf:pdf},
issn = {01640704},
journal = {Journal of Macroeconomics},
number = {3},
pages = {577--595},
title = {{A Survey of Alternative Methodologies for Estimating Potential Output and the Output Gap}},
volume = {21},
year = {1999}
}
@book{Edwards2007,
author = {Edwards, Robert D. and Magee, John},
edition = {9th},
editor = {W.H.C.Bassetti},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Edwards, Magee - 2007 - Technical Analysis of Stock Trends.pdf:pdf},
isbn = {9780849337727},
pages = {1--835},
publisher = {Taylor {\&} Francis Group},
title = {{Technical Analysis of Stock Trends}},
year = {2007}
}
@book{Kim1999,
author = {Kim, Chang-Jin and Nelson, Charles R.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kim, Nelson - 1999 - State-Space Models with Regime-Switching Classical and Gibbs Sampling Approaches with Applications.pdf:pdf},
pages = {1--297},
publisher = {MIT Press Books},
title = {{State-Space Models with Regime-Switching: Classical and Gibbs Sampling Approaches with Applications}},
year = {1999}
}
@book{Gentleman2011,
author = {Pfaff, Bernhard},
doi = {10.1007/978-1-4419-7976-6},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Pfaff - 2011 - Analysis of Integrated and Cointegrated Time Series with R.pdf:pdf},
isbn = {9781441979759},
pages = {154--197},
title = {{Analysis of Integrated and Cointegrated Time Series with R}},
year = {2011}
}
@article{Blake2012,
author = {Blake, Andrew and Mumtaz, Haroon},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Blake, Mumtaz - 2012 - Applied Bayesian Econometrics for Central Bankers.pdf:pdf},
keywords = {Applied,CCBS,Centre for central banking studies},
number = {4},
title = {{Applied Bayesian Econometrics for Central Bankers}},
url = {http://www.bankofengland.co.uk/education/Documents/ccbs/technical{\%}7B{\_}{\%}7Dhandbooks/pdf/techbook4.pdf},
year = {2012}
}
@article{Stock2006,
abstract = {Historically, time series forecasts of economic variables have used only a handful of predictor variables, while forecasts based on a large number of predictors have been the province of judgmental forecasts and large structural econometric models. The past decade, however, has seen considerable progress in the development of time series forecasting methods that exploit many predictors, and this chapter surveys these methods. The first group of methods considered is forecast combination (forecast pooling), in which a single forecast is produced from a panel of many forecasts. The second group of methods is based on dynamic factor models, in which the comovements among a large number of economic variables are treated as arising from a small number of unobserved sources, or factors. In a dynamic factor model, estimates of the factors (which become increasingly precise as the number of series increases) can be used to forecast individual economic variables. The third group of methods is Bayesian model averaging, in which the forecasts from very many models, which differ in their constituent variables, are averaged based on the posterior probability assigned to each model. The chapter also discusses empirical Bayes methods, in which the hyperparameters of the priors are estimated. An empirical illustration applies these different methods to the problem of forecasting the growth rate of the U.S. index of industrial production with 130 predictor variables. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1016/S1574-0706(05)01010-4},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2006 - Forecasting with Many Predictors.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
journal = {Handbook of Economic Forecasting},
keywords = {Bayesian model averaging,dynamic factor models,empirical Bayes forecasts,forecast combining,principal components analysis,shrinkage forecasts},
number = {05},
pages = {515--554},
title = {{Forecasting with Many Predictors}},
volume = {1},
year = {2006}
}
@article{Bartov2004,
author = {Bartov, Eli and Kim, Myungsun},
doi = {10.1023/B:REQU.0000049321.34133.95},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bartov, Kim - 2004 - Risk, Mispricing, and Value Investing.pdf:pdf},
issn = {0924-865X},
journal = {Review of Quantitative Finance and Accounting},
keywords = {accruals,book-to-market,g11,jel classification,m41,market efficiency,mispricing},
number = {4},
pages = {353--376},
title = {{Risk, Mispricing, and Value Investing}},
url = {http://link.springer.com/10.1023/B:REQU.0000049321.34133.95},
volume = {23},
year = {2004}
}
@article{Leamer1985,
author = {Leamer, Edward E.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Leamer - 1985 - Vector Autoregressions for Causal Inference.pdf:pdf},
journal = {Carnegie-Rochester Conference Series on Public Policy},
pages = {255--304},
title = {{Vector Autoregressions for Causal Inference?}},
volume = {22},
year = {1985}
}
@article{Carter1994,
author = {Carter, C. K. and Kohn, R},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Carter, Kohn - 1994 - On Gibbs Sampling for State Space Models.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {541--553},
title = {{On Gibbs Sampling for State Space Models}},
volume = {81},
year = {1994}
}
@article{Bernanke1991,
author = {Bernanke, Ben S. and Lown, Cara S. and Friedman, Benjamin M.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bernanke, Lown, Friedman - 1991 - The Credit Crunch.pdf:pdf},
journal = {Brookings Papers on Economic Activity},
number = {2},
pages = {205--247},
title = {{The Credit Crunch}},
volume = {1991},
year = {1991}
}
@article{Kuttner1992,
author = {Kuttner, Kenneth},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kuttner - 1992 - Monetary policy with uncertain estimates of potential output.pdf:pdf},
journal = {Federal Reserve Bank of Chicago Economic Perspectives},
number = {1},
pages = {2--15},
title = {{Monetary policy with uncertain estimates of potential output}},
volume = {16},
year = {1992}
}
@article{Gourinchas1999,
author = {Gourinchas, Pierre-Olivier and Vald{\'{e}}s, Rodrigo and Landerretche, Oscar},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gourinchas, Vald{\'{e}}s, Landerretche - 1999 - Lending Booms Some Stylized Facts.pdf:pdf},
journal = {IMF Seminar Series},
keywords = {1998,a previous version of,and macroeconomic stability,balance of payment crisis,bank,banking,banking crisis,chile,conference of the central,credit boom,financial integration,for the second annual,lending boom,macroeconomic performance,of chile,santiago,this paper was prepared,we thank},
pages = {1--58},
title = {{Lending Booms: Some Stylized Facts}},
volume = {35},
year = {1999}
}
@article{Koop2011,
abstract = {There are both theoretical and empirical reasons for believing that the parameters of macroeconomic models may vary over time. However, work with time-varying parameter models has largely involved vector autoregressions (VARs), ignoring cointegration. This is despite the fact that cointegration plays an important role in informing macroeconomists on a range of issues. In this paper, we develop a new time varying parameter model which permits cointegration. We use a specification which allows for the cointegrating space to evolve over time in a manner comparable to the random walk variation used with TVPVARs. The properties of our approach are investigated before developing a method of posterior simulation. We use our methods in an empirical investigation involving the Fisher effect. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Koop, Gary and Leon-Gonzalez, Roberto and Strachan, Rodney W.},
doi = {10.1016/j.jeconom.2011.07.007},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koop, Leon-Gonzalez, Strachan - 2011 - Bayesian inference in a time varying cointegration model.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Bayesian,Error correction model,Markov Chain Monte Carlo,Reduced rank regression,Time varying cointegration},
number = {2},
pages = {210--220},
pmid = {1273109},
title = {{Bayesian inference in a time varying cointegration model}},
volume = {165},
year = {2011}
}
@article{Hens2012,
author = {Hens, Thorsten},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hens - 2012 - Wann Momentum, wann Value.pdf:pdf},
journal = {Finanz und Wirtschaft},
number = {53},
pages = {2012},
title = {{Wann Momentum, wann Value?}},
volume = {2012},
year = {2012}
}
@article{Hamilton1983,
author = {Hamilton, James D.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hamilton - 1983 - Oil and the Macroeconomy since World War II.pdf:pdf},
journal = {Journal of Political Economy},
number = {2},
pages = {228--248},
title = {{Oil and the Macroeconomy since World War II}},
volume = {91},
year = {1983}
}
@article{Ghysels2004,
author = {Ghysels, Eric and Santa-Clara, Pedro and Valkanov, Rossen},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ghysels, Santa-Clara, Valkanov - 2004 - The MIDAS Touch Mixed Data Sampling Regression Models.pdf:pdf},
journal = {CIRANO Working Papers},
pages = {1--33},
title = {{The MIDAS Touch: Mixed Data Sampling Regression Models}},
volume = {20},
year = {2004}
}
@book{Godley2007a,
abstract = {Summary: This book challenges the mainstream paradigm, based on the inter-temporal optimisation of welfare by individual agents. It introduces a methodology for studying how it is institutions which create flows of income, expenditure and production together with stocks of assets and liabilities, thereby determining how whole economies evolve through time. This book challenges the mainstream paradigm, which is based on the inter-temporal optimisation of welfare by individual agents. It introduces a new methodology for studying how it is institutions (firms, banks, governments, foreigners and households) which create flows of income, expenditure and production together with stocks of assets (including money) and liabilities, thereby determining how whole economies evolve through time. It is a central contention that any realistic representation of a monetary economy must be grounded in a fully articulated system of national income and flow of funds accounts which is so complete that the nth variable is logically implied by the other n-1. As the financial balances of each sector have exact counterparts in changes in stock variables, historical time is introduced into the basic system of concepts, with asset and liability stocks providing the link between each period and each succeeding period. It is taken as axiomatic that decisions are based on expectations about the future reached under conditions of uncertainty, so for every sector there must exist at least one flexible option or "buffer" over which that sector has no direct control and which adjusts passively when expectations are falsified. For firms the buffer will normally take the form of inventories, for banks and governments it will be stocks of government securities, for households it will be stocks of credit money. Accordingly, outside financial markets there is neither need nor place for equilibrium conditions to bring supply into equivalence with demand. It will almost always be quantities rather than prices which give the signals which keep the economy on track. Starting with extremely simple stock flow consistent (SFC) models, the text describes a succession of increasingly complex models, using a conventional narrative style backed up by equations which bring precision to individual propositions. However, underlying each narrative there exists a simulation model constructed with such rigour that, in harmony with its basis in comprehensive accounting, there is always one equation which is implied logically by all the others. Solutions of these models are used to illustrate, with charts, ways in which whole economies evolve when shocked in various ways. Readers will be able to download all the models and explore their properties for themselves. A major conclusion is that economies require management via fiscal and monetary policy if full employment without inflation is to be achieved.},
author = {Godley, Wynne and Lavoie, Marc},
doi = {10.1007/978-1-137-08599-3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Godley, Lavoie - 2007 - Monetary Economics An Integrated Approach to Credit, Money, Income, Production and Wealth.pdf:pdf},
isbn = {9781137085993},
issn = {00130427},
pages = {1--530},
publisher = {Palgrave Macmillan},
title = {{Monetary Economics: An Integrated Approach to Credit, Money, Income, Production and Wealth}},
year = {2007}
}
@article{Gilchrist2012,
author = {Gilchrist, Simon and Zakraj{\v{s}}ek, Egon},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gilchrist, Zakraj{\v{s}}ek - 2012 - Credit Spreads and Business Cycle Fluctuations.pdf:pdf},
issn = {0002-8282},
journal = {American Economic Review},
number = {4},
pages = {1692--1720},
title = {{Credit Spreads and Business Cycle Fluctuations}},
volume = {102},
year = {2012}
}
@article{Gertler2013,
author = {Gertler, Mark and Karadi, Peter},
doi = {10.1016/j.jmoneco.2010.10.004},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gertler, Karadi - 2011 - A Model of Unconventional Monetary Policy.pdf:pdf},
isbn = {18154654},
issn = {18154654},
journal = {Journal of Monetary Economics},
number = {1},
pages = {17--34},
pmid = {1354554},
publisher = {Elsevier},
title = {{A Model of Unconventional Monetary Policy}},
url = {http://dx.doi.org/10.1016/j.jmoneco.2010.10.004},
volume = {58},
year = {2011}
}
@book{Napier2011,
author = {Wright, Stephen and Smithers, Andrew and Warburton, Peter and Pepper, Gordon and Goldberg, Joachim and Brodie, Herman and Riley, Barry and Napier, Russell},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Wright et al. - 2011 - Practical History of Financial Markets.pdf:pdf},
number = {1030},
publisher = {Edinburgh Business School},
title = {{Practical History of Financial Markets}},
volume = {2011},
year = {2011}
}
@book{Fernald2015,
abstract = {U.S. labor and total-factor productivity growth slowed prior to the Great Recession. The timing rules explanations that focus on disruptions during or since the recession, and industry and state data rule out “bubble economy” stories related to housing or finance. The slowdown is located in industries that produce information technology (IT) or that use IT intensively, consistent with a return to normal productivity growth after nearly a decade of exceptional IT-fueled gains. A calibrated growth model suggests trend productivity growth has returned close to its 1973-1995 pace. Slower underlying productivity growth implies less economic slack than recently estimated by the Congressional Budget Office. As of 2013, about ¾ of the shortfall of actual output from (overly optimistic) pre-recession trends reflects a reduction in the level of potential. (This abstract was borrowed from another version of this item.)},
author = {Fernald, John G.},
booktitle = {NBER Macroeconomics Annual},
doi = {10.1086/680580},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fernald - 2015 - Productivity and Potential Output before, during, and after the Great Recession.pdf:pdf},
isbn = {9780226268736},
issn = {0889-3365},
number = {1},
pages = {1--51},
title = {{Productivity and Potential Output before, during, and after the Great Recession}},
url = {http://www.journals.uchicago.edu/doi/10.1086/680580},
volume = {29},
year = {2015}
}
@article{DelNegro2011,
author = {{Del Negro}, Marco and Schorfheide, Frank},
journal = {The Oxford Handbook of Bayesian Econometrics},
pages = {293--389},
title = {{Bayesian Macroeconometrics}},
year = {2011}
}
@article{Conrad1997,
abstract = {In recent years, several researchers have argued that the stock market consistently overreacts to new information, which, in turn, results in price reversals. Lehmann and others showed that a contrarian can make substantial profits in the short run by simply buying losers and selling winners. We, however, demonstrate that these profits are largely generated by the bid-ask bounce in transaction prices; accounting for this "bounce" by using bid prices eliminates all profits from price reversals for NASDAQ-NMS stocks and most of the profits for NYSE/AMEX stocks. Moreover, any remaining profits (regardless of their source) disappear at trivial levels of transactions costs.},
author = {Conrad, Jennifer and Gultekin, Mustafa N and Kaul, Gautam},
doi = {10.2307/1392341},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Conrad, Gultekin, Kaul - 1997 - Profitability of Short-Term Contrarian Strategies Implications for Market Efficiency.pdf:pdf},
issn = {07350015},
journal = {Journal of Business {\&} Economic Statistics},
number = {3},
pages = {379--386},
title = {{Profitability of Short-Term Contrarian Strategies: Implications for Market Efficiency}},
volume = {15},
year = {1997}
}
@incollection{Barberis2003,
abstract = {Behavioral finance argues that some financial phenomena can plausibly be understood using models in which some agents are not fully rational. The field has two building blocks: limits to arbitrage, which argues that it can be difficult for rational traders to undo the dislocations caused by less rational traders; and psychology, which catalogues the kinds of deviations from full rationality we might expect to see. We discuss these two topics, and then present a number of behavioral finance applications: to the aggregate stock market, to the cross-section of average returns, to individual trading behavior, and to corporate finance. We close by assessing progress in the field and speculating about its future course.},
author = {Barberis, Nicholas and Thaler, Richard},
booktitle = {Handbook of the Economics of Finance},
doi = {10.2139/ssrn.327880},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Barberis, Thaler - 2003 - A Survey of Behavioral Finance.pdf:pdf},
isbn = {1574-0102},
issn = {1556-5068},
pages = {1053--1128},
title = {{A Survey of Behavioral Finance}},
volume = {1},
year = {2003}
}
@article{Boudoukh1994,
author = {Boudoukh, Jacob and Richardson, Matthew P and Whitelaw, Robert F},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Boudoukh, Richardson, Whitelaw - 1994 - A Tale of Three Schools Insights on Autocorrelations of Short-Horizon Stock Return.pdf:pdf},
journal = {The Review of Financial Studies},
number = {3},
pages = {539--573},
title = {{A Tale of Three Schools: Insights on Autocorrelations of Short-Horizon Stock Return}},
volume = {7},
year = {1994}
}
@article{Kuttner1994,
abstract = {This article proposes a new method for estimating potential output in which potential real gross domestic product (GDP) is modeled as an unobserved stochastic trend, and deviations of GDP from potential affect inflation through an aggregate supply relationship. The output and inflation equations together form a bivariate unobserved-components model which is estimated via max- imum likelihood through the use of the Kalman-filter algorithm. The procedure yields a measure of potential output and its standard error and an estimate of the quantitative response of inflation to real growth and the output gap.},
author = {Kuttner, Kenneth N.},
doi = {10.1080/07350015.1994.10524551},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kuttner - 1994 - Estimating Potential Output as a Latent Variable.pdf:pdf},
issn = {15372707},
journal = {Journal of Business and Economic Statistics},
keywords = {Inflation,Kalman filter,Phillips curve,Stochastic detrending,Unobserved- components models},
number = {3},
pages = {361--368},
title = {{Estimating Potential Output as a Latent Variable}},
volume = {12},
year = {1994}
}
@article{Chui2010,
abstract = {This paper examines how cultural differences influence the returns of momentum strategies. Cross-country cultural differences are measured with an individualism index developed by Hofstede (2001), which is related to overconfidence and self-attribution bias. We find that individualism is positively associated with trading volume and volatility, as well as to the magnitude of momentum profits. Momentum profits are also positively related to analyst forecast dispersion, transaction costs, and the familiarity of the market to foreigners, and negatively related to firm size and volatility. However, the addition of these and other variables does not dampen the relation between individualism and momentum profits.},
author = {Chui, Andy C. W. and Titman, Sheridan and Wei, K. C. John},
doi = {10.1111/j.1540-6261.2009.01532.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chui, Titman, Wei - 2010 - Individualism and Momentum Around the World.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
keywords = {ENGL},
number = {1},
pages = {361--392},
pmid = {47446014},
title = {{Individualism and Momentum Around the World}},
volume = {65},
year = {2010}
}
@article{Hirakata2011,
author = {Hirakata, Naohisa and Sudo, Nao and Ueda, Kozo},
doi = {10.1016/j.jedc.2011.08.007},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hirakata, Sudo, Ueda - 2011 - Do banking shocks matter for the U.S. economy.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {Chained credit contracts,Financial accelerators,Financial intermediaries,Monetary policy},
month = {dec},
number = {12},
pages = {2042--2063},
publisher = {Elsevier},
title = {{Do banking shocks matter for the U.S. economy?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165188911001576},
volume = {35},
year = {2011}
}
@article{Fama1965a,
abstract = {This article describes, briefly and simply, the theory of random walks and some of the important issues it raises concerning the work of market analysts. One important model that has evolved from developing and testing models of stock price behavior is the theory of random walks. This theory casts serious doubt on many other methods for describing and predicting stock price behavior--methods that have considerable popularity outside the academic world. In general, the theory of random walks raises challenging questions for anyone who has more than a passing interest in understanding the behavior of stock prices. Unfortunately, however, most discussions of the theory have appeared in technical academic journals and in a form which the non-mathematician would usually find incomprehensible. Essentially, then, chartist techniques attempt to use knowledge of the past behavior of a price series to predict the probable future behavior of the series. The techniques of the chartist have always been surrounded by a certain degree of mysticism, however, and as a result most market professionals have found them suspect.},
author = {Fama, Eugene F.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama - 1965 - Random Walks in Stock Market Prices.pdf:pdf},
isbn = {0015198X},
journal = {Financial Analysts Journal},
keywords = {COST control,INVESTMENT analysis,MARKET prices,MONEY market,RANDOM walks (Mathematics),STOCKS (Finance) -- Prices},
number = {5},
pages = {55--59},
pmid = {7589211},
title = {{Random Walks in Stock Market Prices}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=buh{\&}AN=7589211{\&}site=ehost-live},
volume = {21},
year = {1965}
}
@article{Koop2016,
abstract = {Macroeconomists are increasingly working with large Vector Autoregressions (VARs) where the number of parameters vastly exceeds the number of observations. Existing approaches either involve prior shrinkage or the use of factor methods. In this paper, we develop an alternative based on ideas from the compressed regression literature. It involves randomly compressing the explanatory variables prior to analysis. A huge dimensional problem is thus turned into a much smaller, more computationally tractable one. Bayesian model averaging can be done over various compressions, attaching greater weight to compressions which forecast well. In a macroeconomic application involving up to 129 variables, we find compressed VAR methods to forecast better than either factor methods or large VAR methods involving prior shrinkage.},
author = {Koop, Gary},
doi = {10.2139/ssrn.2754241},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koop - 2016 - Bayesian Compressed Vector Autoregressions(2).pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {forecasting,multivariate time series,random projection},
pages = {1--60},
title = {{Bayesian Compressed Vector Autoregressions}},
url = {http://papers.ssrn.com/abstract=2754241},
year = {2016}
}
@book{EuropeanCommission2008,
abstract = {The System of National Accounts, 2008 (2008 SNA) is a statistical framework that provides a comprehensive, consistent and flexible set of macroeconomic accounts for policymaking, analysis and research purposes. It has been produced and is released under the auspices of the United Nations, the European Commission, the Organisation for Economic Co-operation and Development, the International Monetary Fund and the World Bank Group. It represents an update, mandated by the United Nations Statistical Commission in 2003, of the System of National Accounts, 1993, which was produced under the joint responsibility of the same five organizations. Like earlier editions, the 2008 SNA reflects the evolving needs of its users, new developments in the economic environment and advances in methodological research.A working group, comprising representatives of each of our organizations, managed and coordinated the work. National statistical offices and central banks from countries throughout the world made valuable contributions. Expert groups carried out research on the issues being reviewed. An advisory expert group was established to provide expert opinions from a broad range of countries. During the update work, the recommendations and the updated text were posted on the website of the United Nations Statistics Division for worldwide comment, thereby achieving full transparency in the process.The 2008 SNA is intended for use by all countries, having been designed to accommodate the needs of countries at different stages of economic development. It also provides an overarching framework for standards in other domains of economic statistics, facilitating the integration of these statistical systems to achieve consistency with national accounts.At its fortieth session, the Statistical Commission unanimously adopted the 2008 SNA as the international statistical standard for national accounts. We encourage all countries to compile and report their national accounts on the basis of the 2008 SNA as soon as possible.},
author = {{European Commission} and {International Monetary Funds} and {Organisation for Economic Co-operation and Development} and {United Nations} and {World Bank}},
doi = {10.1057/ukna.2008.3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/European Commission et al. - 2008 - The System of National Accounts 2008.pdf:pdf},
isbn = {978-92-1-161522-7},
issn = {0267-8691},
pages = {1--722},
pmid = {12870},
title = {{The System of National Accounts 2008}},
url = {http://unstats.un.org/unsd/nationalaccount/sna2008.asp},
year = {2008}
}
@article{Imbens2009,
author = {Imbens, Guido W. and Wooldridge, Jeffrey M.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Imbens, Wooldridge - 2009 - Recent Developments in the Econometrics of Program Evaluation.pdf:pdf},
journal = {Journal of Economic Literature},
number = {1},
pages = {5--86},
title = {{Recent Developments in the Econometrics of Program Evaluation}},
volume = {47},
year = {2009}
}
@article{Lakonishok1994,
abstract = {For many years, scholars and investment professionals have argued that value strategies outperform the market. These value strategies call for buying stocks that have low prices relative to earnings, dividends, book assets, or other measures of fundamental value. While there is some agreement that value strategies produce higher returns, the interpretation of why they do so is more controversial. This article provides evidence that value strategies yield higher returns because these strategies exploit the suboptimal behavior of the typical investor and not because these strategies are fundamentally riskier.},
author = {Lakonishok, Josef and Shleifer, Andrei and Vishny, Rw Robert W},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lakonishok, Shleifer, Vishny - 1994 - Contrarian investment, extrapolation, and risk.pdf:pdf},
journal = {Journal of Finance},
number = {5},
pages = {1541--1578},
publisher = {Blackwell Publishing Ltd},
title = {{Contrarian investment, extrapolation, and risk}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1994.tb04772.x/full{\%}5Cnhttp://dx.doi.org/10.1111/j.1540-6261.1994.tb04772.x},
volume = {49},
year = {1994}
}
@article{Hong1999a,
abstract = {We model a market populated by two groups of boundedly rational agents: "newswatchers" and "momentum traders." Each newswatcher observes some private information, but fails to extract other newswatchers' information from prices. If information diffuses gradually across the population, prices underreact in the short run. The underreaction means that the momentum traders can profit by trend-chasing. However, if they can only implement simple (i.e., univariate) strategies, their attempts at arbitrage must inevitably lead to overreaction at long horizons. In addition to providing a unified account of under- and overreactions, the model generates several other distinctive implications.},
author = {Hong, Harrison and Stein, Jeremy C},
doi = {doi:10.1111/0022-1082.00184},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hong, Stein - 1999 - A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets.pdf:pdf},
isbn = {1540-6261},
issn = {0022-1082},
journal = {The Journal of Finance},
number = {6},
pages = {2143--2184},
title = {{A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets}},
url = {http://www.blackwell-synergy.com/doi/abs/10.1111/0022-1082.00184},
volume = {54},
year = {1999}
}
@article{Reinhart2000,
author = {Reinhart, Vincent and Sack, Brian},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Reinhart, Sack - 2000 - The Economic Consequences of Disappearing Government Debt.pdf:pdf},
issn = {1533-4465},
journal = {Brookings Papers on Economic Activity},
number = {2},
pages = {163--209},
title = {{The Economic Consequences of Disappearing Government Debt}},
volume = {31},
year = {2000}
}
@article{Orphanides2000,
abstract = {We exploit data on historical revisions to real-time estimates of the output gap to examine the implications of measurement error for the design of monetary policy, using the Federal Reserve's model of the U.S. economy, FRB/US. Measurement error brings about a substantial deterioration in economic performance, although the problem can be mitigated somewhat by reducing the coefficient on the output gap in policy rules. We also show that it is usually optimal to place some weight on the level of the output gap in the conduct of policy, but under extreme conditions it may be preferable to focus on output growth.},
author = {Orphanides, Athanasios and Porter, Richard D and Reifschneider, David and Tetlow, Robert and Finan, Frederico},
doi = {10.1016/S0148-6195(99)00031-4},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Orphanides et al. - 2000 - Errors in the measurement of the output gap and the design of monetary policy.pdf:pdf},
isbn = {0148-6195},
issn = {01486195},
journal = {Journal of Economics and Business},
keywords = {{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_},and an anonymous,brian sack,dale henderson,david lindsey,david small,donald kohn,interest rate rules,joel wesley,john williams,lewis alexander,michael prell,output gap measurement,policy evaluation,the authors would like,to thank,without implication},
number = {1-2},
pages = {117--141},
title = {{Errors in the measurement of the output gap and the design of monetary policy}},
volume = {52},
year = {2000}
}
@incollection{Jacquier2010,
abstract = {Bayesian Methods in Finance provides a detailed overview of the theory of Bayesian methods and explains their real-world applications to financial modeling. While the principles and concepts explained throughout the book can be used in financial modeling and decision making in general, the authors focus on portfolio management and market risk management - since these are the areas in finance where Bayesian methods have had the greatest penetration to date},
author = {Jacquier, Eric and Polson, Nicholas},
booktitle = {The Oxford Handbook of Bayesian Econometrics},
editor = {Geweke, John and Koop, Gary and {Van Dijk}, Herman},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jacquier, Polson - 2010 - Bayesian Methods in Finance.pdf:pdf},
isbn = {9780471920830},
keywords = {Finanzas,Modelos matem{\'{a}}ticos,teoria bayesiana de decisiones estad{\'{i}}sticas},
number = {September},
pages = {33--61},
title = {{Bayesian Methods in Finance}},
year = {2010}
}
@article{Stock2010,
author = {Stock, James H.},
doi = {10.1257/jep.24.2.83},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock - 2010 - The Other Transformation in Econometric Practice Robust Tools for Inference.pdf:pdf},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
month = {may},
number = {2},
pages = {83--94},
title = {{The Other Transformation in Econometric Practice: Robust Tools for Inference}},
url = {http://pubs.aeaweb.org/doi/abs/10.1257/jep.24.2.83},
volume = {24},
year = {2010}
}
@article{Primiceri2014,
author = {Primiceri, Giorgio},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Primiceri - 2014 - Time-Varying Structural Vector Autoregressions and Monetary Policy A Corrigendum.pdf:pdf},
number = {October},
title = {{Time-Varying Structural Vector Autoregressions and Monetary Policy: A Corrigendum}},
year = {2014}
}
@article{Fuchs-Schuendeln2015,
author = {Fuchs-Schuendeln, Nicola and Hassan, Tarek Alexander},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fuchs-Schuendeln, Hassan - 2015 - Natural Experiments in Macroeconomics.pdf:pdf},
journal = {NBER Working Paper No. 21228},
title = {{Natural Experiments in Macroeconomics}},
year = {2015}
}
@article{Rudebusch1998b,
author = {Rudebusch, Glenn D.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rudebusch - 1998 - Do Measures of Monetary Policy in a Var Make Sense A Reply to Christopher A. Sims.pdf:pdf},
journal = {International Economic Review},
number = {4},
pages = {943--948},
title = {{Do Measures of Monetary Policy in a Var Make Sense? A Reply to Christopher A. Sims}},
volume = {39},
year = {1998}
}
@article{Rottmann2013,
author = {Rottmann, Horst and Wollmersh{\"{a}}user, Timo},
doi = {10.1080/00036846.2012.665604},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Rottmann, Wollmersh{\"{a}}user - 2013 - A Micro Data Approach to the Identification of Credit Crunches.pdf:pdf},
issn = {0003-6846},
journal = {Applied Economics},
month = {jun},
number = {17},
pages = {2423--2441},
title = {{A Micro Data Approach to the Identification of Credit Crunches}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00036846.2012.665604},
volume = {45},
year = {2013}
}
@article{Hong2000,
author = {Hong, Harrison and Lim, Terence and Stein, Jeremy C},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hong, Lim, Stein - 2000 - Bad News Travels Slowly Size, Analyst Coverage, and the Profitability of Momentum Strategies.pdf:pdf},
journal = {Journal of Finance},
number = {1},
pages = {265--295},
title = {{Bad News Travels Slowly: Size, Analyst Coverage, and the Profitability of Momentum Strategies}},
volume = {55},
year = {2000}
}
@article{Garratt2003,
author = {Garratt, Anthony and Lee, Kevin and Pesaran, M. Hashem and Shin, Yongcheol},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Garratt et al. - 2003 - A Long Run Structural Macroeconometric Model of the UK.pdf:pdf},
journal = {The Economic Journal},
keywords = {bias,cross-section dependence,lm test,panel model,spatial dependence},
number = {487},
pages = {412--455},
title = {{A Long Run Structural Macroeconometric Model of the UK}},
volume = {113},
year = {2003}
}
@article{Apel1999,
author = {Apel, Mikael and Jansson, Per},
doi = {10.1016/S0165-1765(99)00111-1},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Apel, Jansson - 1999 - A theory-consistent system approach for estimating potential output and the NAIRU.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {c32,e32,jel classification,nairu,okun,phillips curve,potential output,s law,unobserved-components models},
number = {3},
pages = {271--275},
title = {{A theory-consistent system approach for estimating potential output and the NAIRU}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176599001111},
volume = {64},
year = {1999}
}
@article{Cecchetti2008,
author = {Cecchetti, Stephen G and Li, Hong},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Cecchetti, Li - 2008 - Measuring the Impact of Asset Price Booms Using Quantile Vector Autoregressions.pdf:pdf},
journal = {Brandeis University Working Paper Series},
number = {2},
pages = {1--48},
title = {{Measuring the Impact of Asset Price Booms Using Quantile Vector Autoregressions}},
volume = {2008},
year = {2008}
}
@article{Barlevy2004,
author = {Barlevy, Gadi},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Barlevy - 2004 - The Cost of Business Cycles under Endogenous Growth.pdf:pdf},
journal = {American Economic Review},
number = {4},
pages = {964--990},
title = {{The Cost of Business Cycles under Endogenous Growth}},
volume = {94},
year = {2004}
}
@article{Zaremba2014,
author = {Zaremba, Adam},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Zaremba - 2014 - Country Value Premiums and Financial Crises.pdf:pdf},
journal = {International Journal of Finance and Banking Studies},
keywords = {2014 published by ssbfnet,financial crisis,inter-country variation in stock,returns,value premium},
number = {1},
pages = {12--50},
title = {{Country Value Premiums and Financial Crises}},
volume = {3},
year = {2014}
}
@article{Daniel2012,
author = {Daniel, Kent and Titman, Sheridan},
doi = {10.1561/104.00000003},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Daniel, Titman - 2012 - Testing Factor-Model Explanations of Market Anomalies.pdf:pdf},
issn = {21645744},
journal = {Critical Finance Review},
number = {1},
pages = {103--139},
title = {{Testing Factor-Model Explanations of Market Anomalies}},
volume = {2012},
year = {2012}
}
@article{Percy1992,
author = {Percy, David F.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Percy - 1992 - Prediction for Seemingly Unrelated Regressions.pdf:pdf},
journal = {Journal of the Royal Statistical Society},
keywords = {bayes estimate,gibbs sampling,predictive density function,seemingly,unrelated regressions},
number = {1},
pages = {243--252},
title = {{Prediction for Seemingly Unrelated Regressions}},
volume = {54},
year = {1992}
}
@article{Luciani2017,
author = {Barigozzi, Matteo and Luciani, Matteo},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Barigozzi, Luciani - 2017 - Common Factors, Trends, and Cycles in Large Datasets.pdf:pdf},
journal = {Finance and Economics Discussion Series},
title = {{Common Factors, Trends, and Cycles in Large Datasets}},
volume = {111},
year = {2017}
}
@article{McCracken2016a,
abstract = {This paper describes a large, monthly frequency, macroeconomic database with the goal of establishing a convenient starting point for empirical analysis that requires " big data. " The dataset mimics the coverage of those already used in the literature but has three appealing features. First, it is designed to be updated monthly using the FRED database. Second, it will be publicly accessible, facilitating comparison of related research and replication of empirical work. Third, it will relieve researchers from having to manage data changes and revisions. We show that factors extracted from our dataset share the same predictive content as those based on various vintages of the so-called Stock-Watson dataset. In addition, we suggest that diffusion indexes constructed as the partial sum of the factor estimates can potentially be useful for the study of business cycle chronology.},
author = {McCracken, Michael W. and Ng, Serena},
doi = {10.1080/07350015.2015.1086655},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/McCracken, Ng - 2016 - FRED-MD A Monthly Database for Macroeconomic Research.pdf:pdf},
issn = {15372707},
journal = {Journal of Business and Economic Statistics},
keywords = {Big data,Diffusion index,Factors,Forecasting},
number = {4},
pages = {574--589},
title = {{FRED-MD: A Monthly Database for Macroeconomic Research}},
volume = {34},
year = {2016}
}
@article{Proietti2007,
abstract = {This paper provides an analysis of multivariate unobserved compo- nents models for the estimation of potential output and the output gap in the euro area. Bivariate models of output and inflation and multivariate model- based implementations of the production function approach are considered; according to the latter potential output is derived from the permanent com- ponents of the factors of production consistent with stable inflation, whereas the output gap results from the combination of the transitory components. This approach allows to measure the contribution of the various factors of pro- duction to potential output growth, and to assess the reliability of the output gap estimates.Various alternative statistical specifications for the separation of trend and cycle are considered entertaining different economic hypotheses.The paper also provides an assessment of the reliability of the alternative output gap estimates and analyses their predictive validity by means of a rolling forecast exercise that provides an evaluation of the capability to forecast future inflation},
author = {Proietti, Tommaso and Musso, Alberto and Westermann, Thomas},
doi = {10.1007/s00181-006-0085-2},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Proietti, Musso, Westermann - 2007 - Estimating potential output and the output gap for the euro area A model-based production function.pdf:pdf},
isbn = {0018100600},
issn = {03777332},
journal = {Empirical Economics},
keywords = {Inflation forecasts,Phillips curve,Reliability,Unobserved components},
number = {1},
pages = {85--113},
title = {{Estimating potential output and the output gap for the euro area: A model-based production function approach}},
volume = {33},
year = {2007}
}
@article{Carriero2015,
abstract = {This paper develops a method for producing current-quarter forecasts of GDP growth with a (possibly large) range of available within-the-quarter monthly observations of economic indicators, such as employment and industrial production, and financial indicators, such as stock prices and interest rates. In light of existing evidence of time variation in the variances of shocks to GDP, we consider versions of the model with both constant variances and stochastic volatility. We also evaluate models with either constant or time-varying regression coefficients. We use Bayesian methods to estimate the model, in order to facilitate providing shrinkage on the (possibly large) set of model parameters and conveniently generate predictive densities. We provide results on the accuracy of nowcasts of real-time GDP growth in the U.S. from 1985 through 2011. In terms of point forecasts, our proposal is comparable to alternative econometric methods and survey forecasts. In addition, it provides reliable density forecasts, for which the stochastic volatility specification is quite useful, while parameter time-variation does not seem to matter.},
author = {Carriero, Andrea and Clark, Todd E. and Marcellino, Massimiliano},
doi = {10.1111/rssa.12092},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Carriero, Clark, Marcellino - 2015 - Realtime nowcasting with a Bayesian mixed frequency model with stochastic volatility.pdf:pdf},
issn = {1467985X},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Bayesian methods,Forecasting,Mixed frequency models,Prediction},
number = {4},
pages = {837--862},
title = {{Realtime nowcasting with a Bayesian mixed frequency model with stochastic volatility}},
volume = {178},
year = {2015}
}
@article{Scarpetta2002,
author = {Scarpetta, Stefano and Hemmings, Philip and Tressel, Thierry and Woo, Jaejoon},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Scarpetta et al. - 2002 - ECO WKP ( 2002 ) 15 Unclassified All Economics Department Working Papers are now available through OECD ' s I.pdf:pdf},
pages = {1--65},
title = {{ECO / WKP ( 2002 ) 15 Unclassified All Economics Department Working Papers are now available through OECD ' s Internet Web site at}},
year = {2002}
}
@book{Press2007,
author = {Press, William and Teukolsky, Saul and Vetterling, William and Flannery, Brian},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Press et al. - 2007 - Numerical Recipes.pdf:pdf},
isbn = {9780521880688},
pages = {1--1262},
title = {{Numerical Recipes}},
year = {2007}
}
@article{Bruno2016,
abstract = {The crisis happened in the world in the last years, describing a whole of interdependencies and interactions, highlighted the theory's fundamental flaws of neoclassical economic theory: its unedifying focus on prediction and, above all, its inability to explain how the economy really works. It is the time to investigate economic phenomena not as derived from deterministic, predictable and mechanistic dynamics, but as history-dependent, organic and always evolving processes. Because this view implies new challenges and opportunities for policy, we will focus the attention on innovative components of Complexity Theory for the study of economics and the evaluation of public policies.},
author = {Bruno, Bruna and Faggini, Marisa and Parziale, Anna},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bruno, Faggini, Parziale - 2016 - Complexity Modelling in Economics The State of Art.pdf:pdf},
issn = {2049-3509},
journal = {Economic Thought},
keywords = {complex systems,economics,public policies},
pages = {29--43},
title = {{Complexity Modelling in Economics: The State of Art}},
year = {2016}
}
@article{Giannone2015,
abstract = {Recent studies using long-run restrictions question the valid- ity of the technology-driven real business cycle hypothesis. We propose an alternative identification that maximizes the contribution of technology shockstotheforecast-errorvarianceoflaborproductivityatalongbutfinite horizon. In small-sample Monte Carlo experiments, our identification out- performs standard long-run restrictions by significantly reducing the bias in the short-run impulse responses and raising their estimation precision. Unlike its long-run restriction counterpart, when our Max Share identifica- tion technique is applied to U.S. data, it delivers the robust result that hours worked responds negatively to positive technology shocks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Giannone, Domenico and Lenza, Michele and Primicieri, Giorgio E.},
doi = {10.1162/REST},
eprint = {arXiv:1011.1669v3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Giannone, Lenza, Primicieri - 2015 - Prior Selection for Vector Autoregression.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {2},
pages = {436--451},
pmid = {21860536},
title = {{Prior Selection for Vector Autoregression}},
volume = {97},
year = {2015}
}
@article{Morrow2001,
author = {Morrow, Kieran Mc and Roeger, Werner},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Morrow, Roeger - 2001 - Potential Output Measurement Methods, New Economy Influences and Scenarios for 2001-2010-A Comparison of the EU-.pdf:pdf},
journal = {European Commission Economic Papers},
title = {{Potential Output: Measurement Methods," New" Economy Influences and Scenarios for 2001-2010-A Comparison of the EU-15 and the US}},
url = {http://ideas.repec.org/p/euf/ecopap/0150.html},
volume = {150},
year = {2001}
}
@article{Chen2008,
author = {Chen, L and Petkova, R and Zhang, L},
doi = {10.1016/j.jfineco.2007.04.001},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chen, Petkova, Zhang - 2008 - The expected value premium☆.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {dividend growth,growth,time-varying expected returns,value},
month = {feb},
number = {2},
pages = {269--280},
title = {{The expected value premium☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304405X07002139},
volume = {87},
year = {2008}
}
@article{Sorenson1970,
abstract = {This discussion is directed to least-squares estimation theory, from its inception by Gauss1 to its modern form, as developed by Kalman.2 To aid in furnishing the desired perspective, the contributions and insights provided by Gauss are described and related to developments that have appeared more recently (that is, in the 20th century). In the author's opinion, it is enlightening to consider just how far (or how little) we have advanced since the initial developments and to recognize the truth in the saying that we ``stand on the shoulders of giants.''},
author = {Sorenson, H. W.},
doi = {10.1109/MSPEC.1970.5213471},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sorenson - 1970 - Least-Squares Estimation. From Gauss To Kalman.pdf:pdf},
issn = {00189235},
journal = {IEEE Spectrum},
number = {7},
pages = {63--68},
title = {{Least-Squares Estimation. From Gauss To Kalman}},
volume = {7},
year = {1970}
}
@incollection{Sevestre2002,
author = {Sevestre, Patrick and Worms, Andreas and Ehrmann, Michael and Gambacorta, Leonardo and Mart{\'{i}}nez-Pag{\'{e}}s, Jorge},
booktitle = {Monetary Policy Transmission in the Euro Area},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sevestre et al. - 2003 - Financial Systems and the Role of Banks in Monetary Policy Transmission.pdf:pdf},
number = {November},
pages = {235--269},
title = {{Financial Systems and the Role of Banks in Monetary Policy Transmission}},
year = {2003}
}
@article{Kinsella2011,
abstract = {The crisis has exposed the failure of economic models to deal sensibly with endogenously generated crises propagating from the financial sectors to the real economy, and back again. The goal of this paper is to review the method of stock flow consistent modeling to highlight areas in which it is deficient. I argue there is a fruitful research agenda in shoring up these deficiencies. The objective of stock flow modeling should be the ability to practically model unstable macroeconomies, and in particular their interactions with the financial sector. These models should provide 'Words to the Wise', and until they do, they are just thought experiments.},
author = {Kinsella, Stephen},
doi = {10.2139/ssrn.1955613},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kinsella - 2011 - Words to the Wise Stock Flow Consistent Modeling of Financial Instability.pdf:pdf},
issn = {1556-5068},
journal = {Geary Institute, University College Dublin, Working Papers: 201130, 2011, 14 pp.},
keywords = {Bankruptcy,Business Fluctuations,Credit,Cycles (E32),Instability,Liquidation (G33),Money Multipliers (E51),Money Supply,Prices,and Cycles: Forecas,finance,stock flow consistent models},
number = {November},
pages = {14},
title = {{Words to the Wise: Stock Flow Consistent Modeling of Financial Instability}},
url = {http://search.proquest.com/docview/913432355?accountid=13042{\%}5Cnhttp://ssrn.com/abstract=1955613},
year = {2011}
}
@article{Forni2016a,
author = {Forni, Mario and Giovannelli, Alessandro and Lippi, Marco and Soccorsi, Stefano},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Forni et al. - 2016 - Dynamic Factor Model with Infinite Dimensional Factor Space Forecasting(2).pdf:pdf},
journal = {Working Paper},
number = {March},
pages = {1--44},
title = {{Dynamic Factor Model with Infinite Dimensional Factor Space: Forecasting}},
year = {2016}
}
@article{Bruder2011,
abstract = {The efficient market hypothesis implies that all available information is reflected in current prices, and thus that future returns are unpredictable. Nevertheless, this assumption has been rejected in a large number of academic studies. It is commonly accepted that financial assets may exhibit trends or cycles. Some studies cite slow-moving economic variables related to the business cycle as an explanation for these trends. Other research argues that investors are not fully rational, meaning that prices may underreact in the short run and overreact at long horizons. Momentum strategies try to benefit from these trends. There are two opposing types: trend following and contrarian. Trend following strategies are momentum strategies in which an asset is purchased if the price is rising, while in the contrarian strategy assets are sold if the price is falling. The first step in both strategies is trend estimation, which is the focus of this paper. After a review of trend filtering techniques, we address practical issues, depending on whether trend detection is designed to explain the past or forecast the future.},
author = {Bruder, Benjamin and Dao, Tung-Lam and Richard, Jean-Charles and Roncalli, Thierry},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bruder et al. - 2011 - Trend Filtering Methods for Momentum Strategies.pdf:pdf},
journal = {Lyxor White Papers},
number = {8},
pages = {64},
title = {{Trend Filtering Methods for Momentum Strategies}},
year = {2011}
}
@article{Lutkepohl2013,
author = {L{\"{u}}tkepohl, Helmut and Staszewska-bystrova, Anna and Winker, Peter},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/L{\"{u}}tkepohl, Staszewska-bystrova, Winker - 2013 - Comparison of Methods for Constructing Joint Confidence Bands for Impulse Response Funct.pdf:pdf},
isbn = {4964212823},
title = {{Comparison of Methods for Constructing Joint Confidence Bands for Impulse Response Functions Comparison of Methods for Constructing}},
year = {2013}
}
@article{Lakonishok1994a,
abstract = {For many years, scholars and investment professionals have argued that value strategies outperform the market. These value strategies call for buying stocks that have low prices relative to earnings, dividends, book assets, or other measures of fundamental value. While there is some agreement that value strategies produce higher returns, the interpretation of why they do so is more controversial. This article provides evidence that value strategies yield higher returns because these strategies exploit the suboptimal behavior of the typical investor and not because these strategies are fundamentally riskier.},
author = {Lakonishok, Josef and Shleifer, Andrei and Vishny, Robert W.},
doi = {10.1111/j.1540-6261.1994.tb04772.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lakonishok, Shleifer, Vishny - 1994 - Contrarian Investment, Extrapolation, and Risk(2).pdf:pdf},
isbn = {1540-6261},
issn = {00221082},
journal = {The Journal of Finance},
number = {5},
pages = {1541--1578},
title = {{Contrarian Investment, Extrapolation, and Risk}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.1994.tb04772.x},
volume = {49},
year = {1994}
}
@book{Petris2008,
author = {Petris, Giovanni and Petrone, Sonia and Campagnoli, Patrizia},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Petris, Petrone, Campagnoli - 2008 - Dynamic Linear Models with R.pdf:pdf},
isbn = {978-0-387-77237-0},
pages = {252},
publisher = {Springer},
title = {{Dynamic Linear Models with R}},
url = {http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-77237-0},
year = {2008}
}
@article{Daniel1997,
author = {Daniel, Kent and Hirshleifer, David and Subrahmanyam, Avanidhar},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Daniel, Hirshleifer, Subrahmanyam - 1997 - A Theory of Overconfidence, Self-Attribution, and Security Market Under- and Overreactions.pdf:pdf},
title = {{A Theory of Overconfidence, Self-Attribution, and Security Market Under- and Overreactions}},
year = {1997}
}
@article{Data1994,
abstract = {Time-series forecasts are used in a wide range of economic activities, including setting monetary and fiscal policies, state and local budgeting, financial management, and financial engineering. Key elements of economic forecasting include selecting the fore- casting model(s) appropriate for the problem at hand, assessing and communicating the uncertainty asso- ciated with a forecast, and guarding against model instability.},
author = {Watson, Mark W.},
doi = {DOI: 10.1016/B0-08-043076-7/00526-X},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Watson - 2001 - Time Series Economic Forecasting.pdf:pdf},
isbn = {978-0-08-043076-8},
journal = {International Encyclopedia of the Social {\&} Behavioral Sciences},
pages = {15721--15724},
title = {{Time Series: Economic Forecasting}},
year = {2001}
}
@article{Fama1965b,
abstract = {This paper discusses the theory of random-walk model and then tests the model's empirical validity. The main conclusion will be that the data seem to present consistent and strong support for the model. This implies, of course, that chart reading, though perhaps an interesting pastime, is of no real value to the stock market investor. This is an extreme statement and the chart reader is certainly free to take exception. Since the empirical evidence produced by this and other studies in support of the random-walk model is now so voluminous, the counterarguments of the chart reader will be completely lacking in force if they are not equally well supported by empirical work. By contrast the stock market trader has a much more practical criterion for judging what constitutes important dependence in successive price changes. For his purposes the random walk model is valid as long, as knowledge of the past behavior of the series of price changes cannot be used to increase expected gains. More specifically, the independence assumption is an adequate description of reality as long as the actual degree of dependence in the series of price changes is not sufficient to allow the past history of the series to be used to predict the future in a way, which makes expected profits greater than they would be under a naive buy-and-hold model.},
author = {Fama, Eugene F.},
doi = {10.1086/294743},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama - 1965 - The Behavior of Stock-Market Prices.pdf:pdf},
isbn = {0021-9398},
issn = {0021-9398},
journal = {The Journal of Business},
number = {1},
pages = {34--105},
pmid = {520035},
title = {{The Behavior of Stock-Market Prices}},
volume = {38},
year = {1965}
}
@article{Hong1999,
abstract = {We model a market populated by two groups of boundedly rational agents: "newswatchers" and "momentum traders." Each newswatcher observes some private information, but fails to extract other newswatchers' information from prices. If information diffuses gradually across the population, prices underreact in the short run. The underreaction means that the momentum traders can profit by trend-chasing. However, if they can only implement simple (i.e., univariate) strategies, their attempts at arbitrage must inevitably lead to overreaction at long horizons. In addition to providing a unified account of under- and overreactions, the model generates several other distinctive implications.},
author = {Hong, Harrison and Stein, Jeremy C},
doi = {doi:10.1111/0022-1082.00184},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hong, Stein - 1999 - A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets(2).pdf:pdf},
isbn = {1540-6261},
issn = {0022-1082},
journal = {The Journal of Finance},
number = {6},
pages = {2143--2184},
title = {{A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets}},
url = {http://www.blackwell-synergy.com/doi/abs/10.1111/0022-1082.00184},
volume = {54},
year = {1999}
}
@article{Taieb2017,
abstract = {Many applications require forecasts for a hierarchy comprising a set of time series along with aggregates of subsets of these series. Hierarchical forecasting require not only good prediction accuracy at each level of the hierarchy, but also the coherency between different levels — the property that forecasts add up appropriately across the hierarchy. A fundamental limitation of prior research is the focus on forecasting the mean of each time series. We consider the situation where probabilistic forecasts are needed for each series in the hierarchy, and propose an algorithm to compute predictive distributions rather than mean forecasts only. Our algorithm has the advantage of synthesizing information from different levels in the hierarchy through a sparse forecast combination and a probabilistic hierarchical aggregation. We evaluate the accuracy of our forecasting algorithm on both simulated data and large-scale electricity smart meter data. The results show consistent performance gains compared to state-of-the art methods.},
author = {Taieb, Souhaib Ben and Taylor, James W and Hyndman, Rob J},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Taieb, Taylor, Hyndman - 2017 - Coherent Probabilistic Forecasts for Hierarchical Time Series.pdf:pdf},
issn = {1938-7228},
journal = {Proceedings of the 34th International Conference on Machine Learning},
keywords = {empi,forecast combination,probabilistic forecast},
number = {April},
pages = {3348--3357},
title = {{Coherent Probabilistic Forecasts for Hierarchical Time Series}},
url = {http://proceedings.mlr.press/v70/taieb17a.html},
volume = {70},
year = {2017}
}
@article{Menkhoff2010a,
abstract = {The use of technical analysis by financial market professionals is not well understood. This paper thus analyzes survey evidence from 692 fund managers in five countries, the vast majority of whom rely on technical analysis. At a forecasting horizon of weeks, technical analysis is the most important form of analysis and up to this horizon it is thus more important than fundamental analysis. Technicians are as experienced, as educated, as successful in their career and largely just as overconfident in decision-making as others. However, technical analysis is somewhat more popular in smaller asset management firms. What we find most significant is the relation of technical analysis with the view that prices are heavily determined by psychological influences. Consequently, technicians apply trend-following behavior. ?? 2010 Elsevier B.V.},
author = {Menkhoff, Lukas},
doi = {10.1016/j.jbankfin.2010.04.014},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Menkhoff - 2010 - The Use of Technical Analysis by Fund Managers International Evidence.pdf:pdf},
isbn = {0378-4266},
issn = {03784266},
journal = {Journal of Banking and Finance},
keywords = {Fund managers,Fundamental analysis,Investment behavior,Personal characteristics,Technical analysis},
number = {11},
pages = {2573--2586},
publisher = {Elsevier B.V.},
title = {{The Use of Technical Analysis by Fund Managers: International Evidence}},
url = {http://dx.doi.org/10.1016/j.jbankfin.2010.04.014},
volume = {34},
year = {2010}
}
@misc{R2015,
author = {{R Core Team}},
publisher = {R Foundation for Statistical Computing, Vienna, Austria},
title = {{R: A Language and Environment for Statistical Computing}},
url = {https://www.r-project.org/},
year = {2015}
}
@article{Novy-Marx2012,
abstract = {Momentum is primarily driven by firms' performance 12 to seven months prior to portfolio formation, not by a tendency of rising and falling stocks to keep rising and falling. Strategies based on recent past performance generate positive returns but are less profitable than those based on intermediate horizon past performance, especially among the largest, most liquid stocks. These facts are not particular to the momentum observed in the cross section of US equities. Similar results hold for momentum strategies trading international equity indices, commodities, and currencies. ?? 2011 Elsevier B.V..},
author = {Novy-Marx, Robert},
doi = {10.1016/j.jfineco.2011.05.003},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Novy-Marx - 2012 - Is Momentum Really Momentum.pdf:pdf},
isbn = {0304405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Factor models,Momentum},
number = {3},
pages = {429--453},
pmid = {420},
publisher = {Elsevier},
title = {{Is Momentum Really Momentum?}},
url = {http://dx.doi.org/10.1016/j.jfineco.2011.05.003},
volume = {103},
year = {2012}
}
@book{Lequiller2006,
abstract = {This manual explains what GDP and GNI and their components are, and what they mean. It shows how they are used and what they are used for. And it uses practical examples and exercises to clearly explain these notions. This manual approaches national accounts from a truly global perspective. Special chapters are dedicated to international comparisons as well as to the national systems used in major economies such as USA, China and India. The opening chapter shows how national accounting concepts relate to macroeconomics. The book goes on to systematically deal with volume and prices, international comparability, production, final uses as well as household, business, government and financial accounts.},
author = {Lequiller, Fran{\c{c}}ois and Blades, Derek},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lequiller, Blades - 2006 - Understanding National Accounts.pdf:pdf},
isbn = {92-64-02566-9},
title = {{Understanding National Accounts}},
url = {http://www.oecd.org/std/na/38451313.pdf},
year = {2006}
}
@article{Sims1980,
author = {Sims, Christopher A.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sims - 1980 - Macroeconomics and Reality.pdf:pdf},
journal = {Econometrica},
number = {1},
pages = {1--48},
title = {{Macroeconomics and Reality}},
volume = {48},
year = {1980}
}
@article{Hall2004,
author = {Hall, Stephen G and Mitchell, James},
file = {:/nash/mtec-home/feckert/Desktop/10.1.1.143.7458.pdf:pdf},
number = {0},
pages = {1--36},
title = {{Density Forecast Combination}},
year = {2004}
}
@article{Ibbotson2013,
author = {Ibbotson, Roger G. and Chen, Zhiwu and Kim, Daniel Y.-J. and Hu, Wendy Y.},
doi = {10.2469/faj.v69.n3.4},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ibbotson et al. - 2013 - Liquidity as an Investment Style.pdf:pdf},
issn = {0015-198X},
journal = {Financial Analysts Journal},
month = {may},
number = {3},
pages = {30--44},
title = {{Liquidity as an Investment Style}},
url = {http://www.cfapubs.org/doi/abs/10.2469/faj.v69.n3.4},
volume = {69},
year = {2013}
}
@article{Bikker2005,
author = {Bikker, Jacob A. and Metzemakers, P. A. J.},
doi = {10.1016/j.intfin.2004.03.004},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bikker, Metzemakers - 2005 - Bank Provisioning Behaviour and Procyclicality.pdf:pdf},
issn = {10424431},
journal = {Journal of International Financial Markets, Institutions and Money},
keywords = {business cycle,credit crunch,loan loss provisioning},
month = {apr},
number = {2},
pages = {141--157},
title = {{Bank Provisioning Behaviour and Procyclicality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1042443104000678},
volume = {15},
year = {2005}
}
@article{Sims2010,
author = {Sims, Christopher A.},
doi = {10.1257/jep.24.2.59},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sims - 2010 - But Economics Is Not an Experimental Science.pdf:pdf},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
month = {may},
number = {2},
pages = {59--68},
title = {{But Economics Is Not an Experimental Science}},
url = {http://pubs.aeaweb.org/doi/abs/10.1257/jep.24.2.59},
volume = {24},
year = {2010}
}
@book{Koop2009,
author = {Koop, Gary and Korobilis, Dimitris},
booktitle = {Foundations and Trends{\textregistered} in Econometrics},
doi = {10.1561/0800000013},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Koop, Korobilis - 2009 - Bayesian Multivariate Time Series Methods for Empirical Macroeconomics.pdf:pdf},
isbn = {0800000013},
issn = {1551-3076},
number = {4},
pages = {267--358},
title = {{Bayesian Multivariate Time Series Methods for Empirical Macroeconomics}},
url = {http://www.nowpublishers.com/article/Details/ECO-013},
volume = {3},
year = {2009}
}
@article{Erosheva2017,
abstract = {This paper considers the reflection unidentifiability problem in confirmatory factor analysis (CFA) and the associated implications for Bayesian estimation. We note a direct analogy between the multimodality in CFA models that is due to all possible column sign changes in the matrix of loadings and the multimodality in finite mixture models that is due to all possible relabelings of the mixture components. Drawing on this analogy, we derive and present a simple approach for dealing with reflection in variance in Bayesian factor analysis. We recommend fitting Bayesian factor analysis models without rotational constraints on the loadings—allowing Markov chain Monte Carlo algorithms to explore the full posterior distribution—and then using a relabeling algorithm to pick a factor solution that corresponds to one mode. We demonstrate our approach on the case of a bifactor model; however, the relabeling algorithm is straightforward to generalize for handling multimodalities due to sign invariance in the likelihood in other factor analysis models.},
author = {Erosheva, Elena A. and Curtis, S. Mc Kay},
doi = {10.1007/s11336-017-9564-y},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Erosheva, Curtis - 2017 - Dealing with Reflection Invariance in Bayesian Factor Analysis.pdf:pdf},
issn = {00333123},
journal = {Psychometrika},
keywords = {Markov chain Monte Carlo,identifiability constraints,label-switching,relabeling,rotation,rotational invariance},
number = {2},
pages = {295--307},
publisher = {Springer US},
title = {{Dealing with Reflection Invariance in Bayesian Factor Analysis}},
volume = {82},
year = {2017}
}
@article{Ghysels2007,
author = {Ghysels, Eric and Sinko, Arthur and Valkanov, Rossen},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ghysels, Sinko, Valkanov - 2007 - MIDAS Regressions Further Results and New Directions.pdf:pdf},
journal = {Econometric Reviews},
number = {1},
pages = {1--48},
title = {{MIDAS Regressions: Further Results and New Directions}},
volume = {26},
year = {2007}
}
@article{Geweke1992,
abstract = {Data augmentation and Gibbs sampling are two closely related, sampling-based approaches to the calculation of posterior moments. The fact that each produces a sample whose constituents are neither independent nor identically distributed complicates the assessment of convergence and numerical accuracy of the approximations to the expected value of functions of interest under the posterior. In this paper methods from spectral analysis are used to evaluate numerical accuracy formally and construct diagnostics for convergence. These methods are illustrated in the normal linear model with informative priors, and in the Tobit-censored regression model.},
author = {Geweke, John},
doi = {1176289},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Geweke - 1992 - Evaluating the accuracy of sampling-based approaches to the calculation of posterior moments.pdf:pdf},
journal = {Bayesian Statistics 4},
keywords = {and phrases,carlo integration,data augmentation,gibbs sampling,mixed estimation,monte,tobit model},
pages = {169--193},
title = {{Evaluating the accuracy of sampling-based approaches to the calculation of posterior moments}},
url = {http://www.mpls.frb.org/research/SR/SR148.pdf},
year = {1992}
}
@article{Waggoner1999,
abstract = {In the existing literature, conditional forecasts in the vector autoregressive (VAR) framework have not been commonly presented with probability distributions. This paper develops Bayesian methods for computing the exact finite-sample distribution of conditional forecasts. It broadens the class of conditional forecasts to which the methods can be applied. The methods work for both structural and reduced-form VAR models and, in contrast to common practices, account for parameter uncertainty in finite samples. Empirical examples under both a flat prior and a reference prior are provided to show the use of these methods.},
author = {Waggoner, Daniel F. and Zha, Tao},
doi = {10.1162/003465399558508},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Waggoner, Zha - 1999 - Conditional Forecasts in Dynamic Multivariate Models.pdf:pdf},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
keywords = {bayesian methods,conditional forecasts,error,hard and soft conditions,probability distribution},
number = {4},
pages = {639--651},
title = {{Conditional Forecasts in Dynamic Multivariate Models}},
volume = {81},
year = {1999}
}
@article{Petris2010,
abstract = {Abstract We describe an R package focused on Bayesian analysis of dynamic linear models. The main features of the package are its flexibility to deal with a variety of constant or time-varying, univariate or multivariate models, and the numerically stable singular ... $\backslash$n},
author = {Petris, Giovanni},
doi = {10.1007/BF02887432},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Petris - 2010 - An R Package for Dynamic Linear Models.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {bayesian,forward filtering backward sampling,kalman filter,state space models},
number = {12},
pages = {1--16},
title = {{An R Package for Dynamic Linear Models}},
url = {http://www.jstatsoft.org/v36/i12/paper{\%}5Cnpapers2://publication/uuid/CBB963FA-1862-4D3C-BE12-8DD58B11DC28},
volume = {36},
year = {2010}
}
@book{Gali2008a,
author = {Gal{\'{i}}, Jordi},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gal{\'{i}} - 2008 - Monetary Policy, Inflation and the Business Cycle.pdf:pdf},
isbn = {9780691133164},
pages = {1--203},
publisher = {Princeton University Press},
title = {{Monetary Policy, Inflation and the Business Cycle}},
url = {http://rrp.sagepub.com/cgi/doi/10.1177/0486613410391411},
year = {2008}
}
@article{Lee2000,
abstract = {This study shows that past trading volume provides an important link between "momentum" and "value" strategies. Specifically, we find that firms with high (low) past turnover ratios exhibit many glamour (value) characteristics, earn lower (higher) future returns, and have consistently more negative (positive) earnings surprises over the next eight quarters. Past trading volume also predicts both the magnitude and persistence of price momentum. Specifically, price momentum effects reverse over the next five years, and high (low) volume winners (losers) experience faster reversals. Collectively, our findings show that past volume helps to reconcile intermediate-horizon "underreaction" and long-horizon "overreaction" effects.},
author = {Lee, Charles M. C. and Swaminathan, Bhaskaran},
doi = {10.1111/0022-1082.00280},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lee, Swaminathan - 2000 - Price Momentum and Trading Volume.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
number = {5},
pages = {2017--2069},
title = {{Price Momentum and Trading Volume}},
url = {http://www.blackwell-synergy.com/doi/abs/10.1111/0022-1082.00280},
volume = {55},
year = {2000}
}
@article{Jegadeesh2001,
abstract = {This paper evaluates various explanations for the profitability of momentum strategies documented in Jegadeesh and Titman (1993). The evidence indicates that momentum profits have continued in the 1990's suggesting that the original results were not a product of data snooping bias. The paper also examines the predictions of recent behavioral models that propose that momentum profits are due to delayed overreactions which are eventually reversed. Our evidence provides support for the behavioral models, but this support should be tempered with caution. Although we find no evidence of significant return reversals in the 2 to 3 years following the following formation date, there are significant return reversals 4 to 5 years after the formation date. Our analysis of post-holding period returns sharply rejects a claim in the literature that the observed momentum profits can be explained completely by the cross-sectional dispersion in expected returns. Narasimhan},
author = {Jegadeesh, Narasimhan and Titman, Sheridan},
doi = {10.1111/0022-1082.00342},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jegadeesh, Titman - 2001 - Profitability of Momentum Strategies An Evaluation of Alternative Explanations(2).pdf:pdf},
isbn = {00221082},
issn = {0022-1082},
journal = {The Journal of Finance},
number = {2},
pages = {699--720},
title = {{Profitability of Momentum Strategies: An Evaluation of Alternative Explanations}},
volume = {56},
year = {2001}
}
@misc{Honga,
author = {Hong, Harrison and Stein, Jeremy C},
doi = {doi:10.1111/0022-1082.00184},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hong, Stein - Unknown - Zusammenfassung - A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets.pdf:pdf},
isbn = {1540-6261},
issn = {0022-1082},
title = {{Zusammenfassung - A Unified Theory of Underreaction, Momentum Trading, and Overreaction in Asset Markets}},
url = {http://www.blackwell-synergy.com/doi/abs/10.1111/0022-1082.00184}
}
@article{Grinblatt1995,
abstract = {This study analyzes the extent to which mutual funds purchase stocks based on their past returns as well as their tendency to exhibit "herding" behavior (i.e., buying and selling the same stocks at the same time). We find that 77 percent of the mutual funds were "momentum investors," buying stocks that were past winners; however, most did not systematically sell past losers. On average, funds that invested on momentum realized significantly better performance than other funds. We also find relatively weak evidence that funds tended to buy and sell the same stocks at the same time.},
author = {Grinblatt, Mark and Titman, Sheridan and Wermers, Russ},
doi = {10.2307/2950976},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Grinblatt, Titman, Wermers - 1995 - Momentum Investment Strategies, Portfolio Performance, and Herding A Study of Mutual Fund Behavior.pdf:pdf},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {5},
pages = {1088--1105},
title = {{Momentum Investment Strategies, Portfolio Performance, and Herding: A Study of Mutual Fund Behavior}},
url = {http://www.jstor.org/stable/2950976},
volume = {85},
year = {1995}
}
@article{Stock2002,
abstract = {This article considers forecasting a single time series when there are many predictors (N) and time series observations (T). When the data follow an approximate factor model, the predictors can be summarized by a small number of indexes, which we estimate using principal components. Feasible forecasts are shown to be asymptotically efficient in the sense that the difference between the feasible forecasts and the infeasible forecasts constructed using the actual values of the factors converges in probability to 0 as both N and T grow large. The estimated factors are shown to be consistent, even in the presence of time variation in the factor model.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1198/016214502388618960},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Stock, Watson - 2002 - Forecasting Using Principal Components from a Large Number of Predictors.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {factor models,forecasting,principal components},
number = {460},
pages = {1167--1179},
title = {{Forecasting Using Principal Components from a Large Number of Predictors}},
url = {http://www.jstor.org/stable/3085839},
volume = {97},
year = {2002}
}
@article{Conrad1998,
author = {Kaul, Gautam and Conrad, Jennifer},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kaul, Conrad - 1998 - An Anatomy of Trading Strategies.pdf:pdf},
journal = {The Review of Financial Studies},
number = {3},
pages = {489--519},
title = {{An Anatomy of Trading Strategies}},
volume = {11},
year = {1998}
}
@article{Fama1992,
abstract = {Two easily measured variables, size and book-to-market equity, combine to capture the cross-sectional variation in average stock returns associated with market $\beta$, size, leverage, book-to-market equity, and earnings-price ratios. Moreover, when the tests allow for variation in $\beta$ that is unrelated to size, the relation between market $\beta$ and average return is flat, even when $\beta$ is the only explanatory variable.},
author = {Fama, Eugene F. and French, Kenneth R.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Fama, French - 1992 - The Cross-Section of Expected Stock Returns.pdf:pdf},
journal = {The Journal of Finance},
number = {2},
pages = {427--465},
title = {{The Cross-Section of Expected Stock Returns}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1992.tb04398.x/full},
volume = {XLVII},
year = {1992}
}
@article{Chan1996,
abstract = {We examine whether the predictability of future returns from past returns is due to the market's underreaction to information, in particular to past earnings news. Past return and past earnings surprise each predict large drifts in future returns after controlling for the other. Market risk, size, and book-to-market effects do not explain the drifts. There is little evidence of subsequent reversals in the returns of stocks with high price and earnings momentum. Security analysts' earnings forecasts also respond sluggishly to past news, especially in the case of stocks with the worst past performance. The results suggest a market that responds only gradually to new information.},
author = {Chan, Louis K. C. and Jegadeesh, Narasimhan and Lakonishok, Josef},
doi = {10.1111/j.1540-6261.1996.tb05222.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chan, Jegadeesh, Lakonishok - 1996 - Momentum Strategies.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
number = {5},
pages = {1681--1713},
title = {{Momentum Strategies}},
url = {http://www.jstor.org/stable/2329534?origin=crossref},
volume = {51},
year = {1996}
}
@article{Bohn2002,
author = {Bohn, Henning},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bohn - 2002 - Government Asset and Liability Management in an Era of Vanishing Public Debt.pdf:pdf},
journal = {Journal of Money, Credit and Banking},
keywords = {asset,government,liability,management,public debt},
number = {3},
pages = {887--933},
title = {{Government Asset and Liability Management in an Era of Vanishing Public Debt}},
volume = {34},
year = {2002}
}
@article{Nalewaik2013,
author = {Nalewaik, Jeremy and Diebold, Francis X and Schorfheide, Frank},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Nalewaik, Diebold, Schorfheide - 2013 - Improving GDP Measurement A Measurement-Error Perspective University of Maryland.pdf:pdf},
journal = {Federal Reserve Bank of Philadelphia Working Papers},
number = {13},
title = {{Improving GDP Measurement: A Measurement-Error Perspective University of Maryland}},
year = {2013}
}
@article{Sims1988,
author = {Sims, Christopher A},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sims - 1988 - Bayesian Skepticism on Unit Root Econometrics.pdf:pdf},
pages = {463--474},
title = {{Bayesian Skepticism on Unit Root Econometrics}},
volume = {12},
year = {1988}
}
@book{Chatfield2000,
author = {Chatfield, Chris},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chatfield - 2003 - The Analysis of Time Series.pdf:pdf},
isbn = {1584880635},
pages = {20--115},
title = {{TIME-SERIES FORECASTING.Chapman and Hall/CRC.USA}},
year = {2000}
}
@article{Canova2010,
author = {Canova, Fabio},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Canova - 2010 - Bayesian State Space models.pdf:pdf},
number = {March},
pages = {1--73},
title = {{Bayesian State Space models}},
url = {http://www.crei.cat/people/canova/bayes{\_}ssmodels{\_}upf10.pdf},
year = {2010}
}
@article{Hyndman2011,
abstract = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these "hierarchical time series". They are commonly forecast using either a "bottom-up" or a "top-down" method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
doi = {10.1016/j.csda.2011.03.006},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hyndman et al. - 2011 - Optimal combination forecasts for hierarchical time series.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Bottom-up forecasting,Combining forecasts,GLS regression,Hierarchical forecasting,Reconciling forecasts,Top-down forecasting},
number = {9},
pages = {2579--2589},
publisher = {Elsevier B.V.},
title = {{Optimal combination forecasts for hierarchical time series}},
url = {http://dx.doi.org/10.1016/j.csda.2011.03.006},
volume = {55},
year = {2011}
}
@article{Jackson2015,
author = {Jackson, Tim and Victor, Peter},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jackson, Victor - 2015 - Towards a Stock-Flow Consistent Ecological Macroeconomics.pdf:pdf},
isbn = {15/4},
journal = {UNEP Inquiry Working Paper},
number = {August},
title = {{Towards a Stock-Flow Consistent Ecological Macroeconomics}},
volume = {15/04},
year = {2015}
}
@article{Kim1991,
abstract = {The paper re-examines the empirical evidence for mean-reverting behaviour in stock prices. Comparison of data before and after World War II shows that mean reversion is entirely a pre-war phenomenon. Using randomization methods to calculate significance levels, we find that the full sample evidence for mean reversion is weaker than previously indicated by Monte Carlo methods under a Normal assumption. Further, the switch to mean-averting behaviour after the war is about to be too strong to be compatible with sampling variation. We interpret these findings as evidence of a fundamental change in the stock returns process and conjecture that it may be due to the resolution of the uncertainties of the 1930's and 1940's.},
author = {Kim, Myung Jig and Nelson, Charles R. and Startz, Richard},
doi = {10.2307/2298009},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kim, Nelson, Startz - 1991 - Mean Reversion in Stock Prices A Reappraisal of the Empirical Evidence.pdf:pdf},
issn = {00346527},
journal = {The Review of Economic Studies},
number = {3},
pages = {528--551},
title = {{Mean Reversion in Stock Prices? A Reappraisal of the Empirical Evidence}},
url = {http://www.nber.org/papers/w2795},
volume = {58},
year = {1991}
}
@article{Daniel2011a,
abstract = {Across numerous asset classes, momentum strategies have produced high returns, high Sharpe ratios, and strong positive alphas relative standard asset pricing models. However, the returns to momentum strategies are skewed: they experience infrequent but strong and persistent strings of negative returns. These momentum “crashes” are forecastable: they occur following market declines, when market volatility is high, and contempo- raneous with market “rebounds.” The data suggest that low ex-ante ex- pected returns in crash periods result from a a conditionally high premium attached to the the option-like payoffs of the past-loser portfolios.},
author = {Daniel, Kent and Moskowitz, Tobias J.},
doi = {10.2139/ssrn.1914673},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Daniel, Moskowitz - 2011 - Momentum Crashes.pdf:pdf},
issn = {1556-5068},
journal = {CBS Working Paper},
pages = {1--38},
title = {{Momentum Crashes}},
url = {http://www.columbia.edu/{~}kd2371/papers/unpublished/mom4.pdf{\%}5Cnpapers2://publication/uuid/8CC56886-0412-41E7-B03A-BB0FE59568D9},
year = {2011}
}
@book{Petris2008,
abstract = {State space models have gained tremendous popularity in recent years in as disparate fields as engineering, economics, genetics and ecology. After a detailed introduction to general state space models, this book focuses on dynamic ...},
author = {Petris, Giovanni and Petrone, Sonia and Campagnoli, Patrizia},
doi = {10.1111/j.1751-5823.2010.00109_26.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Petris, Petrone, Campagnoli - 2008 - Dynamic Linear Models with R(2).pdf:pdf},
isbn = {9780387772387 0387772383},
issn = {03067734},
keywords = {Dynamic Linear Models with R,Statistical Theory and Methods},
pages = {1--186},
publisher = {Springer},
title = {{Dynamic Linear Models with R}},
url = {http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-77237-0{\%}5Cnfiles/22/dynamics-linear-models.petris{\_}et{\_}al.pdf{\%}5Cnfiles/21/978-0-387-77237-0.html{\%}5Cnhttp://search.ebscohost.com/login.aspx?direct=true{\&}scope=site{\&}db=nlebk{\&}db=nlabk{\&}AN},
year = {2008}
}
@article{Banbura2013,
abstract = {The term now-casting is a contraction for now and forecasting and has been used for a long-time in meteorology and recently also in economics In this paper we survey recent developments on economic now-casting with special focus on those models that formalize key features of how market participants and policy makers read macroeconomic data releases in real time, which involves: monitoring many data, forming expectations about them and revising the assessment on the state of the economy whenever realizations diverge sizeably from those expectations. (This abstract was borrowed from another version of this item.)},
author = {Banbura, Marta and Giannone, Domenico and Modugno, Mich{\`{e}}le and Reichlin, Lucrezia},
doi = {10.1016/B978-0-444-53683-9.00004-9},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Banbura et al. - 2013 - Now-Casting and the Real-Time Data Flow.pdf:pdf},
isbn = {9780444536839},
journal = {European Central Bank Working Paper Series},
keywords = {Macroeconomic news,macroeconomic forecasting,rea},
number = {15},
title = {{Now-Casting and the Real-Time Data Flow}},
volume = {1564},
year = {2013}
}
@article{Paccagnini,
author = {Paccagnini, Alessia},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Paccagnini - Unknown - Forecasting with FAVAR macroeconomic versus financial factors Forecasting with FAVAR macroeconomic versus finan.pdf:pdf},
number = {256},
title = {{Forecasting with FAVAR : macroeconomic versus financial factors Forecasting with FAVAR : macroeconomic versus financial factors}}
}
@article{Alvarez2015,
author = {Alvarez, Miguel Carri{\'{o}}n},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Alvarez - 2015 - From GDP to Flow-of-Funds A Graphical Stock-Flow modelling approach.pdf:pdf},
journal = {IMK FMM Conference, Berlin 2015},
keywords = {graph theory,national income accounts,stock flow consistent models},
pages = {1--12},
title = {{From GDP to Flow-of-Funds: A Graphical Stock-Flow modelling approach}},
year = {2015}
}
@article{Lewellen2010,
abstract = {It has become standard practice in the cross-sectional asset pricing literature to evaluate models based on how well they explain average returns on size-B/M portfolios, something many models seem to do remarkably well. In this paper, we review and critique the empirical methods used in the literature. We argue that asset pricing tests are often highly misleading, in the sense that apparently strong explanatory power (high cross-sectional R2s and small pricing errors) can provide quite weak support for a model. We offer a number of suggestions for improving empirical tests and evidence that several proposed models do not work as well as originally advertised. ?? 2009 Elsevier B.V.},
author = {Lewellen, Jonathan and Nagel, Stefan and Shanken, Jay},
doi = {10.1016/j.jfineco.2009.09.001},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lewellen, Nagel, Shanken - 2010 - A Skeptical Appraisal of Asset Pricing Tests.pdf:pdf},
isbn = {0304-405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Asset pricing,Cross-sectional tests,Power},
number = {2},
pages = {175--194},
publisher = {Elsevier},
title = {{A Skeptical Appraisal of Asset Pricing Tests}},
url = {http://dx.doi.org/10.1016/j.jfineco.2009.09.001},
volume = {96},
year = {2010}
}
@article{Hyndman2016,
abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
author = {Hyndman, Rob J. and Lee, Alan J. and Wang, Earo},
doi = {10.1016/j.csda.2015.11.007},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Hyndman, Lee, Wang - 2016 - Fast computation of reconciled forecasts for hierarchical and grouped time series.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Combining forecasts,Grouped time series,Hierarchical time series,Reconciling forecasts,Weighted least squares},
pages = {16--32},
publisher = {Elsevier B.V.},
title = {{Fast computation of reconciled forecasts for hierarchical and grouped time series}},
url = {http://dx.doi.org/10.1016/j.csda.2015.11.007},
volume = {97},
year = {2016}
}
@article{Aruoba2009,
abstract = {We construct a framework for measuring economic activity at high frequency, potentially in real time.We a.scotti@frb use a variety of stock and flow data observed at mixed frequencies (including very high frequencies), and we use a dynamic factor model that permits exact filtering. We illustrate the framework in a prototype empirical example and a simulation study calibrated to the example},
author = {Aruoba, S. Borağan and Diebold, Francis X. and Scotti, Chiara},
doi = {10.1198/jbes.2009.07205},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Aruoba, Diebold, Scotti - 2009 - Real-Time Measurement of Business Conditions.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {business cycle,casting,contraction,dynamic factor model,expansion,macroeconomic fore-,recession,state space model,turning point},
number = {4},
pages = {417--427},
title = {{Real-Time Measurement of Business Conditions}},
url = {http://www.tandfonline.com/doi/abs/10.1198/jbes.2009.07205},
volume = {27},
year = {2009}
}
@article{Bikhchandani1998,
abstract = {This article argues that learning by observing the past decisions of others can help explain some otherwise puzzling phenomena about human behavior. For example, why do people tend to converge on similar behavior, in what is known as herding? Why is mass behavior prone to error and fads? It further argues that the theory of observational learning has much to offer economics and business strategy. Social observers have long recognized imitation as important in human society. Machiavelli in 1514 wrote: Men nearly always follow the tracks made by others and proceed in their affairs by imitation. The philosopher Eric Hoffer in 1955 asserted: When people are free to do as they please, they usually imitate each other. A society which gives unlimited freedom to the individual, more often than not attains a disconcerting sameness.},
author = {Bikhchandani, Sushil and Hirshleifer, David and Welch, Ivo},
doi = {10.1257/jep.12.3.151},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bikhchandani, Hirshleifer, Welch - 1998 - Learning from the Behavior of Others Conformity, Fads, and Informational Cascades.pdf:pdf},
isbn = {00223808},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
number = {3},
pages = {151--170},
pmid = {17746758},
title = {{Learning from the Behavior of Others: Conformity, Fads, and Informational Cascades}},
volume = {12},
year = {1998}
}
@book{Albert2009,
abstract = {This book gives you a step-by-step introduction to analysing time series using the open source software R. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence confirms understanding of both the model and the R routine for fitting it to the data. Finally, the model is applied to an analysis of a historical data set. By using R, the whole procedure can be reproduced by the reader. All the data sets used in the book are available on the website The book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyze time series as part of their taught program or their research.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Albert, Jim},
booktitle = {Media},
doi = {10.1007/978-0-387-88698-5},
eprint = {arXiv:1011.1669v3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Albert - 2009 - Bayesian Computation with R.pdf:pdf},
isbn = {9780387886978},
issn = {0266-4763},
pages = {254},
pmid = {22057480},
title = {{Bayesian Computation with R}},
url = {http://www.springerlink.com/index/10.1007/978-0-387-88698-5},
year = {2009}
}
@article{Leamer1983,
author = {Leamer, Edward E.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Leamer - 1983 - Let's Take the Con Out of Econometrics.pdf:pdf},
journal = {The American Economic Review},
number = {1},
pages = {31--43},
title = {{Let's Take the Con Out of Econometrics}},
volume = {73},
year = {1983}
}
@article{Ansley1985,
author = {Ansley, Craig F. and Kohn, Robert},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ansley, Kohn - 1985 - Estimation, Filtering, and Smoothing in State Space Models with Incompletely Specified Initial Conditions.pdf:pdf},
journal = {The Annals of Statistics},
number = {4},
pages = {1286--1316},
title = {{Estimation, Filtering, and Smoothing in State Space Models with Incompletely Specified Initial Conditions}},
volume = {13},
year = {1985}
}
@article{Jensen1978,
abstract = {The efficient market hypothesis has been widely tested and, with few exceptions, found consistent with the data in a wide variety of markets: the New York and American Stock Exchanges, the Australian, English, and German stock markets, various commodity futures markets, the Over-the- Counter markets, the corporate and government bond markets, the option market, and the market for seats on the New York Stock Exchange. Yet, in a manner remarkably similar to that described by Thomas Kuhn in his book, The Structure of Scientific Revolutions, we seem to be entering a stage where widely scattered and as yet incohesive evidence is arising which seems to be inconsistent with the theory. As better data become available (e.g., daily stock price data) and as our econometric sophistication increases, we are beginning to find inconsistencies that our cruder data and techniques missed in the past. It is evidence which we will not be able to ignore. The purpose of this special issue of the Journal of Financial Economics is to bring together a number of these scattered pieces of anomalous evidence regarding Market Efficiency. As Ball (1978) points out in his survey article: taken individually many scattered pieces of evidence on the reaction of stock prices to earnings announcements which are inconsistent with the theory don't amount to much. Yet viewed as a whole, these pieces of evidence begin to stack up in a manner which make a much stronger case for the necessity to carefully review both our acceptance of the efficient market theory and our methodological procedures.},
author = {Jensen, Michael C.},
doi = {10.1016/0304-405X(78)90025-9},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jensen - 1978 - Some Anomalous Evidence Regarding Market Efficiency.pdf:pdf},
isbn = {0304405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Efficient Market Theory,abnormal returns,asset pricing model.,market efficiency,rational expectations theory,theory of ‘random walks'},
number = {2},
pages = {95--101},
title = {{Some Anomalous Evidence Regarding Market Efficiency}},
volume = {6},
year = {1978}
}
@article{Cesur2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Amisano, Gianni and Geweke, John},
doi = {10.1162/REST},
eprint = {arXiv:1011.1669v3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Amisano, Geweke - 2017 - Prediction using several macroeconomic models.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {5},
pages = {912--925},
pmid = {21860536},
title = {{Prediction using several macroeconomic models}},
volume = {99},
year = {2017}
}
@book{Havik2014,
abstract = {This paper provides a detailed description of the current version of the Ecofin Council approved production function (PF) methodology which is used for assessing both the productive capacity (i.e. potential output) and cyclical position (i.e. output gaps) of EU economies. Compared with the previous 2010 paper on the same topic, there have been two significant changes to the PF methodology, namely an overhaul of the NAWRU methodology {\&} the introduction of a new T+10 methodology.},
author = {Havik, Karel and Morrow, Kieran Mc and Orlandi, Fabrice and Planas, Christophe and Raciborski, Rafal and R{\"{o}}ger, Werner and Rossi, Alessandro and Thum-thysen, Anna and Vandermeulen, Valerie},
booktitle = {European Commission Economic Papers},
doi = {10.2765/71437},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Havik et al. - 2014 - The Production Function Methodology for Calculating Potential Growth Rates {\&} Output Gaps.pdf:pdf},
isbn = {9789279351846},
issn = {1725-3187 (electronic)},
keywords = {C10 E60 O10$\backslash$r$\backslash$n$\backslash$r$\backslash$nProduction function methodology,po},
title = {{The Production Function Methodology for Calculating Potential Growth Rates {\&} Output Gaps}},
volume = {535},
year = {2014}
}
@article{Malkiel2005,
abstract = {In recent years financial economists have increasingly questioned the efficient market hypothesis. But surely if market prices were often irrational and if market returns were as predictable as some critics have claimed, then professionally managed investment funds should easily be able to outdistance a passive index fund. This paper shows that professional investment managers, both in The U.S. and abroad, do not outperform their index benchmarks and provides evidence that by and large market prices do seem to reflect all available information.},
author = {Malkiel, Burton G.},
doi = {10.1111/j.0732-8516.2005.00090.x},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Malkiel - 2005 - Reflections on the Efficient Market Hypothesis 30 Years Later.pdf:pdf},
isbn = {1540-6288},
issn = {0732-8516},
journal = {Financial Review},
keywords = {30 years,advocate of the efficient,and,as a result,efficient markets,equity prices adjust to,g12,g14,i have been an,in my view,jel classifications,market hypothesis for over,new information without delay,stock market predictability},
number = {1},
pages = {1--9},
title = {{Reflections on the Efficient Market Hypothesis: 30 Years Later}},
volume = {40},
year = {2005}
}
@book{Malkiel1973,
author = {Malkiel, Burton G.},
pages = {1--456},
publisher = {W. W. Norton {\&} Company, Inc.},
title = {{A Random Walk Down Wall Street}},
year = {1973}
}
@article{Denis2006,
abstract = {Any meaningful analysis of cyclical developments, of medium term growth prospects or of the stance of fiscal and monetary policies are all predicated on either an implicit or explicit assumption concerning the rate of potential output growth. Given the importance of the concept, the measurement of potential output is the subject of contentious and sustained research interest. All the available methods have "pros" and "cons" and none can unequivocally be declared better than the alternatives in all cases. Thus, what matters is to have a method adapted to the problem under analysis, with well defined limits and, in international comparisons, one that deals identically with all countries. This is the approach adopted in the present paper where it is stated clearly that the objective is to produce an economics based, production function, method which can be used for operational EU policy surveillance purposes.},
author = {Denis, C{\'{e}}cile and Grenouilleau, Daniel and Morrow, Kieran Mc and R{\"{o}}ger, Werner},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Denis et al. - 2006 - Calculating Potential Growth Rates and Output Gaps - A Revised Production Function.pdf:pdf},
isbn = {927901188X},
journal = {European Commission Economic Papers},
title = {{Calculating Potential Growth Rates and Output Gaps - A Revised Production Function}},
url = {http://ec.europa.eu/economy{\_}finance/publications/publication{\_}summary752{\_}en.htm},
volume = {247},
year = {2006}
}
@article{Ghysels2012,
author = {Ghysels, Eric},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Ghysels - 2012 - Macroeconomics and the Reality of Mixed Frequency Data.pdf:pdf},
journal = {University of North Carolina Working Paper},
pages = {1--52},
title = {{Macroeconomics and the Reality of Mixed Frequency Data}},
year = {2012}
}
@article{Brooks2001,
author = {Conflitti, Cristina and Mol, Christine De and Giannone, Domenico},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Conflitti, Mol, Giannone - 2001 - Optimal combination of survey forecasts.pdf:pdf},
keywords = {forecast combination},
number = {0},
pages = {415--425},
title = {{Optimal combination of survey forecasts}},
volume = {30},
year = {2001}
}
@article{Furceri2012,
abstract = {The aim of this paper is to assess the impact of financial crises on potential output. For this purpose a univariate autoregressive growth equation is estimated on an unbalanced panel of OECD countries over the period 1960-2008. Our results suggest that the occurrence of a financial crisis negatively and permanently affects potential output. In particular, financial crises are estimated to lower potential output by around 1.5-2.4{\%} on average, with most of the impact coming from the effect on capital. The magnitude of the effect increases with the severity of the crisis. These results are robust to the use of an alternative measure of potential output, changes in the methodology and in the sample periods. The impact of financial crises is also found to vary according to structural features of the economies, such as the degree of openness, macro-economic imbalances, financial deepening and the quality of governance. {\textcopyright} 2012 Elsevier Inc.},
author = {Furceri, Davide and Mourougane, Annabelle},
doi = {10.1016/j.jmacro.2012.05.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Furceri, Mourougane - 2012 - The Effect of Financial Crises on Potential Output New Empirical Evidence from OECD Countries.pdf:pdf},
isbn = {0164-0704},
issn = {01640704},
journal = {Journal of Macroeconomics},
keywords = {Financial crisis,Potential output},
number = {3},
pages = {822--832},
publisher = {Elsevier Inc.},
title = {{The Effect of Financial Crises on Potential Output: New Empirical Evidence from OECD Countries}},
url = {http://dx.doi.org/10.1016/j.jmacro.2012.05.010},
volume = {34},
year = {2012}
}
@article{Roncalli2007,
author = {Roncalli, Thierry and Teiletche, Jerome},
doi = {10.2139/ssrn.1035521},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Roncalli, Teiletche - 2008 - An Alternative Approach to Alternative Beta.pdf:pdf},
issn = {1556-5068},
journal = {Journal of Financial Transformation},
pages = {43--52},
title = {{An Alternative Approach to Alternative Beta}},
url = {http://www.ssrn.com/abstract=1035521},
volume = {24},
year = {2008}
}
@article{Jarocinski2010,
abstract = {This note simplifies the Waggoner and Zha (1999) formula for the conditional distribution of shocks, discusses its linear algebraic intuition, and shows how to account for the dependence between the conditional and unconditional predictive densities when comparing them. {\textcopyright} 2010 Elsevier B.V.},
author = {Jaroci{\'{n}}ski, Marek},
doi = {10.1016/j.econlet.2010.05.022},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Jaroci{\'{n}}ski - 2010 - Conditional forecasts and uncertainty about forecast revisions in vector autoregressions.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {Conditional forecast,Forecast revision,Vector autoregression},
number = {3},
pages = {257--259},
title = {{Conditional forecasts and uncertainty about forecast revisions in vector autoregressions}},
volume = {108},
year = {2010}
}
@article{Gorton2013,
abstract = {1. General Economics and Teaching - General 2. General Economics and Teaching - General - Institutions and the Macroeconomy 3. General Economics and Teaching - Macroeconomics: Consumption, Saving, Production, Employment, and Investment 4. General Economics and Teaching - Prices, Business Fluctuations, and Cycles 5. General Economics and Teaching - Prices, Business Fluctuations, and Cycles - Business Fluctuations; Cycles 6. General Economics and Teaching - Money and Interest Rates 7. General Economics and Teaching - Money and Interest Rates - Demand for Money 8. General Economics and Teaching - General - Financial Crises 9. General Economics and Teaching - General Financial Markets - Asset Pricing; Trading volume; Bond Interest Rates 10. General Economics and Teaching - Financial Institutions and Services},
author = {Gorton, Gary B. and Ordo{\~{n}}ez, Guillermo},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Gorton, Ordo{\~{n}}ez - 2013 - The Supply and Demand for Safe Assets.pdf:pdf},
journal = {NBER Working Paper Series},
keywords = {Asset Pricing,Corporate Finance,Economic Fluctua},
title = {{The Supply and Demand for Safe Assets}},
volume = {18732},
year = {2013}
}
@book{Gentleman2008,
abstract = {Instructional Book for using R for programming},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Everitt, Brian and Hothorn, Torsten},
booktitle = {Applied Spatial Data Analysis with R},
doi = {10.1007/978-0-387-78171-6},
eprint = {arXiv:1011.1669v3},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Everitt, Hothorn - 2008 - An Introduction to Applied Multivariate Analysis with R.pdf:pdf},
isbn = {978-0-387-78170-9},
issn = {9780387938363},
pages = {284},
pmid = {22057480},
title = {{An Introduction to Applied Multivariate Analysis with R}},
year = {2008}
}
@article{Lehmann1990,
author = {Lehmann, Bruce N.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lehmann - 1990 - Fads, Martingales, and Market Efficiency.pdf:pdf},
journal = {Quarterly Journal of Economics},
number = {1},
pages = {1--28},
title = {{Fads, Martingales, and Market Efficiency}},
volume = {105},
year = {1990}
}
@article{Lo2004,
author = {Lo, Andrew W.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lo - 2004 - The Adaptive Markets Hypothesis Market Efficiency from an Evolutionary Perspective.pdf:pdf},
journal = {Journal of Portfolio Management},
number = {5},
pages = {15--29},
title = {{The Adaptive Markets Hypothesis: Market Efficiency from an Evolutionary Perspective}},
volume = {30},
year = {2004}
}
@article{Kiley2013,
abstract = {What is the output gap? I discuss three alternative definitions: the deviation of output from its long-run stochastic trend (i.e., the "Beveridge-Nelson cycle"); the deviation of output from the level consistent with current technologies and normal utilization of capital and labor input (i.e., the "production-function approach"); and the deviation of output from "flexible-price" output (i.e., its "natural rate"). Estimates of each concept are presented from a dynamic-stochastic-general-equilibrium (DSGE) model of the U.S. economy used at the Federal Reserve Board. Four points are emphasized: The DSGE model's estimate of the gap (for each definition) is very similar to gaps from policy institutions, but the model's estimate of potential growth has a higher variance and substantially different covariance with GDP growth; the change in the Beveridge-Nelson trend covaries negatively with the change in the gap in the DSGE model, providing a structural model estimate of a controversial parameter; in this model, estimates of the natural-rate concept are similar to those based on the Beveridge-Nelson and production function approaches; and the estimate of the output gap, irrespective of definition, is closely related to unemployment fluctuations. {\textcopyright} 2013.},
author = {Kiley, Michael T.},
doi = {10.1016/j.jmacro.2013.04.002},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Kiley - 2013 - Output Gaps.pdf:pdf},
issn = {01640704},
journal = {Journal of Macroeconomics},
keywords = {Business cycles,Potential output},
pages = {1--18},
publisher = {Elsevier Inc.},
title = {{Output Gaps}},
url = {http://dx.doi.org/10.1016/j.jmacro.2013.04.002},
volume = {37},
year = {2013}
}
@article{Marcucci2009,
author = {Marcucci, Juri and Quagliariello, Mario},
doi = {10.1016/j.jbankfin.2009.03.010},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Marcucci, Quagliariello - 2009 - Asymmetric Effects of the Business Cycle on Bank Credit Risk.pdf:pdf},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
month = {sep},
number = {9},
pages = {1624--1635},
publisher = {Elsevier B.V.},
title = {{Asymmetric Effects of the Business Cycle on Bank Credit Risk}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378426609000648},
volume = {33},
year = {2009}
}
@article{Aguilar2000,
author = {Aguilar, Omar and West, Mike},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Aguilar, West - 2000 - Bayesian dynamic factor models and variance matrix discounting for portfolio allocation.pdf:pdf},
journal = {J. Bus. Econom. Statist.},
keywords = {dynamic factor analysis,dynamic linear models,exchange rates forecasting,markov chain monte carlo,multivariate stochastic volatility,portfolio selection,variance},
number = {January},
pages = {338--357},
title = {{Bayesian dynamic factor models and variance matrix discounting for portfolio allocation}},
volume = {18},
year = {2000}
}
@article{Moskowitz2012,
abstract = {We document significant "time series momentum" in equity index, currency, commodity, and bond futures for each of the 58 liquid instruments we consider. We find persistence in returns for one to 12 months that partially reverses over longer horizons, consistent with sentiment theories of initial under-reaction and delayed over-reaction. A diversified portfolio of time series momentum strategies across all asset classes delivers substantial abnormal returns with little exposure to standard asset pricing factors and performs best during extreme markets. Examining the trading activities of speculators and hedgers, we find that speculators profit from time series momentum at the expense of hedgers. {\textcopyright} 2011 Elsevier B.V..},
author = {Moskowitz, Tobias J. and Ooi, Yao Hua and Pedersen, Lasse Heje},
doi = {10.1016/j.jfineco.2011.11.003},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Moskowitz, Ooi, Pedersen - 2012 - Time Series Momentum.pdf:pdf},
isbn = {0304405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Asset pricing,Futures pricing,International financial markets,Market efficiency,Trading volume},
number = {2},
pages = {228--250},
pmid = {73528122},
publisher = {Elsevier},
title = {{Time Series Momentum}},
url = {http://dx.doi.org/10.1016/j.jfineco.2011.11.003},
volume = {104},
year = {2012}
}
@article{Chopra1992,
abstract = {A highly controversial issue in financial economies is whether stocks overreact. In this paper we find an economically-important overreaction effect even after adjusting for size and beta. In portfolios formed on the basis of prior five-year returns, extreme prior losers outperform extreme prior winners by 5–10{\%} per year during the subsequent five years. Although we find a pronounced January seasonal, our evidence suggests that the overreaction effect is distinct from tax-loss selling effects. Interestingly, the overreaction effect is substantially stronger for smaller firms than for larger firms. Returns consistent with the overeaction hypothesis are also observed for short windows around quarterly earnings announcements.},
author = {Chopra, Navin and Lakonishok, Josef and Ritter, Jay R.},
doi = {10.1016/0304-405X(92)90005-I},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Chopra, Lakonishok, Ritter - 1992 - Measuring Abnormal Performance - Do Stocks Overreact.pdf:pdf},
isbn = {0304-405X},
issn = {0304405X},
journal = {Journal of Financial Economics},
number = {2},
pages = {235--268},
pmid = {12154467},
title = {{Measuring Abnormal Performance - Do Stocks Overreact?}},
volume = {31},
year = {1992}
}
@article{Grossman1980,
author = {Grossman, Sanford and Stiglitz, Joseph E},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Grossman, Stiglitz - 1980 - On the Impossibility of Informationally Efficient Markets.pdf:pdf},
journal = {American Economic Review},
number = {3},
pages = {393--408},
title = {{On the Impossibility of Informationally Efficient Markets}},
volume = {70},
year = {1980}
}
@article{Asness2013,
author = {Asness, Clifford S. and Moskowitz, Tobias J. and Pedersen, Lasse Heje},
doi = {10.1111/jofi.12021},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Asness, Moskowitz, Pedersen - 2013 - Value and Momentum Everywhere.pdf:pdf},
issn = {00221082},
journal = {The Journal of Finance},
month = {jun},
number = {3},
pages = {929--985},
title = {{Value and Momentum Everywhere}},
url = {http://doi.wiley.com/10.1111/jofi.12021},
volume = {68},
year = {2013}
}
@book{Lynch2007,
author = {Lynch, Scott M.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lynch - 2007 - Introduction to Applied Bayesian Statistics and Estimation for Social Scientists.pdf:pdf},
isbn = {9780387712642},
publisher = {Springer},
title = {{Introduction to Applied Bayesian Statistics and Estimation for Social Scientists}},
url = {http://www.lavoisier.fr/livre/notice.asp?id=O2SWLLAR3XKOWM},
year = {2007}
}
@article{Armesto2010,
author = {Armesto, Michelle T. and Engemann, Kristie M. and Owyang, Michael T.},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Armesto, Engemann, Owyang - 2010 - Forecasting with Mixed Frequencies.pdf:pdf},
journal = {Federal Reserve Bank of St. Louis Review},
keywords = {C32,Federal Reserve Bank of St. Louis,Kristie Engemann,Michael Mike Owyang,Michelle Armesto,economic research},
number = {6},
pages = {521--536},
title = {{Forecasting with Mixed Frequencies}},
volume = {92},
year = {2010}
}
@article{Marcellino2016,
author = {Marcellino, Massimiliano and Porqueddu, Mario and Venditti, Fabrizio},
doi = {10.1080/07350015.2015.1006773},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Marcellino, Porqueddu, Venditti - 2016 - Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volatili.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {business cycle,mixed-frequency data,nonlinear models,nowcasting},
number = {1},
pages = {118--127},
title = {{Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volatility}},
url = {http://www.tandfonline.com/doi/full/10.1080/07350015.2015.1006773},
volume = {34},
year = {2016}
}
@article{Sims1991,
author = {Sims, Christopher A. and Uhlig, Harald},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Sims, Uhlig - 1991 - Understanding Unit Rooters A Helicopter Tour.pdf:pdf},
journal = {Econometrica},
number = {6},
pages = {1591--1599},
title = {{Understanding Unit Rooters: A Helicopter Tour}},
volume = {59},
year = {1991}
}
@article{Houge2006,
author = {Houge, Todd and Loughran, Tim},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Houge, Loughran - 2006 - Do Investors Capture the Value Premium.pdf:pdf},
journal = {Financial Management},
pages = {5--19},
title = {{Do Investors Capture the Value Premium?}},
volume = {35},
year = {2006}
}
@article{Smets2002,
abstract = {This paper analyses the effect of measurement error in the output gap on efficient monetary policy rules in a simple estimated model of the US economy. While it is a well-known result that such additive uncertainty does not affect the optimal feedback rule in a linear-quadratic framework, it is shown that output gap uncertainty can have a significant effect on the efficient response coefficients in restricted instrument rules such as the popular Taylor rule. Output gap uncertainty reduces the response to the current estimated output gap relative to current inflation and may partly explain why the parameters in estimated Taylor rules are often much lower than suggested by optimal control exercises which assume the state of the economy is known.},
author = {Smets, Frank},
doi = {10.1007/s181-002-8362-4},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Smets - 2002 - Output gap uncertainty Does it matter for the Taylor rule.pdf:pdf},
issn = {03777332},
journal = {Empirical Economics},
keywords = {Monetary policy,Output gap,Uncertainty},
number = {1},
pages = {113--129},
title = {{Output gap uncertainty: Does it matter for the Taylor rule?}},
volume = {27},
year = {2002}
}
@article{Aastveit2014,
abstract = {By using a dynamic factor model, we can substantially improve the reliability of real-time output gap estimates for the U.S. economy. First, we use a factor model to extract a series for the common component in GDP from a large panel of monthly real-time macroeconomic variables. This series is immune to revisions to the extent that revisions are due to unbiased measurement errors or idiosyncratic news. Second, our model is able to handle the unbalanced arrival of the data. This yields favorable nowcasting properties and thus starting conditions for the filtering of data into a trend and deviations from a trend. Combined with the method of augmenting data with forecasts prior to filtering, this greatly reduces the end-of-sample imprecision in the gap estimate. The increased precision has economic importance for real-time policy decisions and improves real-time inflation forecasts. {\textcopyright} 2013 The Board of Trustees of the University of Illinois.},
author = {Aastveit, Knut Are and Trovik, T{\o}rres},
doi = {10.1016/j.qref.2013.09.003},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Aastveit, Trovik - 2014 - Estimating the output gap in real time A factor model approach.pdf:pdf},
issn = {10629769},
journal = {Quarterly Review of Economics and Finance},
keywords = {Factor model,Forecasting,Monetary policy,Output gap,Real time analysis},
number = {2},
pages = {180--193},
publisher = {Board of Trustees of the University of Illinois},
title = {{Estimating the output gap in real time: A factor model approach}},
url = {http://dx.doi.org/10.1016/j.qref.2013.09.003},
volume = {54},
year = {2014}
}
@incollection{Lo1988,
abstract = {In this article we test the random walk hypothesis for weekly stock market returns by comparing variance estimators derived from data sampled at different frequencies. The random walk model is strongly rejected for the entire sample period (1962-1985) and for all subperiods for a variety of aggregate returns indexes and size-sorted portfolios. Although the rejections are due largely to the behavior of small stocks, they cannot be attributed completely to the effects of infrequent trading or time-varying volatilities. Moreover, the rejection of the random walk for weekly returns does not support a mean-reverting model of asset prices.},
author = {Lo, Andrew W. and MacKinlay, A. Craig},
booktitle = {A Non-Random Walk Down Wall Street},
doi = {10.1093/rfs/1.1.41},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Lo, MacKinlay - 1988 - Stock Market Prices Do Not Follow Random Walks Evidence from a Simple Specification Test.pdf:pdf},
isbn = {08939454},
issn = {0893-9454},
pages = {17--45},
title = {{Stock Market Prices Do Not Follow Random Walks: Evidence from a Simple Specification Test}},
year = {1988}
}
@book{Lutkepohl2017,
author = {L{\"{u}}tkepohl, Helmut and Kilian, Lutz},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/L{\"{u}}tkepohl, Kilian - 2017 - Structural Vector Autoregressions.pdf:pdf},
pages = {1--507},
publisher = {Cambridge University Press},
title = {{Structural Vector Autoregressions}},
year = {2017}
}
@article{Bernanke1995,
author = {Bernanke, Ben S. and Gertler, Mark},
file = {:/nash/mtec-home/feckert/My Documents/Mendeley Desktop/Bernanke, Gertler - 1995 - Inside the Black Box The Credit Channel of Monetary Policy Transmission.pdf:pdf},
journal = {NBER Working Paper Series},
number = {5146},
pages = {1--47},
title = {{Inside the Black Box: The Credit Channel of Monetary Policy Transmission}},
volume = {1995},
year = {1995}
}
